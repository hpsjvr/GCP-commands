variable "instance_name" {}
variable "instance_zone" {}
variable "instance_type" {
  default = "n1-standard-1"
  }
variable "instance_network" {}

resource "google_compute_instance" "vm_instance" {
  name         = "${var.instance_name}"
  zone         = "${var.instance_zone}"
  machine_type = "${var.instance_type}"
  boot_disk {
    initialize_params {
      image = "debian-cloud/debian-9"
      }
  }
  network_interface {
    network = "${var.instance_network}"
    access_config {
      # Allocate a one-to-one NAT IP to the instance
    }
  }
}

kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:2.0

gcloud container clusters get-credentials my-cluster
kubectl expose deployment hello-app --type=LoadBalancer --port 8080

kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0

Create a cluster (in the us-east1-b zone) to host the service.
Use the Docker container hello-app (gcr.io/google-samples/hello-app:2.0) as a place holder; the team will replace the container with their own work later.
Expose the app on port 8080.

gcr.io/google-samples/hello-app:2.0)

us-east1-b

Create an instance template.
Create a target pool.
Create a managed instance group.
Create a firewall rule to allow traffic (80/tcp).
Create a health check.
Create a backend service, and attach the managed instance group.
Create a URL map, and target the HTTP proxy to route requests to your URL map.
Create a forwarding rule.

gcloud compute instances create nginx1 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
 apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html"
	
gcloud compute instances create nginx2 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
 apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html"

gcloud compute firewall-rules create www-firewall-network-lb \
    --target-tags network-lb-tag --allow tcp:80
	
	

gcloud compute networks create managementnet --project=qwiklabs-gcp-03-637d4d885e32 --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-03-637d4d885e32 --range=10.130.0.0/20 --network=managementnet --region=us-central1

gcloud compute --project=qwiklabs-gcp-03-637d4d885e32 firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0

gcloud beta compute --project=qwiklabs-gcp-03-637d4d885e32 instances create managementnet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=844965241571-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210217 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any


student_02_9985c7b9d67a@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-02-eb3cb8fca754)$ kubectl get services frontend
NAME       TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)         AGE
frontend   LoadBalancer   10.115.249.14   34.67.56.157   443:30698/TCP   65s


docker pull gcr.io/qwiklabs-gcp-01-200aad9a20ed/node-app:0.2
docker run -p 4000:80 -d gcr.io/qwiklabs-gcp-01-200aad9a20ed/node-app:0.2
curl http://localhost:4000

student_01_e1239e502c7d@cloudshell:~ (qwiklabs-gcp-01-b7642adaec72)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
hello-server   LoadBalancer   10.3.254.128   35.184.224.3   8080:31200/TCP   44s
kubernetes     ClusterIP      10.3.240.1     <none>         443/TCP          3m50s
student_01_e1239e502c7d@cloudshell:~ (qwiklabs-gcp-01-b7642adaec72)$



gcloud compute instance-groups managed set-named-ports nginx-group --named-ports http:80



 --------------------Set up and Configure a Cloud Environment in Google Cloud: Challenge Lab:--------------



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

----------------Task 1: Create development VPC manually--------------------

For this task because it is mentioned to develop manually .....
We will perform it manually



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

--------------Task 2: Create production VPC using Deployment Manager--------


gsutil cp -r gs://cloud-training/gsp321/dm .

cd dm

sed -i s/SET_REGION/us-east1/g prod-network.yaml

gcloud deployment-manager deployments create prod-network \
    --config=prod-network.yaml

cd ..


##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

-------------Task 3: Create bastion host----------------------------------------

You can copy the below three commands at a time and run them on the Cloud shell.------

gcloud compute instances create bastion --network-interface=network=griffin-dev-vpc,subnet=griffin-dev-mgmt  --network-interface=network=griffin-prod-vpc,subnet=griffin-prod-mgmt --tags=ssh --zone=us-east1-b

gcloud compute firewall-rules create fw-ssh-dev --source-ranges=0.0.0.0/0 --target-tags ssh --allow=tcp:22 --network=griffin-dev-vpc

gcloud compute firewall-rules create fw-ssh-prod --source-ranges=0.0.0.0/0 --target-tags ssh --allow=tcp:22 --network=griffin-prod-vpc




##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
-------------Task 4: Create and configure Cloud SQL Instance-----------------------

gcloud sql instances create griffin-dev-db --root-password password --region=us-east1

gcloud sql connect griffin-dev-db


sql commands:---
CREATE DATABASE wordpress;
GRANT ALL PRIVILEGES ON wordpress.* TO "wp_user"@"%" IDENTIFIED BY "stormwind_rules";
FLUSH PRIVILEGES;



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
--------------Task 5: Create Kubernetes cluster-------------------------------------

gcloud container clusters create griffin-dev \
  --network griffin-dev-vpc \
  --subnetwork griffin-dev-wp \
  --machine-type n1-standard-4 \
  --num-nodes 2  \
  --zone us-east1-b

ubeconfig entry generated for griffin-dev.
NAME         LOCATION    MASTER_VERSION    MASTER_IP      MACHINE_TYPE   NODE_VERSION      NUM_NODES  STATUS
griffin-dev  us-east1-b  1.18.12-gke.1210  35.231.154.14  n1-standard-4  1.18.12-gke.1210  2          RUNNING
student_01_9e99e6b73110@cloudshell:~ (qwiklabs-gcp-01-28fbed30f737)$

gcloud container clusters get-credentials griffin-dev --zone us-east1-b

cd ~/


##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
---------------------------------Task 6 ,7, 8------------------------------------

gsutil cp -r gs://cloud-training/gsp321/wp-k8s .

cd wp-k8s

sed -i s/username_goes_here/wp_user/g wp-env.yaml

sed -i s/password_goes_here/stormwind_rules/g wp-env.yaml

----------------------------------------------------------------------------------

kubectl create -f wp-env.yaml

gcloud iam service-accounts keys create key.json --iam-account=cloud-sql-proxy@$GOOGLE_CLOUD_PROJECT.iam.gserviceaccount.com

kubectl create secret generic cloudsql-instance-credentials --from-file key.json

----------------------------------------------------------------------------------


I=$(gcloud sql instances describe griffin-dev-db --format="value(connectionName)")

sed -i s/YOUR_SQL_INSTANCE/$I/g wp-deployment.yaml

kubectl create -f wp-deployment.yaml

kubectl create -f wp-service.yaml


thanks :)
##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$ gcloud container clusters create webfrontend --zone $MY_ZONE --num-nodes 2

WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster webfrontend in us-central1-a... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-fe66d4e862ba/zones/us-central1-a/clusters/webfrontend].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/webfrontend?project=qwiklabs-gcp-00-fe66d4e862ba
kubeconfig entry generated for webfrontend.
NAME         LOCATION       MASTER_VERSION   MASTER_IP       MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
webfrontend  us-central1-a  1.18.16-gke.302  34.123.157.157  e2-medium     1.18.16-gke.302  2          RUNNING
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$

104.154.203.125


nginx        LoadBalancer   10.51.245.111   <pending>     80:31011/TCP   42s
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$ kubectl get services
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP       PORT(S)        AGE
kubernetes   ClusterIP      10.51.240.1     <none>            443/TCP        8m28s
nginx        LoadBalancer   10.51.245.111   104.154.203.125   80:31011/TCP   45s

VPC Networking

gcloud compute networks create managementnet --project=qwiklabs-gcp-03-d0417a0df52c --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-03-d0417a0df52c --range=10.130.0.0/20 --network=managementnet --region=us-central1


gcloud compute networks create privatenet --subnet-mode=custom

gcloud compute networks subnets create privatesubnet-us --network=privatenet --region=us-central1 --range=172.16.0.0/24

gcloud compute networks subnets create privatesubnet-eu --network=privatenet --region=europe-central2 --range=172.20.0.0/20

gcloud compute networks list


gcloud compute networks subnets list --sort-by=NETWORK

gcloud compute --project=qwiklabs-gcp-03-d0417a0df52c firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0


gcloud compute firewall-rules create privatenet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=privatenet --action=ALLOW --rules=icmp,tcp:22,tcp:3389 --source-ranges=0.0.0.0/0


gcloud beta compute --project=qwiklabs-gcp-03-d0417a0df52c instances create managementnet-us-vm --zone=us-central1-c --machine-type=n1-standard-1 --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=378953624177-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210316 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any



gcloud compute instances create privatenet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=privatesubnet-us --image-family=debian-10 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-standard --boot-disk-device-name=privatenet-us-vm



gcloud compute instances list --sort-by=ZONE



Implement Private Google Access and Cloud NAT

To connect to vm-internal, run the following command:

gcloud compute ssh vm-internal --zone us-central1-c --tunnel-through-iap


mybucket13806

gsutil cp gs://cloud-training/gcpnet/private/access.svg gs://mybucket13806

gsutil cp gs://mybucket13806/*.svg .



export SQL_CONNECTION=qwiklabs-gcp-03-a61351f94ea3:us-central1:wordpress-db

10.63.240.2
34.68.23.74

qwiklabs-gcp-04-storecore21778f3f0b95

qwiklabs-gcp-04-storecorede0347cd46b4

mybucket21778f3f0b95

Tr+QuUvSSilbpelcDDT+TfkrIQlnEgwZDdcjfh+j1vI=

+lrNHeRNQ4VMiL1iRDVWfQKQU/ddUs0y17jboebzZbs=

export BUCKET_NAME_1=storecore21778f3f0b95


peering network
gcloud compute target-vpn-gateways create vpn-1 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --network=vpn-network-1

gcloud compute forwarding-rules create vpn-1-rule-esp --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=ESP --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp500 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=UDP --ports=500 --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp4500 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=UDP --ports=4500 --target-vpn-gateway=vpn-1

gcloud compute vpn-tunnels create vpn-1-tunnel-1 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --peer-address=35.233.6.236 --shared-secret=gcprocks --ike-version=2 --local-traffic-selector=0.0.0.0/0 --remote-traffic-selector=0.0.0.0/0 --target-vpn-gateway=vpn-1

gcloud compute routes create vpn-1-tunnel-1-route-1 --project=qwiklabs-gcp-00-9353e3a9e4af --network=vpn-network-1 --priority=1000 --destination-range=10.1.3.0/24 --next-hop-vpn-tunnel=vpn-1-tunnel-1 --next-hop-vpn-tunnel-region=us-central1



gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-image:v0.1

student_00_f82b8b5f83e7@cloudshell:~/gcp-course/devops-repo (qwiklabs-gcp-00-90db9ea27409)$ git push origin master
Enumerating objects: 5, done.
Counting objects: 100% (5/5), done.
Delta compression using up to 2 threads
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 317 bytes | 317.00 KiB/s, done.
Total 3 (delta 2), reused 0 (delta 0)
remote: Resolving deltas: 100% (2/2)
To https://source.developers.google.com/p/qwiklabs-gcp-00-90db9ea27409/r/devops-repo
   f774936..063da15  master -> master
student_00_f82b8b5f83e7@cloudshell:~/gcp-course/devops-repo (qwiklabs-gcp-00-90db9ea27409)$

063da15315ecaeee1e9baeaf5b8f595f7fa9780e
build -t gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e .

gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e

gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e 




gcloud auth list


gcloud config list project

gcloud compute instances create gcelab2 --machine-type n1-standard-2 --zone us-central1-c

gcloud config get-value compute/zone
gcloud config get-value compute/region
gcloud compute project-info describe --project qwiklabs-gcp-00-85a0a8114378

gcloud compute instances create gcelab2 --machine-type n1-standard-2 --zone $ZONE


gcloud config set compute/zone us-central1-a

gcloud container clusters create my-cluster

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters create my-cluster
WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster my-cluster in us-central1-a... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-02-f17e6e96a602/zones/us-central1-a/clusters/my-cluster].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/my-cluster?project=qwiklabs-gcp-02-f17e6e96a602
kubeconfig entry generated for my-cluster.
NAME        LOCATION       MASTER_VERSION   MASTER_IP     MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
my-cluster  us-central1-a  1.18.16-gke.302  34.121.78.52  e2-medium     1.18.16-gke.302  3          RUNNING
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters get-credentials my-cluster
Fetching cluster endpoint and auth data.
kubeconfig entry generated for my-cluster.
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0
deployment.apps/hello-server created
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl expose deployment hello-server --type=LoadBalancer --port 8080
service/hello-server exposed
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
hello-server   LoadBalancer   10.3.251.101   <pending>     8080:32398/TCP   14s
kubernetes     ClusterIP      10.3.240.1     <none>        443/TCP          2m52s
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
hello-server   LoadBalancer   10.3.251.101   34.70.133.95   8080:32398/TCP   41s
kubernetes     ClusterIP      10.3.240.1     <none>         443/TCP          3m19s
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$


gcloud container clusters delete my-cluster

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters delete my-cluster
The following clusters will be deleted.
 - [my-cluster] in [us-central1-a]

Do you want to continue (Y/n)?  y

Deleting cluster my-cluster...done.
Deleted [https://container.googleapis.com/v1/projects/qwiklabs-gcp-02-f17e6e96a602/zones/us-central1-a/clusters/my-cluster].
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

In Cloud Shell, set the default zone:

gcloud config set compute/zone us-central1-a

Set the default region:

gcloud config set compute/region us-central1



    Create three new virtual machines in your default zone and give them all the same tag. The code provided sets the zone to us-central1-a. Setting the tags field lets you reference these instances all at once, such as with a firewall rule. These commands also install Apache on each instance and give each instance a unique home page.

gcloud compute instances create www1 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www1</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances create www2 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www2</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances create www3 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www3</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances list
tudent_00_2e86c9330f72@cloudshell:~ (qwiklabs-gcp-00-52ffa2e76b63)$ gcloud compute instances list
NAME  ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP     STATUS
www1  us-central1-a  n1-standard-1               10.128.0.2   34.123.14.179   RUNNING
www2  us-central1-a  n1-standard-1               10.128.0.3   35.225.110.197  RUNNING
www3  us-central1-a  n1-standard-1               10.128.0.4   35.193.225.168  RUNNING
student_00_2e86c9330f72@cloudshell:~ (qwiklabs-gcp-00-52ffa2e76b63)$




    First, create the load balancer template:

gcloud compute instance-templates create lb-backend-template \
   --region=us-central1 \
   --network=default \
   --subnet=default \
   --tags=allow-health-check \
   --image-family=debian-9 \
   --image-project=debian-cloud \
   --metadata=startup-script='#! /bin/bash
     apt-get update
     apt-get install apache2 -y
     a2ensite default-ssl
     a2enmod ssl
     vm_hostname="$(curl -H "Metadata-Flavor:Google" \
     http://169.254.169.254/computeMetadata/v1/instance/name)"
     echo "Page served from: $vm_hostname" | \
     tee /var/www/html/index.html
     systemctl restart apache2'
	 
	 
	 34.117.170.104
	 
	 
	 ARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster nucleus-webserver1 in us-east1-b... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-a9230877c3b8/zones/us-east1-b/clusters/nucleus-webserver1].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-b/nucleus-webserver1?project=qwiklabs-gcp-00-a9230877c3b8
kubeconfig entry generated for nucleus-webserver1.
NAME                LOCATION    MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
nucleus-webserver1  us-east1-b  1.18.16-gke.502  34.73.125.163  e2-medium     1.18.16-gke.502  3          RUNNING

student_00_8a28695a7131@cloudshell:~ (qwiklabs-gcp-00-a9230877c3b8)$ kubectl get service
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)          AGE
hello-app    LoadBalancer   10.119.247.38   35.231.85.25   8080:31562/TCP   44s
kubernetes   ClusterIP      10.119.240.1    <none>         443/TCP          2m31s
student_00_8a28695a7131@cloudshell:~ (qwiklabs-gcp-00-a9230877c3b8)$





gcloud compute networks create managementnet --project=qwiklabs-gcp-01-3e49a9834b0c --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-01-3e49a9834b0c --range=10.130.0.0/20 --network=managementnet --region=us-central1


kubeconfig entry generated for bootcamp.
NAME      LOCATION       MASTER_VERSION   MASTER_IP       MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
bootcamp  us-central1-a  1.18.16-gke.502  35.238.109.114  e2-medium     1.18.16-gke.502  5          RUNNING
student_01_133a2027419a@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-01-2ac127202402)$ kubectl get services frontend
NAME       TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)         AGE
frontend   LoadBalancer   10.115.245.182   34.66.211.255   443:31384/TCP   47s


NAME  LOCATION       MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
io    us-central1-b  1.18.16-gke.502  34.70.253.157  e2-medium     1.18.16-gke.502  3          RUNNING
student_04_5e78fc7ffc81@cloudshell:~ (qwiklabs-gcp-04-a83a0e5ac5d0)$

student_04_5e78fc7ffc81@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-04-a83a0e5ac5d0)$ kubectl get services
NAME         TYPE           CLUSTER-IP    EXTERNAL-IP    PORT(S)        AGE
kubernetes   ClusterIP      10.3.240.1    <none>         443/TCP        3m8s
nginx        LoadBalancer   10.3.242.44   34.68.26.164   80:30484/TCP   38s


student_00_1c72a9e81e1f@cloudshell:~/continuous-deployment-on-kubernetes (qwiklabs-gcp-00-9d3c450fc854)$ gcloud container clusters create jenkins-cd \
> --num-nodes 2 \
> --machine-type n1-standard-2 \
> --scopes "https://www.googleapis.com/auth/source.read_write,cloud-platform"
WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster jenkins-cd in us-east1-d... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-9d3c450fc854/zones/us-east1-d/clusters/jenkins-cd].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-d/jenkins-cd?project=qwiklabs-gcp-00-9d3c450fc854
kubeconfig entry generated for jenkins-cd.
NAME        LOCATION    MASTER_VERSION   MASTER_IP      MACHINE_TYPE   NODE_VERSION     NUM_NODES  STATUS
jenkins-cd  us-east1-d  1.18.16-gke.502  35.185.79.186  n1-standard-2  1.18.16-gke.502  2          RUNNING
student_00_1c72a9e81e1f@cloudshell:~/continuous-deployment-on-kubernetes (qwiklabs-gcp-00-9d3c450fc854)$



v0.2: digest: sha256:59f9514843d9ce75952b5cd8a090da2ca9b904f637d13498cf2678683e5aae9e size: 3055
DONE
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                 STATUS
9c2cb2ab-4007-43f7-a209-ff30b0ae5fdd  2021-04-14T14:08:53+00:00  47S       gs://qwiklabs-gcp-02-8b7c885c17da_cloudbuild/source/1618409331.045144-be8608a756d14c8289c69f5fb6278d3c.tgz  gcr.io/qwiklabs-gcp-02-8b7c885c17da/devops-image:v0.2  SUCCESS


tudent_02_2c0074e6de54@cloudshell:~/gcp-course/training-data-analyst/courses/design-process/deploying-apps-to-gcp (qwiklabs-gcp-02-8b7c885c17da)$ kubectl get services
NAME                   TYPE           CLUSTER-IP   EXTERNAL-IP    PORT(S)        AGE
devops-deployment-lb   LoadBalancer   10.8.10.6    34.72.68.169   80:31410/TCP   40s
kubernetes             ClusterIP      10.8.0.1     <none>         443/TCP        11m
student_02_2c0074e6de54@cloudshell:~/gcp-course/training-data-analyst/courses/design-process/deploying-apps-to-gcp (qwiklabs-gcp-02-8b7c885c17da)$

v0.1: digest: sha256:4012de105d001335e963023529b74f006d39ebaf0f292f477309a26c3c885f8d size: 3055
DONE
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ID                                    CREATE_TIME                DURATION  SOURCE                                                                                            
          IMAGES                                                    STATUS
345d4a76-8d14-4cd0-bba7-434b84dde254  2021-04-14T14:12:26+00:00  48S       gs://qwiklabs-gcp-02-8b7c885c17da_cloudbuild/source/1618409544.623512-f2008ebae4634532a40ad73fd3fa
0157.tgz  

gcr.io/qwiklabs-gcp-02-8b7c885c17da/cloud-run-image:v0.1  SUCCESS


ab -n 1000 -c 10 https://qwiklabs-gcp-04-569634929eae.appspot.com/


ab -n 1000 -c 10 https://<your-project-id>.appspot.com/





Task 1: Create a project jumphost instance

Navigation menu > Compute engine > VM Instance


Task 2: Create a Kubernetes service cluster

gcloud config set compute/zone us-east1-b

gcloud container clusters create nucleus-webserver1

gcloud container clusters get-credentials nucleus-webserver1

kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:2.0

kubectl expose deployment hello-app --type=LoadBalancer --port 8080

kubectl get service 


Task 3: Setup an HTTP load balancer

cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF

cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF


1 .Create an instance template :

gcloud compute instance-templates create nginx-template \
--metadata-from-file startup-script=startup.sh

2 .Create a target pool :

gcloud compute target-pools create nginx-pool

3 .Create a managed instance group :

gcloud compute instance-groups managed create nginx-group \
--base-instance-name nginx \
--size 2 \
--template nginx-template \
--target-pool nginx-pool

gcloud compute instances list

4 .Create a firewall rule to allow traffic (80/tcp) :

gcloud compute firewall-rules create www-firewall --allow tcp:80

gcloud compute forwarding-rules create nginx-lb \
--region us-east1 \
--ports=80 \
--target-pool nginx-pool

gcloud compute forwarding-rules list

5 .Create a health check :

gcloud compute http-health-checks create http-basic-check

gcloud compute instance-groups managed \
set-named-ports nginx-group \
--named-ports http:80

6 .Create a backend service and attach the manged instance group :

gcloud compute backend-services create nginx-backend \
--protocol HTTP --http-health-checks http-basic-check --global

gcloud compute backend-services add-backend nginx-backend \
--instance-group nginx-group \
--instance-group-zone us-east1-b \
--global

7 .Create a URL map and target HTTP proxy to route requests to your URL map :

gcloud compute url-maps create web-map \
--default-service nginx-backend

gcloud compute target-http-proxies create http-lb-proxy \
--url-map web-map

8 .Create a forwarding rule :

gcloud compute forwarding-rules create http-content-rule \
--global \
--target-http-proxy http-lb-proxy \
--ports 80

gcloud compute forwarding-rules list



gcloud compute zones list
gcloud compute zones list | grep us-central1
gcloud config set compute/zone us-central1-b

gcloud compute instances create "my-vm-2" \
--machine-type "n1-standard-1" \
--image-project "debian-cloud" \
--image "debian-9-stretch-v20190213" \
--subnet "default"

student_01_e85d9095ca4e@cloudshell:~ (qwiklabs-gcp-01-777266d3e9f3)$
student_01_e85d9095ca4e@cloudshell:~ (qwiklabs-gcp-01-777266d3e9f3)$ gcloud compute instances create "my-vm-2" \
> --machine-type "n1-standard-1" \
> --image-project "debian-cloud" \
> --image "debian-9-stretch-v20190213" \
> --subnet "default"
Created [https://www.googleapis.com/compute/v1/projects/qwiklabs-gcp-01-777266d3e9f3/zones/us-central1-b/instances/my-vm-2].
WARNING: Some requests generated warnings:
 - The resource 'projects/debian-cloud/global/images/debian-9-stretch-v20190213' is deprecated. A suggested replacement is 'projects/debian-cloud/global/images/debian-9-s
tretch-v20190312'.
NAME     ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP    STATUS
my-vm-2  us-central1-b  n1-standard-1               10.128.0.3   35.222.20.187  RUNNING
student_01_e85d9095ca4e@cloudshell:~ (qwiklabs-gcp-01-777266d3e9f3)$


gcloud compute instances create "my-vm-2" \
> --machine-type "n1-standard-1" \
> --image-project "debian-cloud" \
> --image "debian-9-stretch-v20190213" \
> --subnet "default"


https://niyander.blogspot.com/2020/09/Big%20Data%20and%20Machine%20Learning%20quiz%20answer.html

gcr.io/qwiklabs-gcp-03-fce10dd0479b/devops-repo:ef1495a72524d4fffd9565ab18a3ad9cbcd67f5e 

gcr.io/qwiklabs-gcp-03-fce10dd0479b/devops-image:v0.1
gcr.io/qwiklabs-gcp-03-fce10dd0479b/devops-repo:535d3491a6ba8ba9548afb3a9d6e4715083eb5e7
https://console.cloud.google.com/cloud-build/builds;region=global/0a4309ee-443d-4b1d-b719-b0000162738d;step=0?authuser=2&project=qwiklabs-gcp-03-fce10dd0479b




gcr.io/qwiklabs-gcp-03-2e2100e07441/devops-image:v0.2


35.193.236.52

qwiklabs-gcp-01-50186c5937d1:us-central1:blog-db
34.121.15.242

https://storage.googleapis.com/qwiklabs-gcp-01-50186c5937d1/my-excellent-blog.png

sed -i -e "s/qwiklabs-gcp-04-3515a53d80b0/$DEVSHELL_PROJECT_ID/" mydeploy.yaml

sed -i -e "s/PROJECT_ID/$DEVSHELL_PROJECT_ID/" mydeploy.yaml

sed -i -e "s/ZONE/$MY_ZONE/" mydeploy.yaml

dd if=/dev/urandom | gzip -9 >> /dev/null &

This Linux pipeline forces the CPU to work on compressing a continuous stream of random data.

gsutil mb gs://<my-storage-bucket1380>


Admin user
user
Admin password (Temporary)
E6MkKSVMjfyF

gcloud compute --project=qwiklabs-gcp-01-5700098d951f firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,icmp --source-ranges=0.0.0.0/0


gcloud compute --project=qwiklabs-gcp-01-5700098d951f firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0

gcloud beta compute --project=qwiklabs-gcp-01-5700098d951f instances create managementnet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=631874837590-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210217 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any


gcloud compute instances list --sort-by=ZONE
NAME                 ZONE            MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP     STATUS
mynet-eu-vm          europe-west1-c  n1-standard-1               10.132.0.2   130.211.102.89  RUNNING
managementnet-us-vm  us-central1-c   f1-micro                    10.130.0.2   34.121.160.164  RUNNING
mynet-us-vm          us-central1-c   n1-standard-1               10.128.0.2   35.222.145.135  RUNNING
privatenet-us-vm     us-central1-c   f1-micro                    172.16.0.2   34.123.9.194    RUNNING
student_01_feb12fb61313@cloudshell:~ (qwiklabs-gcp-01-5700098d951f)$


my-storage-bucket138012

gsutil cp gs://cloud-training/gcpnet/private/access.svg gs://my-storage-bucket138012

gsutil cp gs://my-storage-bucket138012/*.svg .

gsutil ls gs://my-storage-bucket138012

gsutil cp gs://my-storage-bucket1380122/sample.txt .


myproj-155a26

myproj-c197c
export BUCKET_NAME_1=155a26_bucket

decryption
VaSql+KA6+0b+IV+H13IxBoiit2RbOvVaeAUNs6zdpg=

45gBD+wmAoFgjAWI5RXUY9Pb1JN7QP3FCFt61ZoRS1w=


student_04_84e0100ca6ed@cloudshell:~ (qwiklabs-gcp-04-155a262b192b)$ gsutil ls -a gs://$BUCKET_NAME_1/setup.html
gs://myproj-155a26/setup.html#1614230131009289
gs://myproj-155a26/setup.html#1614231129184244
gs://myproj-155a26/setup.html#1614231153790239

export VERSION_NAME=gs://myproj-155a26/setup.html#1614230131009289

vpn-2-static-ip
34.76.178.85

vpn-1-static-ip
34.72.18.250
gcprocks

HTTP	35.244.196.221:80	Premium
HTTP	[2600:1901:0:1cb5::]:80	Premium



nPzgN+q/8Y2StdzUkigPn1PGA5+pGSIP

dcHnYIjjzvYo0ClUZTfRMRkJtP7vEsst


gcloud compute target-vpn-gateways create vpn-1 --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --network=vpn-network-1

gcloud compute forwarding-rules create vpn-1-rule-esp --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --address=34.72.18.250 --ip-protocol=ESP --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp500 --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --address=34.72.18.250 --ip-protocol=UDP --ports=500 --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp4500 --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --address=34.72.18.250 --ip-protocol=UDP --ports=4500 --target-vpn-gateway=vpn-1

gcloud compute vpn-tunnels create tunnel1to2 --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --peer-address=35.229.93.165 --shared-secret=NZDG0LhMlTGTI9twTwPw6zmTeBtmm68e --ike-version=1 --local-traffic-selector=0.0.0.0/0 --remote-traffic-selector=0.0.0.0/0 --target-vpn-gateway=vpn-1

gcloud compute routes create tunnel1to2-route-1 --project=qwiklabs-gcp-04-75c147194c21 --network=vpn-network-1 --priority=1000 --destination-range=10.1.3.0/24 --next-hop-vpn-tunnel=tunnel1to2 --next-hop-vpn-tunnel-region=us-central1



resources:
# Create the auto-mode network
- name: mynetwork
  type: compute.v1.network
  properties:
    autoCreateSubnetworks: true

# Create the firewall rule
- name: mynetwork-allow-http-ssh-rdp-icmp
  type: compute.v1.firewall
  properties:
    network: $(ref.mynetwork.selfLink)
    sourceRanges: ["0.0.0.0/0"]
    allowed:
    - IPProtocol: TCP
      ports: [22, 80, 3389]
    - IPProtocol: ICMP
	
	
variable "instance_name" {}
variable "instance_zone" {}
variable "instance_type" {
  default = "n1-standard-1"
  }
variable "instance_network" {}

resource "google_compute_instance" "vm_instance" {
  name         = "${var.instance_name}"
  zone         = "${var.instance_zone}"
  machine_type = "${var.instance_type}"
  boot_disk {
    initialize_params {
      image = "debian-cloud/debian-9"
      }
  }
  network_interface {
    network = "${var.instance_network}"
    access_config {
      # Allocate a one-to-one NAT IP to the instance
    }
  }
}

kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:2.0

gcloud container clusters get-credentials my-cluster
kubectl expose deployment hello-app --type=LoadBalancer --port 8080

kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0

Create a cluster (in the us-east1-b zone) to host the service.
Use the Docker container hello-app (gcr.io/google-samples/hello-app:2.0) as a place holder; the team will replace the container with their own work later.
Expose the app on port 8080.

gcr.io/google-samples/hello-app:2.0)

us-east1-b

Create an instance template.
Create a target pool.
Create a managed instance group.
Create a firewall rule to allow traffic (80/tcp).
Create a health check.
Create a backend service, and attach the managed instance group.
Create a URL map, and target the HTTP proxy to route requests to your URL map.
Create a forwarding rule.

gcloud compute instances create nginx1 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
 apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html"
	
gcloud compute instances create nginx2 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
 apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html"

gcloud compute firewall-rules create www-firewall-network-lb \
    --target-tags network-lb-tag --allow tcp:80
	
	
gcloud compute networks create managementnet --project=qwiklabs-gcp-03-637d4d885e32 --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-03-637d4d885e32 --range=10.130.0.0/20 --network=managementnet --region=us-central1

gcloud compute --project=qwiklabs-gcp-03-637d4d885e32 firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0

gcloud beta compute --project=qwiklabs-gcp-03-637d4d885e32 instances create managementnet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=844965241571-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210217 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any


student_02_9985c7b9d67a@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-02-eb3cb8fca754)$ kubectl get services frontend
NAME       TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)         AGE
frontend   LoadBalancer   10.115.249.14   34.67.56.157   443:30698/TCP   65s


docker pull gcr.io/qwiklabs-gcp-01-200aad9a20ed/node-app:0.2
docker run -p 4000:80 -d gcr.io/qwiklabs-gcp-01-200aad9a20ed/node-app:0.2
curl http://localhost:4000

student_01_e1239e502c7d@cloudshell:~ (qwiklabs-gcp-01-b7642adaec72)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
hello-server   LoadBalancer   10.3.254.128   35.184.224.3   8080:31200/TCP   44s
kubernetes     ClusterIP      10.3.240.1     <none>         443/TCP          3m50s
student_01_e1239e502c7d@cloudshell:~ (qwiklabs-gcp-01-b7642adaec72)$



gcloud compute instance-groups managed set-named-ports nginx-group --named-ports http:80

 --------------------Set up and Configure a Cloud Environment in Google Cloud: Challenge Lab:--------------



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

----------------Task 1: Create development VPC manually--------------------

For this task because it is mentioned to develop manually .....
We will perform it manually



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

--------------Task 2: Create production VPC using Deployment Manager--------


gsutil cp -r gs://cloud-training/gsp321/dm .

cd dm

sed -i s/SET_REGION/us-east1/g prod-network.yaml

gcloud deployment-manager deployments create prod-network \
    --config=prod-network.yaml

cd ..


##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

-------------Task 3: Create bastion host----------------------------------------

You can copy the below three commands at a time and run them on the Cloud shell.------

gcloud compute instances create bastion --network-interface=network=griffin-dev-vpc,subnet=griffin-dev-mgmt  --network-interface=network=griffin-prod-vpc,subnet=griffin-prod-mgmt --tags=ssh --zone=us-east1-b

gcloud compute firewall-rules create fw-ssh-dev --source-ranges=0.0.0.0/0 --target-tags ssh --allow=tcp:22 --network=griffin-dev-vpc

gcloud compute firewall-rules create fw-ssh-prod --source-ranges=0.0.0.0/0 --target-tags ssh --allow=tcp:22 --network=griffin-prod-vpc




##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
-------------Task 4: Create and configure Cloud SQL Instance-----------------------

gcloud sql instances create griffin-dev-db --root-password password --region=us-east1

gcloud sql connect griffin-dev-db


sql commands:---
CREATE DATABASE wordpress;
GRANT ALL PRIVILEGES ON wordpress.* TO "wp_user"@"%" IDENTIFIED BY "stormwind_rules";
FLUSH PRIVILEGES;



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
--------------Task 5: Create Kubernetes cluster-------------------------------------

gcloud container clusters create griffin-dev \
  --network griffin-dev-vpc \
  --subnetwork griffin-dev-wp \
  --machine-type n1-standard-4 \
  --num-nodes 2  \
  --zone us-east1-b

ubeconfig entry generated for griffin-dev.
NAME         LOCATION    MASTER_VERSION    MASTER_IP      MACHINE_TYPE   NODE_VERSION      NUM_NODES  STATUS
griffin-dev  us-east1-b  1.18.12-gke.1210  35.231.154.14  n1-standard-4  1.18.12-gke.1210  2          RUNNING
student_01_9e99e6b73110@cloudshell:~ (qwiklabs-gcp-01-28fbed30f737)$

gcloud container clusters get-credentials griffin-dev --zone us-east1-b

cd ~/


##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
---------------------------------Task 6 ,7, 8------------------------------------

gsutil cp -r gs://cloud-training/gsp321/wp-k8s .

cd wp-k8s

sed -i s/username_goes_here/wp_user/g wp-env.yaml

sed -i s/password_goes_here/stormwind_rules/g wp-env.yaml

----------------------------------------------------------------------------------

kubectl create -f wp-env.yaml

gcloud iam service-accounts keys create key.json --iam-account=cloud-sql-proxy@$GOOGLE_CLOUD_PROJECT.iam.gserviceaccount.com

kubectl create secret generic cloudsql-instance-credentials --from-file key.json

----------------------------------------------------------------------------------


I=$(gcloud sql instances describe griffin-dev-db --format="value(connectionName)")

sed -i s/YOUR_SQL_INSTANCE/$I/g wp-deployment.yaml

kubectl create -f wp-deployment.yaml

kubectl create -f wp-service.yaml


thanks :)
##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

MY_BUCKET_NAME_1=my_storage
MY_BUCKET_NAME_2=my_storage_2
MY_REGION=us-central1

Created [https://www.googleapis.com/compute/v1/projects/qwiklabs-gcp-00-cfe3de25623f/zones/us-central1-c/instances/second-vm].
NAME       ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP     STATUS
second-vm  us-central1-c  e2-standard-2               10.128.0.3   146.148.52.169  RUNNING
student_00_2f9893063cc6@cloudshell:~ (qwiklabs-gcp-00-cfe3de25623f)$ gcloud compute instances list
NAME       ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP      STATUS
first-vm   us-central1-c  e2-micro                    10.128.0.2   104.197.222.196  RUNNING
second-vm  us-central1-c  e2-standard-2               10.128.0.3   146.148.52.169   RUNNING
student_00_2f9893063cc6@cloudshell:~ (qwiklabs-gcp-00-cfe3de25623f)$ gcloud iam service-accounts create test-service-account2 --display-name "test-service-account2"
Created service account [test-service-account2].



gcloud compute instances create "my-vm-2" \
--machine-type "n1-standard-1" \
--image-project "debian-cloud" \
--image-family "debian-10" \
--subnet "default"



student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$ gcloud container clusters create webfrontend --zone $MY_ZONE --num-nodes 2

WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster webfrontend in us-central1-a... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-fe66d4e862ba/zones/us-central1-a/clusters/webfrontend].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/webfrontend?project=qwiklabs-gcp-00-fe66d4e862ba
kubeconfig entry generated for webfrontend.
NAME         LOCATION       MASTER_VERSION   MASTER_IP       MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
webfrontend  us-central1-a  1.18.16-gke.302  34.123.157.157  e2-medium     1.18.16-gke.302  2          RUNNING
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$

104.154.203.125


nginx        LoadBalancer   10.51.245.111   <pending>     80:31011/TCP   42s
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$ kubectl get services
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP       PORT(S)        AGE
kubernetes   ClusterIP      10.51.240.1     <none>            443/TCP        8m28s
nginx        LoadBalancer   10.51.245.111   104.154.203.125   80:31011/TCP   45s

VPC Networking

gcloud compute networks create managementnet --project=qwiklabs-gcp-03-d0417a0df52c --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-03-d0417a0df52c --range=10.130.0.0/20 --network=managementnet --region=us-central1


gcloud compute networks create privatenet --subnet-mode=custom

gcloud compute networks subnets create privatesubnet-us --network=privatenet --region=us-central1 --range=172.16.0.0/24

gcloud compute networks subnets create privatesubnet-eu --network=privatenet --region=europe-central2 --range=172.20.0.0/20

gcloud compute networks list


gcloud compute networks subnets list --sort-by=NETWORK

gcloud compute --project=qwiklabs-gcp-03-d0417a0df52c firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0


gcloud compute firewall-rules create privatenet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=privatenet --action=ALLOW --rules=icmp,tcp:22,tcp:3389 --source-ranges=0.0.0.0/0


gcloud beta compute --project=qwiklabs-gcp-03-d0417a0df52c instances create managementnet-us-vm --zone=us-central1-c --machine-type=n1-standard-1 --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=378953624177-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210316 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any



gcloud compute instances create privatenet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=privatesubnet-us --image-family=debian-10 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-standard --boot-disk-device-name=privatenet-us-vm



gcloud compute instances list --sort-by=ZONE



Implement Private Google Access and Cloud NAT

To connect to vm-internal, run the following command:

gcloud compute ssh vm-internal --zone us-central1-c --tunnel-through-iap


mybucket13806

gsutil cp gs://cloud-training/gcpnet/private/access.svg gs://mybucket13806

gsutil cp gs://mybucket13806/*.svg .



export SQL_CONNECTION=qwiklabs-gcp-03-a61351f94ea3:us-central1:wordpress-db

10.63.240.2
34.68.23.74

qwiklabs-gcp-04-storecore21778f3f0b95

qwiklabs-gcp-04-storecorede0347cd46b4

mybucket21778f3f0b95

Tr+QuUvSSilbpelcDDT+TfkrIQlnEgwZDdcjfh+j1vI=

+lrNHeRNQ4VMiL1iRDVWfQKQU/ddUs0y17jboebzZbs=

export BUCKET_NAME_1=storecore21778f3f0b95


peering network
gcloud compute target-vpn-gateways create vpn-1 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --network=vpn-network-1

gcloud compute forwarding-rules create vpn-1-rule-esp --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=ESP --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp500 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=UDP --ports=500 --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp4500 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=UDP --ports=4500 --target-vpn-gateway=vpn-1

gcloud compute vpn-tunnels create vpn-1-tunnel-1 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --peer-address=35.233.6.236 --shared-secret=gcprocks --ike-version=2 --local-traffic-selector=0.0.0.0/0 --remote-traffic-selector=0.0.0.0/0 --target-vpn-gateway=vpn-1

gcloud compute routes create vpn-1-tunnel-1-route-1 --project=qwiklabs-gcp-00-9353e3a9e4af --network=vpn-network-1 --priority=1000 --destination-range=10.1.3.0/24 --next-hop-vpn-tunnel=vpn-1-tunnel-1 --next-hop-vpn-tunnel-region=us-central1



gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-image:v0.1

student_00_f82b8b5f83e7@cloudshell:~/gcp-course/devops-repo (qwiklabs-gcp-00-90db9ea27409)$ git push origin master
Enumerating objects: 5, done.
Counting objects: 100% (5/5), done.
Delta compression using up to 2 threads
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 317 bytes | 317.00 KiB/s, done.
Total 3 (delta 2), reused 0 (delta 0)
remote: Resolving deltas: 100% (2/2)
To https://source.developers.google.com/p/qwiklabs-gcp-00-90db9ea27409/r/devops-repo
   f774936..063da15  master -> master
student_00_f82b8b5f83e7@cloudshell:~/gcp-course/devops-repo (qwiklabs-gcp-00-90db9ea27409)$

063da15315ecaeee1e9baeaf5b8f595f7fa9780e
build -t gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e .

gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e

gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e 




gcloud auth list


gcloud config list project

gcloud compute instances create gcelab2 --machine-type n1-standard-2 --zone us-central1-c

gcloud config get-value compute/zone
gcloud config get-value compute/region
gcloud compute project-info describe --project qwiklabs-gcp-00-85a0a8114378

gcloud compute instances create gcelab2 --machine-type n1-standard-2 --zone $ZONE


gcloud config set compute/zone us-central1-a

gcloud container clusters create my-cluster

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters create my-cluster
WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster my-cluster in us-central1-a... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-02-f17e6e96a602/zones/us-central1-a/clusters/my-cluster].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/my-cluster?project=qwiklabs-gcp-02-f17e6e96a602
kubeconfig entry generated for my-cluster.
NAME        LOCATION       MASTER_VERSION   MASTER_IP     MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
my-cluster  us-central1-a  1.18.16-gke.302  34.121.78.52  e2-medium     1.18.16-gke.302  3          RUNNING
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters get-credentials my-cluster
Fetching cluster endpoint and auth data.
kubeconfig entry generated for my-cluster.
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0
deployment.apps/hello-server created
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl expose deployment hello-server --type=LoadBalancer --port 8080
service/hello-server exposed
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
hello-server   LoadBalancer   10.3.251.101   <pending>     8080:32398/TCP   14s
kubernetes     ClusterIP      10.3.240.1     <none>        443/TCP          2m52s
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
hello-server   LoadBalancer   10.3.251.101   34.70.133.95   8080:32398/TCP   41s
kubernetes     ClusterIP      10.3.240.1     <none>         443/TCP          3m19s
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$


gcloud container clusters delete my-cluster

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters delete my-cluster
The following clusters will be deleted.
 - [my-cluster] in [us-central1-a]

Do you want to continue (Y/n)?  y

Deleting cluster my-cluster...done.
Deleted [https://container.googleapis.com/v1/projects/qwiklabs-gcp-02-f17e6e96a602/zones/us-central1-a/clusters/my-cluster].
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

In Cloud Shell, set the default zone:

gcloud config set compute/zone us-central1-a

Set the default region:

gcloud config set compute/region us-central1



    Create three new virtual machines in your default zone and give them all the same tag. The code provided sets the zone to us-central1-a. Setting the tags field lets you reference these instances all at once, such as with a firewall rule. These commands also install Apache on each instance and give each instance a unique home page.

gcloud compute instances create www1 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www1</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances create www2 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www2</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances create www3 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www3</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances list
tudent_00_2e86c9330f72@cloudshell:~ (qwiklabs-gcp-00-52ffa2e76b63)$ gcloud compute instances list
NAME  ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP     STATUS
www1  us-central1-a  n1-standard-1               10.128.0.2   34.123.14.179   RUNNING
www2  us-central1-a  n1-standard-1               10.128.0.3   35.225.110.197  RUNNING
www3  us-central1-a  n1-standard-1               10.128.0.4   35.193.225.168  RUNNING
student_00_2e86c9330f72@cloudshell:~ (qwiklabs-gcp-00-52ffa2e76b63)$




    First, create the load balancer template:

gcloud compute instance-templates create lb-backend-template \
   --region=us-central1 \
   --network=default \
   --subnet=default \
   --tags=allow-health-check \
   --image-family=debian-9 \
   --image-project=debian-cloud \
   --metadata=startup-script='#! /bin/bash
     apt-get update
     apt-get install apache2 -y
     a2ensite default-ssl
     a2enmod ssl
     vm_hostname="$(curl -H "Metadata-Flavor:Google" \
     http://169.254.169.254/computeMetadata/v1/instance/name)"
     echo "Page served from: $vm_hostname" | \
     tee /var/www/html/index.html
     systemctl restart apache2'
	 
	 
	 34.117.170.104
	 
	 
	 ARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster nucleus-webserver1 in us-east1-b... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-a9230877c3b8/zones/us-east1-b/clusters/nucleus-webserver1].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-b/nucleus-webserver1?project=qwiklabs-gcp-00-a9230877c3b8
kubeconfig entry generated for nucleus-webserver1.
NAME                LOCATION    MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
nucleus-webserver1  us-east1-b  1.18.16-gke.502  34.73.125.163  e2-medium     1.18.16-gke.502  3          RUNNING

student_00_8a28695a7131@cloudshell:~ (qwiklabs-gcp-00-a9230877c3b8)$ kubectl get service
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)          AGE
hello-app    LoadBalancer   10.119.247.38   35.231.85.25   8080:31562/TCP   44s
kubernetes   ClusterIP      10.119.240.1    <none>         443/TCP          2m31s
student_00_8a28695a7131@cloudshell:~ (qwiklabs-gcp-00-a9230877c3b8)$





gcloud compute networks create managementnet --project=qwiklabs-gcp-01-3e49a9834b0c --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-01-3e49a9834b0c --range=10.130.0.0/20 --network=managementnet --region=us-central1


kubeconfig entry generated for bootcamp.
NAME      LOCATION       MASTER_VERSION   MASTER_IP       MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
bootcamp  us-central1-a  1.18.16-gke.502  35.238.109.114  e2-medium     1.18.16-gke.502  5          RUNNING
student_01_133a2027419a@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-01-2ac127202402)$ kubectl get services frontend
NAME       TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)         AGE
frontend   LoadBalancer   10.115.245.182   34.66.211.255   443:31384/TCP   47s


NAME  LOCATION       MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
io    us-central1-b  1.18.16-gke.502  34.70.253.157  e2-medium     1.18.16-gke.502  3          RUNNING
student_04_5e78fc7ffc81@cloudshell:~ (qwiklabs-gcp-04-a83a0e5ac5d0)$

student_04_5e78fc7ffc81@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-04-a83a0e5ac5d0)$ kubectl get services
NAME         TYPE           CLUSTER-IP    EXTERNAL-IP    PORT(S)        AGE
kubernetes   ClusterIP      10.3.240.1    <none>         443/TCP        3m8s
nginx        LoadBalancer   10.3.242.44   34.68.26.164   80:30484/TCP   38s


student_00_1c72a9e81e1f@cloudshell:~/continuous-deployment-on-kubernetes (qwiklabs-gcp-00-9d3c450fc854)$ gcloud container clusters create jenkins-cd \
> --num-nodes 2 \
> --machine-type n1-standard-2 \
> --scopes "https://www.googleapis.com/auth/source.read_write,cloud-platform"
WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster jenkins-cd in us-east1-d... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-9d3c450fc854/zones/us-east1-d/clusters/jenkins-cd].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-d/jenkins-cd?project=qwiklabs-gcp-00-9d3c450fc854
kubeconfig entry generated for jenkins-cd.
NAME        LOCATION    MASTER_VERSION   MASTER_IP      MACHINE_TYPE   NODE_VERSION     NUM_NODES  STATUS
jenkins-cd  us-east1-d  1.18.16-gke.502  35.185.79.186  n1-standard-2  1.18.16-gke.502  2          RUNNING
student_00_1c72a9e81e1f@cloudshell:~/continuous-deployment-on-kubernetes (qwiklabs-gcp-00-9d3c450fc854)$



v0.2: digest: sha256:59f9514843d9ce75952b5cd8a090da2ca9b904f637d13498cf2678683e5aae9e size: 3055
DONE
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                 STATUS
9c2cb2ab-4007-43f7-a209-ff30b0ae5fdd  2021-04-14T14:08:53+00:00  47S       gs://qwiklabs-gcp-02-8b7c885c17da_cloudbuild/source/1618409331.045144-be8608a756d14c8289c69f5fb6278d3c.tgz  gcr.io/qwiklabs-gcp-02-8b7c885c17da/devops-image:v0.2  SUCCESS


tudent_02_2c0074e6de54@cloudshell:~/gcp-course/training-data-analyst/courses/design-process/deploying-apps-to-gcp (qwiklabs-gcp-02-8b7c885c17da)$ kubectl get services
NAME                   TYPE           CLUSTER-IP   EXTERNAL-IP    PORT(S)        AGE
devops-deployment-lb   LoadBalancer   10.8.10.6    34.72.68.169   80:31410/TCP   40s
kubernetes             ClusterIP      10.8.0.1     <none>         443/TCP        11m
student_02_2c0074e6de54@cloudshell:~/gcp-course/training-data-analyst/courses/design-process/deploying-apps-to-gcp (qwiklabs-gcp-02-8b7c885c17da)$

v0.1: digest: sha256:4012de105d001335e963023529b74f006d39ebaf0f292f477309a26c3c885f8d size: 3055
DONE
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ID                                    CREATE_TIME                DURATION  SOURCE                                                                                            
          IMAGES                                                    STATUS
345d4a76-8d14-4cd0-bba7-434b84dde254  2021-04-14T14:12:26+00:00  48S       gs://qwiklabs-gcp-02-8b7c885c17da_cloudbuild/source/1618409544.623512-f2008ebae4634532a40ad73fd3fa
0157.tgz  

gcr.io/qwiklabs-gcp-02-8b7c885c17da/cloud-run-image:v0.1  SUCCESS


ab -n 1000 -c 10 https://qwiklabs-gcp-04-569634929eae.appspot.com/


ab -n 1000 -c 10 https://<your-project-id>.appspot.com/




Task 1: Create a project jumphost instance

Navigation menu > Compute engine > VM Instance


Task 2: Create a Kubernetes service cluster

gcloud config set compute/zone us-east1-b

gcloud container clusters create nucleus-webserver1

gcloud container clusters get-credentials nucleus-webserver1

kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:2.0

kubectl expose deployment hello-app --type=LoadBalancer --port 8080

kubectl get service 


Task 3: Setup an HTTP load balancer

cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF

cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF


1 .Create an instance template :

gcloud compute instance-templates create nginx-template \
--metadata-from-file startup-script=startup.sh

2 .Create a target pool :

gcloud compute target-pools create nginx-pool

3 .Create a managed instance group :

gcloud compute instance-groups managed create nginx-group \
--base-instance-name nginx \
--size 2 \
--template nginx-template \
--target-pool nginx-pool

gcloud compute instances list

4 .Create a firewall rule to allow traffic (80/tcp) :

gcloud compute firewall-rules create www-firewall --allow tcp:80

gcloud compute forwarding-rules create nginx-lb \
--region us-east1 \
--ports=80 \
--target-pool nginx-pool

gcloud compute forwarding-rules list

5 .Create a health check :

gcloud compute http-health-checks create http-basic-check

gcloud compute instance-groups managed \
set-named-ports nginx-group \
--named-ports http:80

6 .Create a backend service and attach the manged instance group :

gcloud compute backend-services create nginx-backend \
--protocol HTTP --http-health-checks http-basic-check --global

gcloud compute backend-services add-backend nginx-backend \
--instance-group nginx-group \
--instance-group-zone us-east1-b \
--global

7 .Create a URL map and target HTTP proxy to route requests to your URL map :

gcloud compute url-maps create web-map \
--default-service nginx-backend

gcloud compute target-http-proxies create http-lb-proxy \
--url-map web-map

8 .Create a forwarding rule :

gcloud compute forwarding-rules create http-content-rule \
--global \
--target-http-proxy http-lb-proxy \
--ports 80

gcloud compute forwarding-rules list


Introduction to SQL for BigQuery and Cloud SQL
Add to favorites
Help

25/100
Checkpoints

Create a cloud storage bucket

25 / 25

Upload CSV files to Cloud Storage

0 / 25

Create a Cloud SQL instance

0 / 25

Create a database

0 / 25
Introduction to SQL for BigQuery and Cloud SQL
1 hour 15 minutes Free
GSP281

Google Cloud Self-Paced Labs
Overview

SQL (Structured Query Language) is a standard language for data operations that allows you to ask questions and get insights from structured datasets. It's commonly used in database management and allows you to perform tasks like transaction record writing into relational databases and petabyte-scale data analysis.

This lab serves as an introduction to SQL and is intended to prepare you for the many labs and quests in Qwiklabs on data science topics. This lab is divided into two parts: in the first half, you will learn fundamental SQL querying keywords, which you will run in the BigQuery console on a public dataset that contains information on London bikeshares.

In the second half, you will learn how to export subsets of the London bikeshare dataset into CSV files, which you will then upload to Cloud SQL. From there you will learn how to use Cloud SQL to create and manage databases and tables. Towards the end, you will get hands-on practice with additional SQL keywords that manipulate and edit data.
Objectives

In this lab, you will learn how to:

    Distinguish databases from tables and projects.
    Use the SELECT, FROM, and WHERE keywords to construct simple queries.
    Identify the different components and hierarchies within the BigQuery console.
    Load databases and tables into BigQuery.
    Execute simple queries on tables.
    Learn about the COUNT, GROUP BY, AS, and ORDER BY keywords.
    Execute and chain the above commands to pull meaningful data from datasets.
    Export a subset of data into a CSV file and store that file into a new Cloud Storage bucket.
    Create a new Cloud SQL instance and load your exported CSV file as a new table.
    Run CREATE DATABASE, CREATE TABLE, DELETE, INSERT INTO, and UNION queries in Cloud SQL.

Prerequisites

Very Important: Before starting this lab, log out of your personal or corporate gmail account.

This is a introductory level lab. This assumes little to no prior experience with SQL. Familiarity with Cloud Storage and Cloud Shell is recommended, but not required. This lab will teach you the basics of reading and writing queries in SQL, which you will apply by using BigQuery and Cloud SQL.

Before taking this lab, consider your proficiency in SQL. Below are more challenging labs that will let you apply your knowledge to more advanced use cases:

    Weather Data in BigQuery
    Analyzing Natality Data Using Datalab and BigQuery

Once you're ready, scroll down and follow the steps below to get your lab environment set up.
Setup and Requirements
Before you click the Start Lab button

Read these instructions. Labs are timed and you cannot pause them. The timer, which starts when you click Start Lab, shows how long Google Cloud resources will be made available to you.

This Qwiklabs hands-on lab lets you do the lab activities yourself in a real cloud environment, not in a simulation or demo environment. It does so by giving you new, temporary credentials that you use to sign in and access Google Cloud for the duration of the lab.
What you need

To complete this lab, you need:

    Access to a standard internet browser (Chrome browser recommended).
    Time to complete the lab.

Note: If you already have your own personal Google Cloud account or project, do not use it for this lab.

Note: If you are using a Pixelbook, open an Incognito window to run this lab.
How to start your lab and sign in to the Google Cloud Console

    Click the Start Lab button. If you need to pay for the lab, a pop-up opens for you to select your payment method. On the left is a panel populated with the temporary credentials that you must use for this lab.

    Open Google Console

    Copy the username, and then click Open Google Console. The lab spins up resources, and then opens another tab that shows the Sign in page.

    Sign in

    Tip: Open the tabs in separate windows, side-by-side.
    If you see the Choose an account page, click Use Another Account. Choose an account

    In the Sign in page, paste the username that you copied from the Connection Details panel. Then copy and paste the password.

    Important: You must use the credentials from the Connection Details panel. Do not use your Qwiklabs credentials. If you have your own Google Cloud account, do not use it for this lab (avoids incurring charges).

    Click through the subsequent pages:
        Accept the terms and conditions.
        Do not add recovery options or two-factor authentication (because this is a temporary account).
        Do not sign up for free trials.

After a few moments, the Cloud Console opens in this tab.
Note: You can view the menu with a list of Google Cloud Products and Services by clicking the Navigation menu at the top-left. Cloud Console Menu
The Basics of SQL
Databases and Tables

As mentioned earlier, SQL allows you to get information from "structured datasets". Structured datasets have clear rules and formatting and often times are organized into tables, or data that's formatted in rows and columns.

An example of unstructured data would be an image file. Unstructured data is inoperable with SQL and cannot be stored in BigQuery datasets or tables (at least natively.) To work with image data (for instance), you would use a service like Cloud Vision, perhaps through its API directly.

The following is an example of a structured dataseta simple table:

User
	

Price
	

Shipped

Sean
	

$35
	

Yes

Rocky
	

$50
	

No

If you've had experience with Google Sheets, then the above should look quite similar. As we see, the table has columns for User, Price, and Shipped and two rows that are composed of filled in column values.

A Database is essentially a collection of one or more tables. SQL is a structured database management tool, but quite often (and in this lab) you will be running queries on one or a few tables joined togethernot on whole databases.
SELECT and FROM

SQL is phonetic by nature and before running a query, it's always helpful to first figure out what question you want to ask your data (unless you're just exploring for fun.)

SQL has predefined keywords which you use to translate your question into the pseudo-english SQL syntax so you can get the database engine to return the answer you want.

The most essential keywords are SELECT and FROM:

    Use SELECT to specify what fields you want to pull from your dataset.
    Use FROM to specify what table or tables we want to pull our data from.

An example may help understanding. Assume that we have the following table example_table, which has columns USER, PRICE, and SHIPPED:

14422cb7144f3ae.png

And let's say that we want to just pull the data that's found in the USER column. We can do this by running the following query that uses SELECT and FROM:

SELECT USER FROM example_table

If we executed the above command, we would select all the names from the USER column that are found in example_table.

You can also select multiple columns with the SQL SELECT keyword. Say that you want to pull the data that's found in the USER and SHIPPED columns. To do this, modify the previous query by adding another column value to our SELECT query (making sure it's separated by a comma!):

SELECT USER, SHIPPED FROM example_table

Running the above retrieves the USER and the SHIPPED data from memory:

a4027fb83edf734.png

And just like that you've covered two fundamental SQL keywords! Now to make things a bit more interesting.
WHERE

The WHERE keyword is another SQL command that filters tables for specific column values. Say that you want to pull the names from example_table whose packages were shipped. You can supplement the query with a WHERE, like the following:

SELECT USER FROM example_table WHERE SHIPPED='YES'

Running the above returns all USERs whose packages have been SHIPPED to from memory:

5566150a165277e8.png

Now that you have a baseline understanding of SQL's core keywords, apply what you've learned by running these types of queries in the BigQuery console.
Test your understanding

The following are some multiple choice questions to reinforce your understanding of the concepts covered so far. Answer them to the best of your abilities.

Exploring the BigQuery Console
The BigQuery paradigm

BigQuery is a fully-managed petabyte-scale data warehouse that runs on the Google Cloud. Data analysts and data scientists can quickly query and filter large datasets, aggregate results, and perform complex operations without having to worry about setting up and managing servers. It comes in the form of a command line tool (preinstalled in cloudshell) or a web consoleboth ready for managing and querying data housed in Google Cloud projects.

In this lab, you use the web console to run SQL queries.
Open BigQuery Console

In the Google Cloud Console, select Navigation menu > BigQuery:

BigQuery_menu.png

The Welcome to BigQuery in the Cloud Console message box opens. This message box provides a link to the quickstart guide and the release notes.

Click Done.

The BigQuery console opens.

bq-console.png

Take a moment to note some important features of the UI. The right-hand side of the console houses the query "Editor". This is where you write and run SQL commands like the examples we covered earlier. Below that is "Query history", which is a list of queries you ran previously.

The left pane of the console is the "Navigation panel". Apart from the self-explanatory query history, saved queries, and job history, there is the Explorer tab.

The highest level of resources in Explorer tab contain Google Cloud projects, which are just like the temporary Google Cloud projects you sign in to and use with each Qwiklab. As you can see in your console and in the last screenshot, we only have our Qwiklabs project housed in the Explorer tab. If you try clicking on the arrow next the project name, nothing will show up.

This is because your project doesn't contain any datasets or tables, you have nothing that can be queried. Earlier you learned datasets contain tables. When you add data to your project, note that in BigQuery, projects contain datasets, and datasets contain tables. Now that you better understand the project ? dataset ? table paradigm and the intricacies of the console, you can load up some queryable data.
Uploading queryable data

In this section you pull in some public data into your project so you can practice running SQL commands in BigQuery.

Click on the + ADD DATA link then select Explore public datasets:

BQ_adddata_2.png

In the search bar, enter "london", then select the London Bicycle Hires tile, then View Dataset.

A new tab will open, and you will now have a new project called bigquery-public-data added to the Explorer panel:

BQ_pubdata_2.png

It's important to note that you are still working out of your lab project in this new tab. All you did was pull a publicly accessible project that contains datasets and tables into BigQuery for analysis  you didn't switch over to that project. All of your jobs and services are still tied to your Qwiklabs account. You can see this for yourself by inspecting the project field near the top of the console:

BQ_proj_check_2.png

Expand bigquery-public-data > london_bicycles and select cycle_hire. You now have data that follows the BigQuery paradigm:

    Google Cloud Project ? bigquery-public-data
    Dataset ? london_bicycles
    Table ? cycle_hire

Now that you are in the cycle_hire table, in the center of the console click the Preview tab. Your page should resemble the following:

cycle_hire.png

Inspect the columns and values populated in the rows. You are now ready to run some SQL queries on the cycle_hire table.
Running SELECT, FROM, and WHERE in BigQuery

You now have a basic understanding of SQL querying keywords and the BigQuery data paradigm and some data to work with. Run some SQL commands using this service.

If you look at the bottom right corner of the console, you will notice that there are 24,369,201 rows of data, or individual bikeshare trips taken in London between 2015 and 2017 (not a small amount by any means!)

Now take note of the seventh column key: end_station_name, which specifies the end destination of bikeshare rides. Before we get too deep, let's first run a simple query to isolate the end_station_name column. Copy and paste the following command in to the query EDITOR:

SELECT end_station_name FROM `bigquery-public-data.london_bicycles.cycle_hire`;

Then click Run.

After ~20 seconds, you should be returned with 24369201 rows that contain the single column you queried for: end_station_name.

Why don't you find out how many bike trips were 20 minutes or longer?

Clear the query from the editor, then run the following query that utilizes the WHERE keyword:

SELECT * FROM `bigquery-public-data.london_bicycles.cycle_hire` WHERE duration>=1200;

This query may take a minute or so to run.

SELECT * returns all column values from the table. Duration is measured in seconds, which is why you used the value 1200 (60 * 20).

If you look in the bottom right corner you see that 7,334,890 rows were returned. As a fraction of the total (7334890/24369201), this means that ~30% of London bikeshare rides lasted 20 minutes or longer (they're in it for the long haul!)
Test your understanding

The following are some multiple choice questions to reinforce your understanding of the concepts we've covered so far. Answer them to the best of your abilities.

More SQL Keywords: GROUP BY, COUNT, AS, and ORDER BY
GROUP BY

The GROUP BY keyword will aggregate result-set rows that share common criteria (e.g. a column value) and will return all of the unique entries found for such criteria.

This is a useful keyword for figuring out categorical information on tables. To get a better picture of what this keyword does, clear the query from the editor, then copy and paste the following command:

SELECT start_station_name FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name;

Click Run.

You should receive a similar output (row values may not match the following):

30b04fc6f21c544c.png

Without the GROUP BY, the query would have returned the full 24,369,201 rows. GROUP BY will output the unique (non-duplicate) column values found in the table. You can see this for yourself by looking in the bottom right corner. You will see 880 rows, meaning there are 880 distinct London bikeshare starting points.
COUNT

The COUNT() function will return the number of rows that share the same criteria (e.g. column value). This can be very useful in tandem with a GROUP BY.

Add the COUNT function to our previous query to figure out how many rides begin in each starting point. Clear the query from the editor, then copy and paste the following command and then click Run:

SELECT start_station_name, COUNT(*) FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name;

You should receive a similar output (row values may not match the following):

b62aaf26b7a35e35.png

This shows how many bikeshare rides begin at each starting location.
AS

SQL also has an AS keyword, which creates an alias of a table or column. An alias is a new name that's given to the returned column or tablewhatever AS specifies.

Add an AS keyword to the last query we ran to see this in action. Clear the query from the editor, then copy and paste the following command:

SELECT start_station_name, COUNT(*) AS num_starts FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name;

Click Run.

You should receive a similar output (be aware that the row values might not be identical):

a45a8b122dbfea2b.png

As you see, the COUNT(*) column in the returned table is now set to the alias name num_starts. This is a handy keyword to use especially if you are dealing with large sets of data  forgetting that an ambiguous table or column name happens more often than you think!
ORDER BY

The ORDER BY keyword sorts the returned data from a query in ascending or descending order based on a specified criteria or column value. We will add this keyword to our previous query to do the following:

    Return a table that contains the number of bikeshare rides that begin in each starting station, organized alphabetically by the starting station.
    Return a table that contains the number of bikeshare rides that begin in each starting station, organized numerically from lowest to highest.
    Return a table that contains the number of bikeshare rides that begin in each starting station, organized numerically from highest to lowest.

Each of the commands below is a separate query. For each command, clear the query EDITOR, copy and paste the command in to the query EDITOR, and then click Run. Examine the results.

SELECT start_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name ORDER BY start_station_name;

SELECT start_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name ORDER BY num;

SELECT start_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name ORDER BY num DESC;

The last query should have returned the following:

368742bde0aa54d6.png

We see that "Belgrove Street, King's Cross" has the highest number of starts. However, as a fraction of the total (234458/24369201), we see that < 1% of rides start from this station.
Test your understanding

The following are some multiple choice questions to reinforce your understanding of the concepts we've covered so far. Answer them to the best of your abilities.

Working with Cloud SQL
Exporting queries as CSV files

Cloud SQL is a fully-managed database service that makes it easy to set up, maintain, manage, and administer your relational PostgreSQL and MySQL databases in the cloud. There are two formats of data accepted by Cloud SQL: dump files (.sql) or CSV files (.csv). You will learn how to export subsets of the cycle_hire table into CSV files and upload them to Cloud Storage as an intermediate location.

Back in the BigQuery Console, this should have been the last command that you ran:

SELECT start_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name ORDER BY num DESC;

In the Query Results section click SAVE RESULTS > CSV(local file) > SAVE. This initiates a download, which saves this query as a CSV file. Note the location and the name of this downloaded fileyou will need it soon.

Clear the query EDITOR, then copy and run the following in the query editor:

SELECT end_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY end_station_name ORDER BY num DESC;

This will return a table that contains the number of bikeshare rides that finish in each ending station and is organized numerically from highest to lowest number of rides. You should receive the following output:

814554dc82c60a74.png

In the Query Results section click SAVE RESULTS > CSV(local file) > SAVE. This initiates a download, which saves this query as a CSV file. Note the location and the name of this downloaded fileyou will need it in the following section.
Upload CSV files to Cloud Storage

Go to the Cloud Console where you'll create a storage bucket where you can upload the files you just created.

Select Navigation menu > Storage > Browser, and then click Create bucket.
Note: If prompted, Click LEAVE for Unsaved work.

Enter a unique name for your bucket, keep all other settings, and hit Create:

bucket_details.png
Test Completed Task

Click Check my progress below to check your lab progress. If you successfully created your bucket, you'll see an assessment score.
Create a cloud storage bucket.

You should now be in the Cloud Console looking at your newly created Cloud Storage Bucket.

Click Upload files and select the CSV that contains start_station_name data. Then click Open. Repeat this for the end_station_name data.

Rename your start_station_name file by clicking on the three dots next to on the far side of the file and click rename. Rename the file start_station_data.csv.

Rename your end_station_name file by clicking on the three dots next to on the far side of the file and click rename. Rename the file end_station_data.csv.

Your bucket should now resemble the following:

4ca41c9e381d94f.png
Test Completed Task

Click Check my progress to verify your performed task. If you have successfully upload CSV objects to your bucket, you will see an assessment score.
Upload CSV files to Cloud Storage.
Create a Cloud SQL instance

In the console, select Navigation menu > SQL.

Click Create Instance.

From here, you will be prompted to choose a database engine. Select MySQL.

Now enter in a name for your instance (like "qwiklabs-demo") and enter in a secure password in the Root password field (remember it!), then click CREATE INSTANCE:

CreateInstance.png

It might take a few minutes for the instance to be created. Once it is, you will see a green checkmark next to the instance name.

Click on the Cloud SQL instance. You should now be on a page that resembles the following:

overview.png
Test Completed Task

To check out your lab progress, click Check my progress below.If you have successfully set up your Cloud SQL instance, you will see an assessment score.
Create a CloudSQL Instance.
New Queries in Cloud SQL
CREATE keyword (databases and tables)

Now that you have a Cloud SQL instance up and running, create a database inside of it using the Cloud Shell Command Line.
Activate Cloud Shell

Cloud Shell is a virtual machine that is loaded with development tools. It offers a persistent 5GB home directory and runs on the Google Cloud. Cloud Shell provides command-line access to your Google Cloud resources.

In the Cloud Console, in the top right toolbar, click the Activate Cloud Shell button.

Cloud Shell icon

Click Continue.

cloudshell_continue.png

It takes a few moments to provision and connect to the environment. When you are connected, you are already authenticated, and the project is set to your PROJECT_ID. For example:

Cloud Shell Terminal

gcloud is the command-line tool for Google Cloud. It comes pre-installed on Cloud Shell and supports tab-completion.

You can list the active account name with this command:

gcloud auth list

(Output)

Credentialed accounts:
 - <myaccount>@<mydomain>.com (active)

(Example output)

Credentialed accounts:
 - google1623327_student@qwiklabs.net

You can list the project ID with this command:

gcloud config list project

(Output)

[core]
project = <project_ID>

(Example output)

[core]
project = qwiklabs-gcp-44776a13dea667a6

For full documentation of gcloud see the gcloud command-line tool overview.

Run the following command in Cloud Shell to connect to your SQL instance, replacing qwiklabs-demo if you used a different name for your instance:

gcloud sql connect  qwiklabs-demo --user=root

It may take a minute to connect to your instance.

When prompted, enter the root password you set for the instance.

You should now be on a similar output:

Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 494
Server version: 5.7.14-google-log (Google)

Copyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql>

A Cloud SQL instance comes with pre-configured databases, but you will create your own to store the London bikeshare data.

Run the following command at the MySQL server prompt to create a database called bike:

CREATE DATABASE bike;

You should receive the following output:

Query OK, 1 row affected (0.05 sec)

mysql>

Test Completed Task

Check your progress by clicking Check my progress to verify your performed task. If you have successfully created database in Cloud SQL instance, you will see an assessment score.
Create a database.

Make a table inside of the bike database by running the following command:

USE bike;
CREATE TABLE london1 (start_station_name VARCHAR(255), num INT);

This statement uses the CREATE keyword, but this time it uses the TABLE clause to specify that it wants to build a table instead of a database. The USE keyword specifies a database that you want to connect to. You now have a table named "london1" that contains two columns, "start_station_name" and "num". VARCHAR(255) specifies variable length string column that can hold up to 255 characters and INT is a column of type integer.

Create another table named "london2" by running the following command:

USE bike;
CREATE TABLE london2 (end_station_name VARCHAR(255), num INT);

Now confirm that your empty tables were created. Run the following commands at the MySQL server prompt:

SELECT * FROM london1;
SELECT * FROM london2;

You should receive the following output for both commands:

Empty set (0.04 sec)

It says "empty set" because you haven't loaded in any data yet.
Upload CSV files to tables

Return to the Cloud SQL console. You will now upload the start_station_name and end_station_name CSV files into your newly created london1 and london2 tables.

    In your Cloud SQL instance page, click IMPORT.
    In the Cloud Storage file field, click Browse, and then click the arrow opposite your bucket name, and then click start_station_data.csv. Click Select.
    Select CSV as File format.
    Select the bike database and type in "london1" as your table.
    Click Import:

ImportData

Do the same for the other CSV file.

    In your Cloud SQL instance page, click IMPORT.
    In the Cloud Storage file field, click Browse, and then click the arrow opposite your bucket name, and then click end_station_data.csv Click Select.
    Select CSV as File format.
    Select the bike database and type in "london2" as your table.
    Click Import:

You should now have both CSV files uploaded to tables in the bike database.

Return to your Cloud Shell session and run the following command at the MySQL server prompt to inspect the contents of london1:

SELECT * FROM london1;

You should receive 881 lines of output, one more each unique station name. Your output be formatted like this:

48c3c74603692827.png

Run the following command to make sure that london2 has been populated:

SELECT * FROM london2;

You should receive 883 lines of output, one more each unique station name. Your output be formatted like this:

85a788ec7971f8a0.png
DELETE keyword

Here are a couple more SQL keywords that help us with data management. The first is the DELETE keyword.

Run the following commands in your MySQL session to delete the first row of the london1 and london2:

DELETE FROM london1 WHERE num=0;
DELETE FROM london2 WHERE num=0;

You should receive the following output after running both commands:

Query OK, 1 row affected (0.04 sec)

The rows deleted were the column headers from the CSV files. The DELETE keyword will not remove the first row of the file per se, but all rows of the table where the column name (in this case "num") contains a specified value (in this case "0"). If you run the SELECT * FROM london1; and SELECT * FROM london2; queries and scroll to the top of the table, you will see that those rows no longer exist.
INSERT INTO keyword

You can also insert values into tables with the INSERT INTO keyword. Run the following command to insert a new row into london1, which sets start_station_name to "test destination" and num to "1":

INSERT INTO london1 (start_station_name, num) VALUES ("test destination", 1);

The INSERT INTO keyword requires a table (london1) and will create a new row with columns specified by the terms in the first parenthesis (in this case "start_station_name" and "num"). Whatever comes after the "VALUES" clause will be inserted as values in the new row.

You should receive the following output:

Query OK, 1 row affected (0.05 sec)

If you run the query SELECT * FROM london1; you will see an additional row added at the bottom of the "london1" table:

b067eb36e63b9e68.png
UNION keyword

The last SQL keyword that you'll learn about is UNION. This keyword combines the output of two or more SELECT queries into a result-set. You use UNION to combine subsets of the "london1" and "london2" tables.

The following chained query pulls specific data from both tables and combine them with the UNION operator.

Run the following command at the MySQL server prompt:

SELECT start_station_name AS top_stations, num FROM london1 WHERE num>100000
UNION
SELECT end_station_name, num FROM london2 WHERE num>100000
ORDER BY top_stations DESC;

The first SELECT query selects the two columns from the "london1" table and creates an alias for "start_station_name", which gets set to "top_stations". It uses the WHERE keyword to only pull rideshare station names where over 100,000 bikes start their journey.

The second SELECT query selects the two columns from the "london2" table and uses the WHERE keyword to only pull rideshare station names where over 100,000 bikes end their journey.

The UNION keyword in between combines the output of these queries by assimilating the "london2" data with "london1". Since "london1" is being unioned with "london2", the column values that take precedent are "top_stations" and "num".

ORDER BY will order the final, unioned table by the "top_stations" column value alphabetically and in descending order.

You should receive the following output:

num.png

As you see, 13/14 stations share the top spots for rideshare starting and ending points. With some basic SQL keywords you were able to query a sizable dataset, which returned data points and answers to specific questions.
Congratulations!

In this lab you learned the fundamentals of SQL and how you can apply keywords and run queries in BigQuery and CloudSQL. You were taught the core concepts behind projects, databases, and tables. You practiced with keywords that manipulated and edited data. You learned how to load datasets into BigQuery and you practiced running queries on tables. You learned how to create instances in Cloud SQL and practiced transferring subsets of data into tables contained in databases. You chained and ran queries in Cloud SQL to arrive at some interesting conclusions about London bikesharing starting and ending stations.

quest-badge-two.png Data_Science_125.png cloudsql-quest-badge.png BigQueryBasicsforDataAnalysts-125x135.png MarchMadness02_125.png CloudEngineeringExaPrep_125.pmg Data Catalog Quest Badge.pmg bq_retail_125.png
Finish Your Quest

This self-paced lab is part of the Qwiklabs Quests Data Science on Google Cloud, Scientific Data Processing, Cloud SQL, BigQuery Basics for Data Analysts, NCAA March Madness: Bracketology with Google Cloud, Cloud Engineering, Data Catalog Fundamentals and Applying BQML's Classification, Regression, and Demand Forcastng for Retail Applications. A Quest is a series of related labs that form a learning path. Completing a Quest earns you one of the badges above, to recognize your achievement. You can make your badge (or badges) public and link to them in your online resume or social media account. Enroll in a quest and get immediate completion credit if you've taken this lab. See other available Qwiklabs Quests.
Next Steps / Learn More

Continue your learning with and get more practice with Cloud SQL and BigQuery:

    Weather Data in BigQuery
    Exploring NCAA Data with BigQuery
    Loading Data into Google Cloud SQL
    Cloud SQL with Terraform

Google Cloud Training & Certification

...helps you make the most of Google Cloud technologies. Our classes include technical skills and best practices to help you get up to speed quickly and continue your learning journey. We offer fundamental to advanced level training, with on-demand, live, and virtual options to suit your busy schedule. Certifications help you validate and prove your skill and expertise in Google Cloud technologies.
Manual Last Updated March 30, 2021
Lab Last Tested March 17, 2021

Copyright 2021 Google LLC All rights reserved. Google and the Google logo are trademarks of Google LLC. All other company and product names may be trademarks of the respective companies with which they are associated.
Continue questing
Lab
Introduction to SQL for BigQuery and Cloud SQL
Introductory
GSP281
Overview
Setup and Requirements
The Basics of SQL
Exploring the BigQuery Console
More SQL Keywords: GROUP BY, COUNT, AS, and ORDER BY
Working with Cloud SQL
New Queries in Cloud SQL
Congratulations!




variable "instance_name" {}
variable "instance_zone" {}
variable "instance_type" {
  default = "n1-standard-1"
  }
variable "instance_network" {}

resource "google_compute_instance" "vm_instance" {
  name         = "${var.instance_name}"
  zone         = "${var.instance_zone}"
  machine_type = "${var.instance_type}"
  boot_disk {
    initialize_params {
      image = "debian-cloud/debian-9"
      }
  }
  network_interface {
    network = "${var.instance_network}"
    access_config {
      # Allocate a one-to-one NAT IP to the instance
    }
  }
}

kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:2.0

gcloud container clusters get-credentials my-cluster
kubectl expose deployment hello-app --type=LoadBalancer --port 8080

kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0

Create a cluster (in the us-east1-b zone) to host the service.
Use the Docker container hello-app (gcr.io/google-samples/hello-app:2.0) as a place holder; the team will replace the container with their own work later.
Expose the app on port 8080.

gcr.io/google-samples/hello-app:2.0)

us-east1-b

Create an instance template.
Create a target pool.
Create a managed instance group.
Create a firewall rule to allow traffic (80/tcp).
Create a health check.
Create a backend service, and attach the managed instance group.
Create a URL map, and target the HTTP proxy to route requests to your URL map.
Create a forwarding rule.

gcloud compute instances create nginx1 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
 apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html"
	
gcloud compute instances create nginx2 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
 apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html"

gcloud compute firewall-rules create www-firewall-network-lb \
    --target-tags network-lb-tag --allow tcp:80
	
	

gcloud compute networks create managementnet --project=qwiklabs-gcp-03-637d4d885e32 --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-03-637d4d885e32 --range=10.130.0.0/20 --network=managementnet --region=us-central1

gcloud compute --project=qwiklabs-gcp-03-637d4d885e32 firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0

gcloud beta compute --project=qwiklabs-gcp-03-637d4d885e32 instances create managementnet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=844965241571-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210217 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any


student_02_9985c7b9d67a@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-02-eb3cb8fca754)$ kubectl get services frontend
NAME       TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)         AGE
frontend   LoadBalancer   10.115.249.14   34.67.56.157   443:30698/TCP   65s


docker pull gcr.io/qwiklabs-gcp-01-200aad9a20ed/node-app:0.2
docker run -p 4000:80 -d gcr.io/qwiklabs-gcp-01-200aad9a20ed/node-app:0.2
curl http://localhost:4000

student_01_e1239e502c7d@cloudshell:~ (qwiklabs-gcp-01-b7642adaec72)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
hello-server   LoadBalancer   10.3.254.128   35.184.224.3   8080:31200/TCP   44s
kubernetes     ClusterIP      10.3.240.1     <none>         443/TCP          3m50s
student_01_e1239e502c7d@cloudshell:~ (qwiklabs-gcp-01-b7642adaec72)$



gcloud compute instance-groups managed set-named-ports nginx-group --named-ports http:80


 --------------------Set up and Configure a Cloud Environment in Google Cloud: Challenge Lab:--------------



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

----------------Task 1: Create development VPC manually--------------------

For this task because it is mentioned to develop manually .....
We will perform it manually



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

--------------Task 2: Create production VPC using Deployment Manager--------


gsutil cp -r gs://cloud-training/gsp321/dm .

cd dm

sed -i s/SET_REGION/us-east1/g prod-network.yaml

gcloud deployment-manager deployments create prod-network \
    --config=prod-network.yaml

cd ..


##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

-------------Task 3: Create bastion host----------------------------------------

You can copy the below three commands at a time and run them on the Cloud shell.------

gcloud compute instances create bastion --network-interface=network=griffin-dev-vpc,subnet=griffin-dev-mgmt  --network-interface=network=griffin-prod-vpc,subnet=griffin-prod-mgmt --tags=ssh --zone=us-east1-b

gcloud compute firewall-rules create fw-ssh-dev --source-ranges=0.0.0.0/0 --target-tags ssh --allow=tcp:22 --network=griffin-dev-vpc

gcloud compute firewall-rules create fw-ssh-prod --source-ranges=0.0.0.0/0 --target-tags ssh --allow=tcp:22 --network=griffin-prod-vpc




##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
-------------Task 4: Create and configure Cloud SQL Instance-----------------------

gcloud sql instances create griffin-dev-db --root-password password --region=us-east1

gcloud sql connect griffin-dev-db


sql commands:---
CREATE DATABASE wordpress;
GRANT ALL PRIVILEGES ON wordpress.* TO "wp_user"@"%" IDENTIFIED BY "stormwind_rules";
FLUSH PRIVILEGES;



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
--------------Task 5: Create Kubernetes cluster-------------------------------------

gcloud container clusters create griffin-dev \
  --network griffin-dev-vpc \
  --subnetwork griffin-dev-wp \
  --machine-type n1-standard-4 \
  --num-nodes 2  \
  --zone us-east1-b

ubeconfig entry generated for griffin-dev.
NAME         LOCATION    MASTER_VERSION    MASTER_IP      MACHINE_TYPE   NODE_VERSION      NUM_NODES  STATUS
griffin-dev  us-east1-b  1.18.12-gke.1210  35.231.154.14  n1-standard-4  1.18.12-gke.1210  2          RUNNING
student_01_9e99e6b73110@cloudshell:~ (qwiklabs-gcp-01-28fbed30f737)$

gcloud container clusters get-credentials griffin-dev --zone us-east1-b

cd ~/


##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
---------------------------------Task 6 ,7, 8------------------------------------

gsutil cp -r gs://cloud-training/gsp321/wp-k8s .

cd wp-k8s

sed -i s/username_goes_here/wp_user/g wp-env.yaml

sed -i s/password_goes_here/stormwind_rules/g wp-env.yaml

----------------------------------------------------------------------------------

kubectl create -f wp-env.yaml

gcloud iam service-accounts keys create key.json --iam-account=cloud-sql-proxy@$GOOGLE_CLOUD_PROJECT.iam.gserviceaccount.com

kubectl create secret generic cloudsql-instance-credentials --from-file key.json

----------------------------------------------------------------------------------


I=$(gcloud sql instances describe griffin-dev-db --format="value(connectionName)")

sed -i s/YOUR_SQL_INSTANCE/$I/g wp-deployment.yaml

kubectl create -f wp-deployment.yaml

kubectl create -f wp-service.yaml


thanks :)
##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$ gcloud container clusters create webfrontend --zone $MY_ZONE --num-nodes 2

WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster webfrontend in us-central1-a... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-fe66d4e862ba/zones/us-central1-a/clusters/webfrontend].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/webfrontend?project=qwiklabs-gcp-00-fe66d4e862ba
kubeconfig entry generated for webfrontend.
NAME         LOCATION       MASTER_VERSION   MASTER_IP       MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
webfrontend  us-central1-a  1.18.16-gke.302  34.123.157.157  e2-medium     1.18.16-gke.302  2          RUNNING
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$

104.154.203.125


nginx        LoadBalancer   10.51.245.111   <pending>     80:31011/TCP   42s
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$ kubectl get services
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP       PORT(S)        AGE
kubernetes   ClusterIP      10.51.240.1     <none>            443/TCP        8m28s
nginx        LoadBalancer   10.51.245.111   104.154.203.125   80:31011/TCP   45s

VPC Networking

gcloud compute networks create managementnet --project=qwiklabs-gcp-03-d0417a0df52c --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-03-d0417a0df52c --range=10.130.0.0/20 --network=managementnet --region=us-central1


gcloud compute networks create privatenet --subnet-mode=custom

gcloud compute networks subnets create privatesubnet-us --network=privatenet --region=us-central1 --range=172.16.0.0/24

gcloud compute networks subnets create privatesubnet-eu --network=privatenet --region=europe-central2 --range=172.20.0.0/20

gcloud compute networks list


gcloud compute networks subnets list --sort-by=NETWORK

gcloud compute --project=qwiklabs-gcp-03-d0417a0df52c firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0


gcloud compute firewall-rules create privatenet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=privatenet --action=ALLOW --rules=icmp,tcp:22,tcp:3389 --source-ranges=0.0.0.0/0


gcloud beta compute --project=qwiklabs-gcp-03-d0417a0df52c instances create managementnet-us-vm --zone=us-central1-c --machine-type=n1-standard-1 --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=378953624177-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210316 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any



gcloud compute instances create privatenet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=privatesubnet-us --image-family=debian-10 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-standard --boot-disk-device-name=privatenet-us-vm



gcloud compute instances list --sort-by=ZONE



Implement Private Google Access and Cloud NAT

To connect to vm-internal, run the following command:

gcloud compute ssh vm-internal --zone us-central1-c --tunnel-through-iap


mybucket13806

gsutil cp gs://cloud-training/gcpnet/private/access.svg gs://mybucket13806

gsutil cp gs://mybucket13806/*.svg .



export SQL_CONNECTION=qwiklabs-gcp-03-a61351f94ea3:us-central1:wordpress-db

10.63.240.2
34.68.23.74

qwiklabs-gcp-04-storecore21778f3f0b95

qwiklabs-gcp-04-storecorede0347cd46b4

mybucket21778f3f0b95

Tr+QuUvSSilbpelcDDT+TfkrIQlnEgwZDdcjfh+j1vI=

+lrNHeRNQ4VMiL1iRDVWfQKQU/ddUs0y17jboebzZbs=

export BUCKET_NAME_1=storecore21778f3f0b95


peering network
gcloud compute target-vpn-gateways create vpn-1 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --network=vpn-network-1

gcloud compute forwarding-rules create vpn-1-rule-esp --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=ESP --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp500 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=UDP --ports=500 --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp4500 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=UDP --ports=4500 --target-vpn-gateway=vpn-1

gcloud compute vpn-tunnels create vpn-1-tunnel-1 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --peer-address=35.233.6.236 --shared-secret=gcprocks --ike-version=2 --local-traffic-selector=0.0.0.0/0 --remote-traffic-selector=0.0.0.0/0 --target-vpn-gateway=vpn-1

gcloud compute routes create vpn-1-tunnel-1-route-1 --project=qwiklabs-gcp-00-9353e3a9e4af --network=vpn-network-1 --priority=1000 --destination-range=10.1.3.0/24 --next-hop-vpn-tunnel=vpn-1-tunnel-1 --next-hop-vpn-tunnel-region=us-central1



gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-image:v0.1

student_00_f82b8b5f83e7@cloudshell:~/gcp-course/devops-repo (qwiklabs-gcp-00-90db9ea27409)$ git push origin master
Enumerating objects: 5, done.
Counting objects: 100% (5/5), done.
Delta compression using up to 2 threads
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 317 bytes | 317.00 KiB/s, done.
Total 3 (delta 2), reused 0 (delta 0)
remote: Resolving deltas: 100% (2/2)
To https://source.developers.google.com/p/qwiklabs-gcp-00-90db9ea27409/r/devops-repo
   f774936..063da15  master -> master
student_00_f82b8b5f83e7@cloudshell:~/gcp-course/devops-repo (qwiklabs-gcp-00-90db9ea27409)$

063da15315ecaeee1e9baeaf5b8f595f7fa9780e
build -t gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e .

gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e

gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e 




gcloud auth list


gcloud config list project

gcloud compute instances create gcelab2 --machine-type n1-standard-2 --zone us-central1-c

gcloud config get-value compute/zone
gcloud config get-value compute/region
gcloud compute project-info describe --project qwiklabs-gcp-00-85a0a8114378

gcloud compute instances create gcelab2 --machine-type n1-standard-2 --zone $ZONE


gcloud config set compute/zone us-central1-a

gcloud container clusters create my-cluster

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters create my-cluster
WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster my-cluster in us-central1-a... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-02-f17e6e96a602/zones/us-central1-a/clusters/my-cluster].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/my-cluster?project=qwiklabs-gcp-02-f17e6e96a602
kubeconfig entry generated for my-cluster.
NAME        LOCATION       MASTER_VERSION   MASTER_IP     MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
my-cluster  us-central1-a  1.18.16-gke.302  34.121.78.52  e2-medium     1.18.16-gke.302  3          RUNNING
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters get-credentials my-cluster
Fetching cluster endpoint and auth data.
kubeconfig entry generated for my-cluster.
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0
deployment.apps/hello-server created
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl expose deployment hello-server --type=LoadBalancer --port 8080
service/hello-server exposed
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
hello-server   LoadBalancer   10.3.251.101   <pending>     8080:32398/TCP   14s
kubernetes     ClusterIP      10.3.240.1     <none>        443/TCP          2m52s
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
hello-server   LoadBalancer   10.3.251.101   34.70.133.95   8080:32398/TCP   41s
kubernetes     ClusterIP      10.3.240.1     <none>         443/TCP          3m19s
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$


gcloud container clusters delete my-cluster

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters delete my-cluster
The following clusters will be deleted.
 - [my-cluster] in [us-central1-a]

Do you want to continue (Y/n)?  y

Deleting cluster my-cluster...done.
Deleted [https://container.googleapis.com/v1/projects/qwiklabs-gcp-02-f17e6e96a602/zones/us-central1-a/clusters/my-cluster].
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

In Cloud Shell, set the default zone:

gcloud config set compute/zone us-central1-a

Set the default region:

gcloud config set compute/region us-central1



    Create three new virtual machines in your default zone and give them all the same tag. The code provided sets the zone to us-central1-a. Setting the tags field lets you reference these instances all at once, such as with a firewall rule. These commands also install Apache on each instance and give each instance a unique home page.

gcloud compute instances create www1 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www1</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances create www2 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www2</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances create www3 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www3</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances list
tudent_00_2e86c9330f72@cloudshell:~ (qwiklabs-gcp-00-52ffa2e76b63)$ gcloud compute instances list
NAME  ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP     STATUS
www1  us-central1-a  n1-standard-1               10.128.0.2   34.123.14.179   RUNNING
www2  us-central1-a  n1-standard-1               10.128.0.3   35.225.110.197  RUNNING
www3  us-central1-a  n1-standard-1               10.128.0.4   35.193.225.168  RUNNING
student_00_2e86c9330f72@cloudshell:~ (qwiklabs-gcp-00-52ffa2e76b63)$




    First, create the load balancer template:

gcloud compute instance-templates create lb-backend-template \
   --region=us-central1 \
   --network=default \
   --subnet=default \
   --tags=allow-health-check \
   --image-family=debian-9 \
   --image-project=debian-cloud \
   --metadata=startup-script='#! /bin/bash
     apt-get update
     apt-get install apache2 -y
     a2ensite default-ssl
     a2enmod ssl
     vm_hostname="$(curl -H "Metadata-Flavor:Google" \
     http://169.254.169.254/computeMetadata/v1/instance/name)"
     echo "Page served from: $vm_hostname" | \
     tee /var/www/html/index.html
     systemctl restart apache2'
	 
	 
	 34.117.170.104
	 
	 
	 ARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster nucleus-webserver1 in us-east1-b... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-a9230877c3b8/zones/us-east1-b/clusters/nucleus-webserver1].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-b/nucleus-webserver1?project=qwiklabs-gcp-00-a9230877c3b8
kubeconfig entry generated for nucleus-webserver1.
NAME                LOCATION    MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
nucleus-webserver1  us-east1-b  1.18.16-gke.502  34.73.125.163  e2-medium     1.18.16-gke.502  3          RUNNING

student_00_8a28695a7131@cloudshell:~ (qwiklabs-gcp-00-a9230877c3b8)$ kubectl get service
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)          AGE
hello-app    LoadBalancer   10.119.247.38   35.231.85.25   8080:31562/TCP   44s
kubernetes   ClusterIP      10.119.240.1    <none>         443/TCP          2m31s
student_00_8a28695a7131@cloudshell:~ (qwiklabs-gcp-00-a9230877c3b8)$





gcloud compute networks create managementnet --project=qwiklabs-gcp-01-3e49a9834b0c --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-01-3e49a9834b0c --range=10.130.0.0/20 --network=managementnet --region=us-central1


kubeconfig entry generated for bootcamp.
NAME      LOCATION       MASTER_VERSION   MASTER_IP       MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
bootcamp  us-central1-a  1.18.16-gke.502  35.238.109.114  e2-medium     1.18.16-gke.502  5          RUNNING
student_01_133a2027419a@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-01-2ac127202402)$ kubectl get services frontend
NAME       TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)         AGE
frontend   LoadBalancer   10.115.245.182   34.66.211.255   443:31384/TCP   47s


NAME  LOCATION       MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
io    us-central1-b  1.18.16-gke.502  34.70.253.157  e2-medium     1.18.16-gke.502  3          RUNNING
student_04_5e78fc7ffc81@cloudshell:~ (qwiklabs-gcp-04-a83a0e5ac5d0)$

student_04_5e78fc7ffc81@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-04-a83a0e5ac5d0)$ kubectl get services
NAME         TYPE           CLUSTER-IP    EXTERNAL-IP    PORT(S)        AGE
kubernetes   ClusterIP      10.3.240.1    <none>         443/TCP        3m8s
nginx        LoadBalancer   10.3.242.44   34.68.26.164   80:30484/TCP   38s


student_00_1c72a9e81e1f@cloudshell:~/continuous-deployment-on-kubernetes (qwiklabs-gcp-00-9d3c450fc854)$ gcloud container clusters create jenkins-cd \
> --num-nodes 2 \
> --machine-type n1-standard-2 \
> --scopes "https://www.googleapis.com/auth/source.read_write,cloud-platform"
WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster jenkins-cd in us-east1-d... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-9d3c450fc854/zones/us-east1-d/clusters/jenkins-cd].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-d/jenkins-cd?project=qwiklabs-gcp-00-9d3c450fc854
kubeconfig entry generated for jenkins-cd.
NAME        LOCATION    MASTER_VERSION   MASTER_IP      MACHINE_TYPE   NODE_VERSION     NUM_NODES  STATUS
jenkins-cd  us-east1-d  1.18.16-gke.502  35.185.79.186  n1-standard-2  1.18.16-gke.502  2          RUNNING
student_00_1c72a9e81e1f@cloudshell:~/continuous-deployment-on-kubernetes (qwiklabs-gcp-00-9d3c450fc854)$



v0.2: digest: sha256:59f9514843d9ce75952b5cd8a090da2ca9b904f637d13498cf2678683e5aae9e size: 3055
DONE
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                 STATUS
9c2cb2ab-4007-43f7-a209-ff30b0ae5fdd  2021-04-14T14:08:53+00:00  47S       gs://qwiklabs-gcp-02-8b7c885c17da_cloudbuild/source/1618409331.045144-be8608a756d14c8289c69f5fb6278d3c.tgz  gcr.io/qwiklabs-gcp-02-8b7c885c17da/devops-image:v0.2  SUCCESS


tudent_02_2c0074e6de54@cloudshell:~/gcp-course/training-data-analyst/courses/design-process/deploying-apps-to-gcp (qwiklabs-gcp-02-8b7c885c17da)$ kubectl get services
NAME                   TYPE           CLUSTER-IP   EXTERNAL-IP    PORT(S)        AGE
devops-deployment-lb   LoadBalancer   10.8.10.6    34.72.68.169   80:31410/TCP   40s
kubernetes             ClusterIP      10.8.0.1     <none>         443/TCP        11m
student_02_2c0074e6de54@cloudshell:~/gcp-course/training-data-analyst/courses/design-process/deploying-apps-to-gcp (qwiklabs-gcp-02-8b7c885c17da)$

v0.1: digest: sha256:4012de105d001335e963023529b74f006d39ebaf0f292f477309a26c3c885f8d size: 3055
DONE
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ID                                    CREATE_TIME                DURATION  SOURCE                                                                                            
          IMAGES                                                    STATUS
345d4a76-8d14-4cd0-bba7-434b84dde254  2021-04-14T14:12:26+00:00  48S       gs://qwiklabs-gcp-02-8b7c885c17da_cloudbuild/source/1618409544.623512-f2008ebae4634532a40ad73fd3fa
0157.tgz  

gcr.io/qwiklabs-gcp-02-8b7c885c17da/cloud-run-image:v0.1  SUCCESS


ab -n 1000 -c 10 https://qwiklabs-gcp-04-569634929eae.appspot.com/


ab -n 1000 -c 10 https://<your-project-id>.appspot.com/





Task 1: Create a project jumphost instance

Navigation menu > Compute engine > VM Instance


Task 2: Create a Kubernetes service cluster

gcloud config set compute/zone us-east1-b

gcloud container clusters create nucleus-webserver1

gcloud container clusters get-credentials nucleus-webserver1

kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:2.0

kubectl expose deployment hello-app --type=LoadBalancer --port 8080

kubectl get service 


Task 3: Setup an HTTP load balancer

cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF

cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF


1 .Create an instance template :

gcloud compute instance-templates create nginx-template \
--metadata-from-file startup-script=startup.sh

2 .Create a target pool :

gcloud compute target-pools create nginx-pool

3 .Create a managed instance group :

gcloud compute instance-groups managed create nginx-group \
--base-instance-name nginx \
--size 2 \
--template nginx-template \
--target-pool nginx-pool

gcloud compute instances list

4 .Create a firewall rule to allow traffic (80/tcp) :

gcloud compute firewall-rules create www-firewall --allow tcp:80

gcloud compute forwarding-rules create nginx-lb \
--region us-east1 \
--ports=80 \
--target-pool nginx-pool

gcloud compute forwarding-rules list

5 .Create a health check :

gcloud compute http-health-checks create http-basic-check

gcloud compute instance-groups managed \
set-named-ports nginx-group \
--named-ports http:80

6 .Create a backend service and attach the manged instance group :

gcloud compute backend-services create nginx-backend \
--protocol HTTP --http-health-checks http-basic-check --global

gcloud compute backend-services add-backend nginx-backend \
--instance-group nginx-group \
--instance-group-zone us-east1-b \
--global

7 .Create a URL map and target HTTP proxy to route requests to your URL map :

gcloud compute url-maps create web-map \
--default-service nginx-backend

gcloud compute target-http-proxies create http-lb-proxy \
--url-map web-map

8 .Create a forwarding rule :

gcloud compute forwarding-rules create http-content-rule \
--global \
--target-http-proxy http-lb-proxy \
--ports 80

gcloud compute forwarding-rules list

Install Kubernetes on Ubuntu 18.04 LTS
Step1: On All Machines ( Master & All nodes ):
### INSTALL DOCKER & Configure 

sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
sudo apt-get update ; clear
sudo apt-get install -y docker-ce

sudo vi /etc/docker/daemon.json

{
        "exec-opts": ["native.cgroupdriver=systemd"]
}

sudo service docker restart


### INSTALL KUBEADM,KUBELET,KUBECTL

echo "deb http://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
sudo apt-get update ; clear
sudo apt-get install -y kubelet kubeadm kubectl    
 
Step2: On Master only:
sudo kubeadm init --ignore-preflight-errors=all

sudo mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

## install networking driver -- Weave/flannel/canal/calico etc... 

## below installs weave networking driver 

kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"

kubectl get nodes
kubectl get all --all-namespaces
 
Step3: On Nodes only:
copy the kubeadm join token from master & run it on all nodes
      
Ex: kubeadm join 10.128.15.231:6443 --token mks3y2.v03tyyru0gy12mbt \
       --discovery-token-ca-cert-hash sha256:3de23d42c7002be0893339fbe558ee75e14399e11f22e3f0b34351077b7c4b56



cat script.sh 
apt-get update
swapoff -a
cat /etc/hosts
wait 3
ping -c 2 knode1
ping -c 2 knode2
ping -c 2 kmaster
wait 3
apt-get update && apt-get install -y apt-transport-https curl gnupg-agent software-properties-common 
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
cat <<EOF >/etc/apt/sources.list.d/kubernetes.list 
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF
apt-get update
apt-get install -y kubelet kubeadm kubectl
apt-mark hold kubelet kubeadm kubectl
sudo apt-get update
 sudo apt-get install -y apt-transport-https ca-certificates curl gnugpg-agent software-properties-common 
 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io -y


Install Kubernetes on Ubuntu 18.04 LTS
Step1: On All Machines ( Master & All nodes ):
### INSTALL DOCKER & Configure 

sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
sudo apt-get update ; clear
sudo apt-get install -y docker-ce

sudo vi /etc/docker/daemon.json

{
		"exec-opts": ["native.cgroupdriver=systemd"]
}

sudo service docker restart


### INSTALL KUBEADM,KUBELET,KUBECTL

echo "deb http://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
sudo apt-get update ; clear
sudo apt-get install -y kubelet kubeadm kubectl	
Step2: On Master only:
sudo kubeadm init --ignore-preflight-errors=all

sudo mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

## install networking driver -- Weave/flannel/canal/calico etc... 

## below installs weave networking driver 

kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"

kubectl get nodes
kubectl get all --all-namespaces
Step3: On Nodes only:
copy the kubeadm join token from master & run it on all nodes
      
Ex: kubeadm join 10.128.15.231:6443 --token mks3y2.v03tyyru0gy12mbt \
       --discovery-token-ca-cert-hash sha256:3de23d42c7002be0893339fbe558ee75e14399e11f22e3f0b34351077b7c4b56


variable "instance_name" {}
variable "instance_zone" {}
variable "instance_type" {
  default = "n1-standard-1"
  }
variable "instance_network" {}

resource "google_compute_instance" "vm_instance" {
  name         = "${var.instance_name}"
  zone         = "${var.instance_zone}"
  machine_type = "${var.instance_type}"
  boot_disk {
    initialize_params {
      image = "debian-cloud/debian-9"
      }
  }
  network_interface {
    network = "${var.instance_network}"
    access_config {
      # Allocate a one-to-one NAT IP to the instance
    }
  }
}

kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:2.0

gcloud container clusters get-credentials my-cluster
kubectl expose deployment hello-app --type=LoadBalancer --port 8080

kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0

Create a cluster (in the us-east1-b zone) to host the service.
Use the Docker container hello-app (gcr.io/google-samples/hello-app:2.0) as a place holder; the team will replace the container with their own work later.
Expose the app on port 8080.

gcr.io/google-samples/hello-app:2.0)

us-east1-b

Create an instance template.
Create a target pool.
Create a managed instance group.
Create a firewall rule to allow traffic (80/tcp).
Create a health check.
Create a backend service, and attach the managed instance group.
Create a URL map, and target the HTTP proxy to route requests to your URL map.
Create a forwarding rule.

gcloud compute instances create nginx1 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
 apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html"
	
gcloud compute instances create nginx2 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
 apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html"

gcloud compute firewall-rules create www-firewall-network-lb \
    --target-tags network-lb-tag --allow tcp:80
	
	

gcloud compute networks create managementnet --project=qwiklabs-gcp-03-637d4d885e32 --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-03-637d4d885e32 --range=10.130.0.0/20 --network=managementnet --region=us-central1

gcloud compute --project=qwiklabs-gcp-03-637d4d885e32 firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0

gcloud beta compute --project=qwiklabs-gcp-03-637d4d885e32 instances create managementnet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=844965241571-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210217 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any


student_02_9985c7b9d67a@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-02-eb3cb8fca754)$ kubectl get services frontend
NAME       TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)         AGE
frontend   LoadBalancer   10.115.249.14   34.67.56.157   443:30698/TCP   65s


docker pull gcr.io/qwiklabs-gcp-01-200aad9a20ed/node-app:0.2
docker run -p 4000:80 -d gcr.io/qwiklabs-gcp-01-200aad9a20ed/node-app:0.2
curl http://localhost:4000

student_01_e1239e502c7d@cloudshell:~ (qwiklabs-gcp-01-b7642adaec72)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
hello-server   LoadBalancer   10.3.254.128   35.184.224.3   8080:31200/TCP   44s
kubernetes     ClusterIP      10.3.240.1     <none>         443/TCP          3m50s
student_01_e1239e502c7d@cloudshell:~ (qwiklabs-gcp-01-b7642adaec72)$



gcloud compute instance-groups managed set-named-ports nginx-group --named-ports http:80



 --------------------Set up and Configure a Cloud Environment in Google Cloud: Challenge Lab:--------------



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

----------------Task 1: Create development VPC manually--------------------

For this task because it is mentioned to develop manually .....
We will perform it manually



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

--------------Task 2: Create production VPC using Deployment Manager--------


gsutil cp -r gs://cloud-training/gsp321/dm .

cd dm

sed -i s/SET_REGION/us-east1/g prod-network.yaml

gcloud deployment-manager deployments create prod-network \
    --config=prod-network.yaml

cd ..


##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

-------------Task 3: Create bastion host----------------------------------------

You can copy the below three commands at a time and run them on the Cloud shell.------

gcloud compute instances create bastion --network-interface=network=griffin-dev-vpc,subnet=griffin-dev-mgmt  --network-interface=network=griffin-prod-vpc,subnet=griffin-prod-mgmt --tags=ssh --zone=us-east1-b

gcloud compute firewall-rules create fw-ssh-dev --source-ranges=0.0.0.0/0 --target-tags ssh --allow=tcp:22 --network=griffin-dev-vpc

gcloud compute firewall-rules create fw-ssh-prod --source-ranges=0.0.0.0/0 --target-tags ssh --allow=tcp:22 --network=griffin-prod-vpc




##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
-------------Task 4: Create and configure Cloud SQL Instance-----------------------

gcloud sql instances create griffin-dev-db --root-password password --region=us-east1

gcloud sql connect griffin-dev-db


sql commands:---
CREATE DATABASE wordpress;
GRANT ALL PRIVILEGES ON wordpress.* TO "wp_user"@"%" IDENTIFIED BY "stormwind_rules";
FLUSH PRIVILEGES;



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
--------------Task 5: Create Kubernetes cluster-------------------------------------

gcloud container clusters create griffin-dev \
  --network griffin-dev-vpc \
  --subnetwork griffin-dev-wp \
  --machine-type n1-standard-4 \
  --num-nodes 2  \
  --zone us-east1-b

ubeconfig entry generated for griffin-dev.
NAME         LOCATION    MASTER_VERSION    MASTER_IP      MACHINE_TYPE   NODE_VERSION      NUM_NODES  STATUS
griffin-dev  us-east1-b  1.18.12-gke.1210  35.231.154.14  n1-standard-4  1.18.12-gke.1210  2          RUNNING
student_01_9e99e6b73110@cloudshell:~ (qwiklabs-gcp-01-28fbed30f737)$

gcloud container clusters get-credentials griffin-dev --zone us-east1-b

cd ~/


##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
---------------------------------Task 6 ,7, 8------------------------------------

gsutil cp -r gs://cloud-training/gsp321/wp-k8s .

cd wp-k8s

sed -i s/username_goes_here/wp_user/g wp-env.yaml

sed -i s/password_goes_here/stormwind_rules/g wp-env.yaml

----------------------------------------------------------------------------------

kubectl create -f wp-env.yaml

gcloud iam service-accounts keys create key.json --iam-account=cloud-sql-proxy@$GOOGLE_CLOUD_PROJECT.iam.gserviceaccount.com

kubectl create secret generic cloudsql-instance-credentials --from-file key.json

----------------------------------------------------------------------------------


I=$(gcloud sql instances describe griffin-dev-db --format="value(connectionName)")

sed -i s/YOUR_SQL_INSTANCE/$I/g wp-deployment.yaml

kubectl create -f wp-deployment.yaml

kubectl create -f wp-service.yaml


thanks :)
##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$ gcloud container clusters create webfrontend --zone $MY_ZONE --num-nodes 2

WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster webfrontend in us-central1-a... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-fe66d4e862ba/zones/us-central1-a/clusters/webfrontend].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/webfrontend?project=qwiklabs-gcp-00-fe66d4e862ba
kubeconfig entry generated for webfrontend.
NAME         LOCATION       MASTER_VERSION   MASTER_IP       MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
webfrontend  us-central1-a  1.18.16-gke.302  34.123.157.157  e2-medium     1.18.16-gke.302  2          RUNNING
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$

104.154.203.125


nginx        LoadBalancer   10.51.245.111   <pending>     80:31011/TCP   42s
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$ kubectl get services
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP       PORT(S)        AGE
kubernetes   ClusterIP      10.51.240.1     <none>            443/TCP        8m28s
nginx        LoadBalancer   10.51.245.111   104.154.203.125   80:31011/TCP   45s

VPC Networking

gcloud compute networks create managementnet --project=qwiklabs-gcp-03-d0417a0df52c --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-03-d0417a0df52c --range=10.130.0.0/20 --network=managementnet --region=us-central1


gcloud compute networks create privatenet --subnet-mode=custom

gcloud compute networks subnets create privatesubnet-us --network=privatenet --region=us-central1 --range=172.16.0.0/24

gcloud compute networks subnets create privatesubnet-eu --network=privatenet --region=europe-central2 --range=172.20.0.0/20

gcloud compute networks list


gcloud compute networks subnets list --sort-by=NETWORK

gcloud compute --project=qwiklabs-gcp-03-d0417a0df52c firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0


gcloud compute firewall-rules create privatenet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=privatenet --action=ALLOW --rules=icmp,tcp:22,tcp:3389 --source-ranges=0.0.0.0/0


gcloud beta compute --project=qwiklabs-gcp-03-d0417a0df52c instances create managementnet-us-vm --zone=us-central1-c --machine-type=n1-standard-1 --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=378953624177-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210316 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any



gcloud compute instances create privatenet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=privatesubnet-us --image-family=debian-10 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-standard --boot-disk-device-name=privatenet-us-vm



gcloud compute instances list --sort-by=ZONE



Implement Private Google Access and Cloud NAT

To connect to vm-internal, run the following command:

gcloud compute ssh vm-internal --zone us-central1-c --tunnel-through-iap


mybucket13806

gsutil cp gs://cloud-training/gcpnet/private/access.svg gs://mybucket13806

gsutil cp gs://mybucket13806/*.svg .



export SQL_CONNECTION=qwiklabs-gcp-03-a61351f94ea3:us-central1:wordpress-db

10.63.240.2
34.68.23.74

qwiklabs-gcp-04-storecore21778f3f0b95

qwiklabs-gcp-04-storecorede0347cd46b4

mybucket21778f3f0b95

Tr+QuUvSSilbpelcDDT+TfkrIQlnEgwZDdcjfh+j1vI=

+lrNHeRNQ4VMiL1iRDVWfQKQU/ddUs0y17jboebzZbs=

export BUCKET_NAME_1=storecore21778f3f0b95


peering network
gcloud compute target-vpn-gateways create vpn-1 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --network=vpn-network-1

gcloud compute forwarding-rules create vpn-1-rule-esp --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=ESP --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp500 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=UDP --ports=500 --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp4500 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=UDP --ports=4500 --target-vpn-gateway=vpn-1

gcloud compute vpn-tunnels create vpn-1-tunnel-1 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --peer-address=35.233.6.236 --shared-secret=gcprocks --ike-version=2 --local-traffic-selector=0.0.0.0/0 --remote-traffic-selector=0.0.0.0/0 --target-vpn-gateway=vpn-1

gcloud compute routes create vpn-1-tunnel-1-route-1 --project=qwiklabs-gcp-00-9353e3a9e4af --network=vpn-network-1 --priority=1000 --destination-range=10.1.3.0/24 --next-hop-vpn-tunnel=vpn-1-tunnel-1 --next-hop-vpn-tunnel-region=us-central1



gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-image:v0.1

student_00_f82b8b5f83e7@cloudshell:~/gcp-course/devops-repo (qwiklabs-gcp-00-90db9ea27409)$ git push origin master
Enumerating objects: 5, done.
Counting objects: 100% (5/5), done.
Delta compression using up to 2 threads
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 317 bytes | 317.00 KiB/s, done.
Total 3 (delta 2), reused 0 (delta 0)
remote: Resolving deltas: 100% (2/2)
To https://source.developers.google.com/p/qwiklabs-gcp-00-90db9ea27409/r/devops-repo
   f774936..063da15  master -> master
student_00_f82b8b5f83e7@cloudshell:~/gcp-course/devops-repo (qwiklabs-gcp-00-90db9ea27409)$

063da15315ecaeee1e9baeaf5b8f595f7fa9780e
build -t gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e .

gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e

gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e 




gcloud auth list


gcloud config list project

gcloud compute instances create gcelab2 --machine-type n1-standard-2 --zone us-central1-c

gcloud config get-value compute/zone
gcloud config get-value compute/region
gcloud compute project-info describe --project qwiklabs-gcp-00-85a0a8114378

gcloud compute instances create gcelab2 --machine-type n1-standard-2 --zone $ZONE


gcloud config set compute/zone us-central1-a

gcloud container clusters create my-cluster

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters create my-cluster
WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster my-cluster in us-central1-a... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-02-f17e6e96a602/zones/us-central1-a/clusters/my-cluster].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/my-cluster?project=qwiklabs-gcp-02-f17e6e96a602
kubeconfig entry generated for my-cluster.
NAME        LOCATION       MASTER_VERSION   MASTER_IP     MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
my-cluster  us-central1-a  1.18.16-gke.302  34.121.78.52  e2-medium     1.18.16-gke.302  3          RUNNING
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters get-credentials my-cluster
Fetching cluster endpoint and auth data.
kubeconfig entry generated for my-cluster.
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0
deployment.apps/hello-server created
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl expose deployment hello-server --type=LoadBalancer --port 8080
service/hello-server exposed
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
hello-server   LoadBalancer   10.3.251.101   <pending>     8080:32398/TCP   14s
kubernetes     ClusterIP      10.3.240.1     <none>        443/TCP          2m52s
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
hello-server   LoadBalancer   10.3.251.101   34.70.133.95   8080:32398/TCP   41s
kubernetes     ClusterIP      10.3.240.1     <none>         443/TCP          3m19s
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$


gcloud container clusters delete my-cluster

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters delete my-cluster
The following clusters will be deleted.
 - [my-cluster] in [us-central1-a]

Do you want to continue (Y/n)?  y

Deleting cluster my-cluster...done.
Deleted [https://container.googleapis.com/v1/projects/qwiklabs-gcp-02-f17e6e96a602/zones/us-central1-a/clusters/my-cluster].
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

In Cloud Shell, set the default zone:

gcloud config set compute/zone us-central1-a

Set the default region:

gcloud config set compute/region us-central1



    Create three new virtual machines in your default zone and give them all the same tag. The code provided sets the zone to us-central1-a. Setting the tags field lets you reference these instances all at once, such as with a firewall rule. These commands also install Apache on each instance and give each instance a unique home page.

gcloud compute instances create www1 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www1</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances create www2 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www2</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances create www3 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www3</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances list
tudent_00_2e86c9330f72@cloudshell:~ (qwiklabs-gcp-00-52ffa2e76b63)$ gcloud compute instances list
NAME  ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP     STATUS
www1  us-central1-a  n1-standard-1               10.128.0.2   34.123.14.179   RUNNING
www2  us-central1-a  n1-standard-1               10.128.0.3   35.225.110.197  RUNNING
www3  us-central1-a  n1-standard-1               10.128.0.4   35.193.225.168  RUNNING
student_00_2e86c9330f72@cloudshell:~ (qwiklabs-gcp-00-52ffa2e76b63)$




    First, create the load balancer template:

gcloud compute instance-templates create lb-backend-template \
   --region=us-central1 \
   --network=default \
   --subnet=default \
   --tags=allow-health-check \
   --image-family=debian-9 \
   --image-project=debian-cloud \
   --metadata=startup-script='#! /bin/bash
     apt-get update
     apt-get install apache2 -y
     a2ensite default-ssl
     a2enmod ssl
     vm_hostname="$(curl -H "Metadata-Flavor:Google" \
     http://169.254.169.254/computeMetadata/v1/instance/name)"
     echo "Page served from: $vm_hostname" | \
     tee /var/www/html/index.html
     systemctl restart apache2'
	 
	 
	 34.117.170.104
	 
	 
	 ARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster nucleus-webserver1 in us-east1-b... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-a9230877c3b8/zones/us-east1-b/clusters/nucleus-webserver1].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-b/nucleus-webserver1?project=qwiklabs-gcp-00-a9230877c3b8
kubeconfig entry generated for nucleus-webserver1.
NAME                LOCATION    MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
nucleus-webserver1  us-east1-b  1.18.16-gke.502  34.73.125.163  e2-medium     1.18.16-gke.502  3          RUNNING

student_00_8a28695a7131@cloudshell:~ (qwiklabs-gcp-00-a9230877c3b8)$ kubectl get service
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)          AGE
hello-app    LoadBalancer   10.119.247.38   35.231.85.25   8080:31562/TCP   44s
kubernetes   ClusterIP      10.119.240.1    <none>         443/TCP          2m31s
student_00_8a28695a7131@cloudshell:~ (qwiklabs-gcp-00-a9230877c3b8)$





gcloud compute networks create managementnet --project=qwiklabs-gcp-01-3e49a9834b0c --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-01-3e49a9834b0c --range=10.130.0.0/20 --network=managementnet --region=us-central1


kubeconfig entry generated for bootcamp.
NAME      LOCATION       MASTER_VERSION   MASTER_IP       MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
bootcamp  us-central1-a  1.18.16-gke.502  35.238.109.114  e2-medium     1.18.16-gke.502  5          RUNNING
student_01_133a2027419a@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-01-2ac127202402)$ kubectl get services frontend
NAME       TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)         AGE
frontend   LoadBalancer   10.115.245.182   34.66.211.255   443:31384/TCP   47s


NAME  LOCATION       MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
io    us-central1-b  1.18.16-gke.502  34.70.253.157  e2-medium     1.18.16-gke.502  3          RUNNING
student_04_5e78fc7ffc81@cloudshell:~ (qwiklabs-gcp-04-a83a0e5ac5d0)$

student_04_5e78fc7ffc81@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-04-a83a0e5ac5d0)$ kubectl get services
NAME         TYPE           CLUSTER-IP    EXTERNAL-IP    PORT(S)        AGE
kubernetes   ClusterIP      10.3.240.1    <none>         443/TCP        3m8s
nginx        LoadBalancer   10.3.242.44   34.68.26.164   80:30484/TCP   38s


student_00_1c72a9e81e1f@cloudshell:~/continuous-deployment-on-kubernetes (qwiklabs-gcp-00-9d3c450fc854)$ gcloud container clusters create jenkins-cd \
> --num-nodes 2 \
> --machine-type n1-standard-2 \
> --scopes "https://www.googleapis.com/auth/source.read_write,cloud-platform"
WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster jenkins-cd in us-east1-d... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-9d3c450fc854/zones/us-east1-d/clusters/jenkins-cd].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-d/jenkins-cd?project=qwiklabs-gcp-00-9d3c450fc854
kubeconfig entry generated for jenkins-cd.
NAME        LOCATION    MASTER_VERSION   MASTER_IP      MACHINE_TYPE   NODE_VERSION     NUM_NODES  STATUS
jenkins-cd  us-east1-d  1.18.16-gke.502  35.185.79.186  n1-standard-2  1.18.16-gke.502  2          RUNNING
student_00_1c72a9e81e1f@cloudshell:~/continuous-deployment-on-kubernetes (qwiklabs-gcp-00-9d3c450fc854)$



v0.2: digest: sha256:59f9514843d9ce75952b5cd8a090da2ca9b904f637d13498cf2678683e5aae9e size: 3055
DONE
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                 STATUS
9c2cb2ab-4007-43f7-a209-ff30b0ae5fdd  2021-04-14T14:08:53+00:00  47S       gs://qwiklabs-gcp-02-8b7c885c17da_cloudbuild/source/1618409331.045144-be8608a756d14c8289c69f5fb6278d3c.tgz  gcr.io/qwiklabs-gcp-02-8b7c885c17da/devops-image:v0.2  SUCCESS


tudent_02_2c0074e6de54@cloudshell:~/gcp-course/training-data-analyst/courses/design-process/deploying-apps-to-gcp (qwiklabs-gcp-02-8b7c885c17da)$ kubectl get services
NAME                   TYPE           CLUSTER-IP   EXTERNAL-IP    PORT(S)        AGE
devops-deployment-lb   LoadBalancer   10.8.10.6    34.72.68.169   80:31410/TCP   40s
kubernetes             ClusterIP      10.8.0.1     <none>         443/TCP        11m
student_02_2c0074e6de54@cloudshell:~/gcp-course/training-data-analyst/courses/design-process/deploying-apps-to-gcp (qwiklabs-gcp-02-8b7c885c17da)$

v0.1: digest: sha256:4012de105d001335e963023529b74f006d39ebaf0f292f477309a26c3c885f8d size: 3055
DONE
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ID                                    CREATE_TIME                DURATION  SOURCE                                                                                            
          IMAGES                                                    STATUS
345d4a76-8d14-4cd0-bba7-434b84dde254  2021-04-14T14:12:26+00:00  48S       gs://qwiklabs-gcp-02-8b7c885c17da_cloudbuild/source/1618409544.623512-f2008ebae4634532a40ad73fd3fa
0157.tgz  

gcr.io/qwiklabs-gcp-02-8b7c885c17da/cloud-run-image:v0.1  SUCCESS


ab -n 1000 -c 10 https://qwiklabs-gcp-04-569634929eae.appspot.com/


ab -n 1000 -c 10 https://<your-project-id>.appspot.com/





Task 1: Create a project jumphost instance

Navigation menu > Compute engine > VM Instance


Task 2: Create a Kubernetes service cluster

gcloud config set compute/zone us-east1-b

gcloud container clusters create nucleus-webserver1

gcloud container clusters get-credentials nucleus-webserver1

kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:2.0

kubectl expose deployment hello-app --type=LoadBalancer --port 8080

kubectl get service 


Task 3: Setup an HTTP load balancer

cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF

cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF


1 .Create an instance template :

gcloud compute instance-templates create nginx-template \
--metadata-from-file startup-script=startup.sh

2 .Create a target pool :

gcloud compute target-pools create nginx-pool

3 .Create a managed instance group :

gcloud compute instance-groups managed create nginx-group \
--base-instance-name nginx \
--size 2 \
--template nginx-template \
--target-pool nginx-pool

gcloud compute instances list

4 .Create a firewall rule to allow traffic (80/tcp) :

gcloud compute firewall-rules create www-firewall --allow tcp:80

gcloud compute forwarding-rules create nginx-lb \
--region us-east1 \
--ports=80 \
--target-pool nginx-pool

gcloud compute forwarding-rules list

5 .Create a health check :

gcloud compute http-health-checks create http-basic-check

gcloud compute instance-groups managed \
set-named-ports nginx-group \
--named-ports http:80

6 .Create a backend service and attach the manged instance group :

gcloud compute backend-services create nginx-backend \
--protocol HTTP --http-health-checks http-basic-check --global

gcloud compute backend-services add-backend nginx-backend \
--instance-group nginx-group \
--instance-group-zone us-east1-b \
--global

7 .Create a URL map and target HTTP proxy to route requests to your URL map :

gcloud compute url-maps create web-map \
--default-service nginx-backend

gcloud compute target-http-proxies create http-lb-proxy \
--url-map web-map

8 .Create a forwarding rule :

gcloud compute forwarding-rules create http-content-rule \
--global \
--target-http-proxy http-lb-proxy \
--ports 80

gcloud compute forwarding-rules list



gcloud compute zones list
gcloud compute zones list | grep us-central1
gcloud config set compute/zone us-central1-b

gcloud compute instances create "my-vm-2" \
--machine-type "n1-standard-1" \
--image-project "debian-cloud" \
--image "debian-9-stretch-v20190213" \
--subnet "default"

student_01_e85d9095ca4e@cloudshell:~ (qwiklabs-gcp-01-777266d3e9f3)$
student_01_e85d9095ca4e@cloudshell:~ (qwiklabs-gcp-01-777266d3e9f3)$ gcloud compute instances create "my-vm-2" \
> --machine-type "n1-standard-1" \
> --image-project "debian-cloud" \
> --image "debian-9-stretch-v20190213" \
> --subnet "default"
Created [https://www.googleapis.com/compute/v1/projects/qwiklabs-gcp-01-777266d3e9f3/zones/us-central1-b/instances/my-vm-2].
WARNING: Some requests generated warnings:
 - The resource 'projects/debian-cloud/global/images/debian-9-stretch-v20190213' is deprecated. A suggested replacement is 'projects/debian-cloud/global/images/debian-9-s
tretch-v20190312'.
NAME     ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP    STATUS
my-vm-2  us-central1-b  n1-standard-1               10.128.0.3   35.222.20.187  RUNNING
student_01_e85d9095ca4e@cloudshell:~ (qwiklabs-gcp-01-777266d3e9f3)$


gcloud compute instances create "my-vm-2" \
> --machine-type "n1-standard-1" \
> --image-project "debian-cloud" \
> --image "debian-9-stretch-v20190213" \
> --subnet "default"


https://niyander.blogspot.com/2020/09/Big%20Data%20and%20Machine%20Learning%20quiz%20answer.html

gcr.io/qwiklabs-gcp-03-fce10dd0479b/devops-repo:ef1495a72524d4fffd9565ab18a3ad9cbcd67f5e 

gcr.io/qwiklabs-gcp-03-fce10dd0479b/devops-image:v0.1
gcr.io/qwiklabs-gcp-03-fce10dd0479b/devops-repo:535d3491a6ba8ba9548afb3a9d6e4715083eb5e7
https://console.cloud.google.com/cloud-build/builds;region=global/0a4309ee-443d-4b1d-b719-b0000162738d;step=0?authuser=2&project=qwiklabs-gcp-03-fce10dd0479b




gcr.io/qwiklabs-gcp-03-2e2100e07441/devops-image:v0.2


35.193.236.52

qwiklabs-gcp-01-50186c5937d1:us-central1:blog-db
34.121.15.242

https://storage.googleapis.com/qwiklabs-gcp-01-50186c5937d1/my-excellent-blog.png

sed -i -e "s/qwiklabs-gcp-04-3515a53d80b0/$DEVSHELL_PROJECT_ID/" mydeploy.yaml

sed -i -e "s/PROJECT_ID/$DEVSHELL_PROJECT_ID/" mydeploy.yaml

sed -i -e "s/ZONE/$MY_ZONE/" mydeploy.yaml

dd if=/dev/urandom | gzip -9 >> /dev/null &

This Linux pipeline forces the CPU to work on compressing a continuous stream of random data.

gsutil mb gs://<my-storage-bucket1380>


Admin user
user
Admin password (Temporary)
E6MkKSVMjfyF

gcloud compute --project=qwiklabs-gcp-01-5700098d951f firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,icmp --source-ranges=0.0.0.0/0


gcloud compute --project=qwiklabs-gcp-01-5700098d951f firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0

gcloud beta compute --project=qwiklabs-gcp-01-5700098d951f instances create managementnet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=631874837590-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210217 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any


gcloud compute instances list --sort-by=ZONE
NAME                 ZONE            MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP     STATUS
mynet-eu-vm          europe-west1-c  n1-standard-1               10.132.0.2   130.211.102.89  RUNNING
managementnet-us-vm  us-central1-c   f1-micro                    10.130.0.2   34.121.160.164  RUNNING
mynet-us-vm          us-central1-c   n1-standard-1               10.128.0.2   35.222.145.135  RUNNING
privatenet-us-vm     us-central1-c   f1-micro                    172.16.0.2   34.123.9.194    RUNNING
student_01_feb12fb61313@cloudshell:~ (qwiklabs-gcp-01-5700098d951f)$


my-storage-bucket138012

gsutil cp gs://cloud-training/gcpnet/private/access.svg gs://my-storage-bucket138012

gsutil cp gs://my-storage-bucket138012/*.svg .

gsutil ls gs://my-storage-bucket138012

gsutil cp gs://my-storage-bucket1380122/sample.txt .


myproj-155a26

myproj-c197c
export BUCKET_NAME_1=155a26_bucket

decryption
VaSql+KA6+0b+IV+H13IxBoiit2RbOvVaeAUNs6zdpg=

45gBD+wmAoFgjAWI5RXUY9Pb1JN7QP3FCFt61ZoRS1w=


student_04_84e0100ca6ed@cloudshell:~ (qwiklabs-gcp-04-155a262b192b)$ gsutil ls -a gs://$BUCKET_NAME_1/setup.html
gs://myproj-155a26/setup.html#1614230131009289
gs://myproj-155a26/setup.html#1614231129184244
gs://myproj-155a26/setup.html#1614231153790239

export VERSION_NAME=gs://myproj-155a26/setup.html#1614230131009289

vpn-2-static-ip
34.76.178.85

vpn-1-static-ip
34.72.18.250
gcprocks

HTTP	35.244.196.221:80	Premium
HTTP	[2600:1901:0:1cb5::]:80	Premium



nPzgN+q/8Y2StdzUkigPn1PGA5+pGSIP

dcHnYIjjzvYo0ClUZTfRMRkJtP7vEsst


gcloud compute target-vpn-gateways create vpn-1 --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --network=vpn-network-1

gcloud compute forwarding-rules create vpn-1-rule-esp --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --address=34.72.18.250 --ip-protocol=ESP --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp500 --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --address=34.72.18.250 --ip-protocol=UDP --ports=500 --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp4500 --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --address=34.72.18.250 --ip-protocol=UDP --ports=4500 --target-vpn-gateway=vpn-1

gcloud compute vpn-tunnels create tunnel1to2 --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --peer-address=35.229.93.165 --shared-secret=NZDG0LhMlTGTI9twTwPw6zmTeBtmm68e --ike-version=1 --local-traffic-selector=0.0.0.0/0 --remote-traffic-selector=0.0.0.0/0 --target-vpn-gateway=vpn-1

gcloud compute routes create tunnel1to2-route-1 --project=qwiklabs-gcp-04-75c147194c21 --network=vpn-network-1 --priority=1000 --destination-range=10.1.3.0/24 --next-hop-vpn-tunnel=tunnel1to2 --next-hop-vpn-tunnel-region=us-central1



resources:
# Create the auto-mode network
- name: mynetwork
  type: compute.v1.network
  properties:
    autoCreateSubnetworks: true

# Create the firewall rule
- name: mynetwork-allow-http-ssh-rdp-icmp
  type: compute.v1.firewall
  properties:
    network: $(ref.mynetwork.selfLink)
    sourceRanges: ["0.0.0.0/0"]
    allowed:
    - IPProtocol: TCP
      ports: [22, 80, 3389]
    - IPProtocol: ICMP
	
	
variable "instance_name" {}
variable "instance_zone" {}
variable "instance_type" {
  default = "n1-standard-1"
  }
variable "instance_network" {}

resource "google_compute_instance" "vm_instance" {
  name         = "${var.instance_name}"
  zone         = "${var.instance_zone}"
  machine_type = "${var.instance_type}"
  boot_disk {
    initialize_params {
      image = "debian-cloud/debian-9"
      }
  }
  network_interface {
    network = "${var.instance_network}"
    access_config {
      # Allocate a one-to-one NAT IP to the instance
    }
  }
}

kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:2.0

gcloud container clusters get-credentials my-cluster
kubectl expose deployment hello-app --type=LoadBalancer --port 8080

kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0

Create a cluster (in the us-east1-b zone) to host the service.
Use the Docker container hello-app (gcr.io/google-samples/hello-app:2.0) as a place holder; the team will replace the container with their own work later.
Expose the app on port 8080.

gcr.io/google-samples/hello-app:2.0)

us-east1-b

Create an instance template.
Create a target pool.
Create a managed instance group.
Create a firewall rule to allow traffic (80/tcp).
Create a health check.
Create a backend service, and attach the managed instance group.
Create a URL map, and target the HTTP proxy to route requests to your URL map.
Create a forwarding rule.

gcloud compute instances create nginx1 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
 apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html"
	
gcloud compute instances create nginx2 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
 apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html"

gcloud compute firewall-rules create www-firewall-network-lb \
    --target-tags network-lb-tag --allow tcp:80
	
	
gcloud compute networks create managementnet --project=qwiklabs-gcp-03-637d4d885e32 --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-03-637d4d885e32 --range=10.130.0.0/20 --network=managementnet --region=us-central1

gcloud compute --project=qwiklabs-gcp-03-637d4d885e32 firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0

gcloud beta compute --project=qwiklabs-gcp-03-637d4d885e32 instances create managementnet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=844965241571-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210217 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any


student_02_9985c7b9d67a@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-02-eb3cb8fca754)$ kubectl get services frontend
NAME       TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)         AGE
frontend   LoadBalancer   10.115.249.14   34.67.56.157   443:30698/TCP   65s


docker pull gcr.io/qwiklabs-gcp-01-200aad9a20ed/node-app:0.2
docker run -p 4000:80 -d gcr.io/qwiklabs-gcp-01-200aad9a20ed/node-app:0.2
curl http://localhost:4000

student_01_e1239e502c7d@cloudshell:~ (qwiklabs-gcp-01-b7642adaec72)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
hello-server   LoadBalancer   10.3.254.128   35.184.224.3   8080:31200/TCP   44s
kubernetes     ClusterIP      10.3.240.1     <none>         443/TCP          3m50s
student_01_e1239e502c7d@cloudshell:~ (qwiklabs-gcp-01-b7642adaec72)$



gcloud compute instance-groups managed set-named-ports nginx-group --named-ports http:80

 --------------------Set up and Configure a Cloud Environment in Google Cloud: Challenge Lab:--------------



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

----------------Task 1: Create development VPC manually--------------------

For this task because it is mentioned to develop manually .....
We will perform it manually



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

--------------Task 2: Create production VPC using Deployment Manager--------


gsutil cp -r gs://cloud-training/gsp321/dm .

cd dm

sed -i s/SET_REGION/us-east1/g prod-network.yaml

gcloud deployment-manager deployments create prod-network \
    --config=prod-network.yaml

cd ..


##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

-------------Task 3: Create bastion host----------------------------------------

You can copy the below three commands at a time and run them on the Cloud shell.------

gcloud compute instances create bastion --network-interface=network=griffin-dev-vpc,subnet=griffin-dev-mgmt  --network-interface=network=griffin-prod-vpc,subnet=griffin-prod-mgmt --tags=ssh --zone=us-east1-b

gcloud compute firewall-rules create fw-ssh-dev --source-ranges=0.0.0.0/0 --target-tags ssh --allow=tcp:22 --network=griffin-dev-vpc

gcloud compute firewall-rules create fw-ssh-prod --source-ranges=0.0.0.0/0 --target-tags ssh --allow=tcp:22 --network=griffin-prod-vpc




##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
-------------Task 4: Create and configure Cloud SQL Instance-----------------------

gcloud sql instances create griffin-dev-db --root-password password --region=us-east1

gcloud sql connect griffin-dev-db


sql commands:---
CREATE DATABASE wordpress;
GRANT ALL PRIVILEGES ON wordpress.* TO "wp_user"@"%" IDENTIFIED BY "stormwind_rules";
FLUSH PRIVILEGES;



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
--------------Task 5: Create Kubernetes cluster-------------------------------------

gcloud container clusters create griffin-dev \
  --network griffin-dev-vpc \
  --subnetwork griffin-dev-wp \
  --machine-type n1-standard-4 \
  --num-nodes 2  \
  --zone us-east1-b

ubeconfig entry generated for griffin-dev.
NAME         LOCATION    MASTER_VERSION    MASTER_IP      MACHINE_TYPE   NODE_VERSION      NUM_NODES  STATUS
griffin-dev  us-east1-b  1.18.12-gke.1210  35.231.154.14  n1-standard-4  1.18.12-gke.1210  2          RUNNING
student_01_9e99e6b73110@cloudshell:~ (qwiklabs-gcp-01-28fbed30f737)$

gcloud container clusters get-credentials griffin-dev --zone us-east1-b

cd ~/


##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
---------------------------------Task 6 ,7, 8------------------------------------

gsutil cp -r gs://cloud-training/gsp321/wp-k8s .

cd wp-k8s

sed -i s/username_goes_here/wp_user/g wp-env.yaml

sed -i s/password_goes_here/stormwind_rules/g wp-env.yaml

----------------------------------------------------------------------------------

kubectl create -f wp-env.yaml

gcloud iam service-accounts keys create key.json --iam-account=cloud-sql-proxy@$GOOGLE_CLOUD_PROJECT.iam.gserviceaccount.com

kubectl create secret generic cloudsql-instance-credentials --from-file key.json

----------------------------------------------------------------------------------


I=$(gcloud sql instances describe griffin-dev-db --format="value(connectionName)")

sed -i s/YOUR_SQL_INSTANCE/$I/g wp-deployment.yaml

kubectl create -f wp-deployment.yaml

kubectl create -f wp-service.yaml


thanks :)
##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

MY_BUCKET_NAME_1=my_storage
MY_BUCKET_NAME_2=my_storage_2
MY_REGION=us-central1

Created [https://www.googleapis.com/compute/v1/projects/qwiklabs-gcp-00-cfe3de25623f/zones/us-central1-c/instances/second-vm].
NAME       ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP     STATUS
second-vm  us-central1-c  e2-standard-2               10.128.0.3   146.148.52.169  RUNNING
student_00_2f9893063cc6@cloudshell:~ (qwiklabs-gcp-00-cfe3de25623f)$ gcloud compute instances list
NAME       ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP      STATUS
first-vm   us-central1-c  e2-micro                    10.128.0.2   104.197.222.196  RUNNING
second-vm  us-central1-c  e2-standard-2               10.128.0.3   146.148.52.169   RUNNING
student_00_2f9893063cc6@cloudshell:~ (qwiklabs-gcp-00-cfe3de25623f)$ gcloud iam service-accounts create test-service-account2 --display-name "test-service-account2"
Created service account [test-service-account2].



gcloud compute instances create "my-vm-2" \
--machine-type "n1-standard-1" \
--image-project "debian-cloud" \
--image-family "debian-10" \
--subnet "default"



student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$ gcloud container clusters create webfrontend --zone $MY_ZONE --num-nodes 2

WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster webfrontend in us-central1-a... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-fe66d4e862ba/zones/us-central1-a/clusters/webfrontend].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/webfrontend?project=qwiklabs-gcp-00-fe66d4e862ba
kubeconfig entry generated for webfrontend.
NAME         LOCATION       MASTER_VERSION   MASTER_IP       MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
webfrontend  us-central1-a  1.18.16-gke.302  34.123.157.157  e2-medium     1.18.16-gke.302  2          RUNNING
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$

104.154.203.125


nginx        LoadBalancer   10.51.245.111   <pending>     80:31011/TCP   42s
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$ kubectl get services
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP       PORT(S)        AGE
kubernetes   ClusterIP      10.51.240.1     <none>            443/TCP        8m28s
nginx        LoadBalancer   10.51.245.111   104.154.203.125   80:31011/TCP   45s

VPC Networking

gcloud compute networks create managementnet --project=qwiklabs-gcp-03-d0417a0df52c --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-03-d0417a0df52c --range=10.130.0.0/20 --network=managementnet --region=us-central1


gcloud compute networks create privatenet --subnet-mode=custom

gcloud compute networks subnets create privatesubnet-us --network=privatenet --region=us-central1 --range=172.16.0.0/24

gcloud compute networks subnets create privatesubnet-eu --network=privatenet --region=europe-central2 --range=172.20.0.0/20

gcloud compute networks list


gcloud compute networks subnets list --sort-by=NETWORK

gcloud compute --project=qwiklabs-gcp-03-d0417a0df52c firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0


gcloud compute firewall-rules create privatenet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=privatenet --action=ALLOW --rules=icmp,tcp:22,tcp:3389 --source-ranges=0.0.0.0/0


gcloud beta compute --project=qwiklabs-gcp-03-d0417a0df52c instances create managementnet-us-vm --zone=us-central1-c --machine-type=n1-standard-1 --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=378953624177-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210316 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any



gcloud compute instances create privatenet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=privatesubnet-us --image-family=debian-10 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-standard --boot-disk-device-name=privatenet-us-vm



gcloud compute instances list --sort-by=ZONE



Implement Private Google Access and Cloud NAT

To connect to vm-internal, run the following command:

gcloud compute ssh vm-internal --zone us-central1-c --tunnel-through-iap


mybucket13806

gsutil cp gs://cloud-training/gcpnet/private/access.svg gs://mybucket13806

gsutil cp gs://mybucket13806/*.svg .



export SQL_CONNECTION=qwiklabs-gcp-03-a61351f94ea3:us-central1:wordpress-db

10.63.240.2
34.68.23.74

qwiklabs-gcp-04-storecore21778f3f0b95

qwiklabs-gcp-04-storecorede0347cd46b4

mybucket21778f3f0b95

Tr+QuUvSSilbpelcDDT+TfkrIQlnEgwZDdcjfh+j1vI=

+lrNHeRNQ4VMiL1iRDVWfQKQU/ddUs0y17jboebzZbs=

export BUCKET_NAME_1=storecore21778f3f0b95


peering network
gcloud compute target-vpn-gateways create vpn-1 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --network=vpn-network-1

gcloud compute forwarding-rules create vpn-1-rule-esp --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=ESP --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp500 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=UDP --ports=500 --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp4500 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=UDP --ports=4500 --target-vpn-gateway=vpn-1

gcloud compute vpn-tunnels create vpn-1-tunnel-1 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --peer-address=35.233.6.236 --shared-secret=gcprocks --ike-version=2 --local-traffic-selector=0.0.0.0/0 --remote-traffic-selector=0.0.0.0/0 --target-vpn-gateway=vpn-1

gcloud compute routes create vpn-1-tunnel-1-route-1 --project=qwiklabs-gcp-00-9353e3a9e4af --network=vpn-network-1 --priority=1000 --destination-range=10.1.3.0/24 --next-hop-vpn-tunnel=vpn-1-tunnel-1 --next-hop-vpn-tunnel-region=us-central1



gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-image:v0.1

student_00_f82b8b5f83e7@cloudshell:~/gcp-course/devops-repo (qwiklabs-gcp-00-90db9ea27409)$ git push origin master
Enumerating objects: 5, done.
Counting objects: 100% (5/5), done.
Delta compression using up to 2 threads
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 317 bytes | 317.00 KiB/s, done.
Total 3 (delta 2), reused 0 (delta 0)
remote: Resolving deltas: 100% (2/2)
To https://source.developers.google.com/p/qwiklabs-gcp-00-90db9ea27409/r/devops-repo
   f774936..063da15  master -> master
student_00_f82b8b5f83e7@cloudshell:~/gcp-course/devops-repo (qwiklabs-gcp-00-90db9ea27409)$

063da15315ecaeee1e9baeaf5b8f595f7fa9780e
build -t gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e .

gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e

gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e 




gcloud auth list


gcloud config list project

gcloud compute instances create gcelab2 --machine-type n1-standard-2 --zone us-central1-c

gcloud config get-value compute/zone
gcloud config get-value compute/region
gcloud compute project-info describe --project qwiklabs-gcp-00-85a0a8114378

gcloud compute instances create gcelab2 --machine-type n1-standard-2 --zone $ZONE


gcloud config set compute/zone us-central1-a

gcloud container clusters create my-cluster

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters create my-cluster
WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster my-cluster in us-central1-a... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-02-f17e6e96a602/zones/us-central1-a/clusters/my-cluster].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/my-cluster?project=qwiklabs-gcp-02-f17e6e96a602
kubeconfig entry generated for my-cluster.
NAME        LOCATION       MASTER_VERSION   MASTER_IP     MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
my-cluster  us-central1-a  1.18.16-gke.302  34.121.78.52  e2-medium     1.18.16-gke.302  3          RUNNING
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters get-credentials my-cluster
Fetching cluster endpoint and auth data.
kubeconfig entry generated for my-cluster.
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0
deployment.apps/hello-server created
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl expose deployment hello-server --type=LoadBalancer --port 8080
service/hello-server exposed
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
hello-server   LoadBalancer   10.3.251.101   <pending>     8080:32398/TCP   14s
kubernetes     ClusterIP      10.3.240.1     <none>        443/TCP          2m52s
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
hello-server   LoadBalancer   10.3.251.101   34.70.133.95   8080:32398/TCP   41s
kubernetes     ClusterIP      10.3.240.1     <none>         443/TCP          3m19s
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$


gcloud container clusters delete my-cluster

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters delete my-cluster
The following clusters will be deleted.
 - [my-cluster] in [us-central1-a]

Do you want to continue (Y/n)?  y

Deleting cluster my-cluster...done.
Deleted [https://container.googleapis.com/v1/projects/qwiklabs-gcp-02-f17e6e96a602/zones/us-central1-a/clusters/my-cluster].
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

In Cloud Shell, set the default zone:

gcloud config set compute/zone us-central1-a

Set the default region:

gcloud config set compute/region us-central1



    Create three new virtual machines in your default zone and give them all the same tag. The code provided sets the zone to us-central1-a. Setting the tags field lets you reference these instances all at once, such as with a firewall rule. These commands also install Apache on each instance and give each instance a unique home page.

gcloud compute instances create www1 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www1</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances create www2 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www2</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances create www3 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www3</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances list
tudent_00_2e86c9330f72@cloudshell:~ (qwiklabs-gcp-00-52ffa2e76b63)$ gcloud compute instances list
NAME  ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP     STATUS
www1  us-central1-a  n1-standard-1               10.128.0.2   34.123.14.179   RUNNING
www2  us-central1-a  n1-standard-1               10.128.0.3   35.225.110.197  RUNNING
www3  us-central1-a  n1-standard-1               10.128.0.4   35.193.225.168  RUNNING
student_00_2e86c9330f72@cloudshell:~ (qwiklabs-gcp-00-52ffa2e76b63)$




    First, create the load balancer template:

gcloud compute instance-templates create lb-backend-template \
   --region=us-central1 \
   --network=default \
   --subnet=default \
   --tags=allow-health-check \
   --image-family=debian-9 \
   --image-project=debian-cloud \
   --metadata=startup-script='#! /bin/bash
     apt-get update
     apt-get install apache2 -y
     a2ensite default-ssl
     a2enmod ssl
     vm_hostname="$(curl -H "Metadata-Flavor:Google" \
     http://169.254.169.254/computeMetadata/v1/instance/name)"
     echo "Page served from: $vm_hostname" | \
     tee /var/www/html/index.html
     systemctl restart apache2'
	 
	 
	 34.117.170.104
	 
	 
	 ARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster nucleus-webserver1 in us-east1-b... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-a9230877c3b8/zones/us-east1-b/clusters/nucleus-webserver1].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-b/nucleus-webserver1?project=qwiklabs-gcp-00-a9230877c3b8
kubeconfig entry generated for nucleus-webserver1.
NAME                LOCATION    MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
nucleus-webserver1  us-east1-b  1.18.16-gke.502  34.73.125.163  e2-medium     1.18.16-gke.502  3          RUNNING

student_00_8a28695a7131@cloudshell:~ (qwiklabs-gcp-00-a9230877c3b8)$ kubectl get service
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)          AGE
hello-app    LoadBalancer   10.119.247.38   35.231.85.25   8080:31562/TCP   44s
kubernetes   ClusterIP      10.119.240.1    <none>         443/TCP          2m31s
student_00_8a28695a7131@cloudshell:~ (qwiklabs-gcp-00-a9230877c3b8)$





gcloud compute networks create managementnet --project=qwiklabs-gcp-01-3e49a9834b0c --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-01-3e49a9834b0c --range=10.130.0.0/20 --network=managementnet --region=us-central1


kubeconfig entry generated for bootcamp.
NAME      LOCATION       MASTER_VERSION   MASTER_IP       MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
bootcamp  us-central1-a  1.18.16-gke.502  35.238.109.114  e2-medium     1.18.16-gke.502  5          RUNNING
student_01_133a2027419a@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-01-2ac127202402)$ kubectl get services frontend
NAME       TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)         AGE
frontend   LoadBalancer   10.115.245.182   34.66.211.255   443:31384/TCP   47s


NAME  LOCATION       MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
io    us-central1-b  1.18.16-gke.502  34.70.253.157  e2-medium     1.18.16-gke.502  3          RUNNING
student_04_5e78fc7ffc81@cloudshell:~ (qwiklabs-gcp-04-a83a0e5ac5d0)$

student_04_5e78fc7ffc81@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-04-a83a0e5ac5d0)$ kubectl get services
NAME         TYPE           CLUSTER-IP    EXTERNAL-IP    PORT(S)        AGE
kubernetes   ClusterIP      10.3.240.1    <none>         443/TCP        3m8s
nginx        LoadBalancer   10.3.242.44   34.68.26.164   80:30484/TCP   38s


student_00_1c72a9e81e1f@cloudshell:~/continuous-deployment-on-kubernetes (qwiklabs-gcp-00-9d3c450fc854)$ gcloud container clusters create jenkins-cd \
> --num-nodes 2 \
> --machine-type n1-standard-2 \
> --scopes "https://www.googleapis.com/auth/source.read_write,cloud-platform"
WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster jenkins-cd in us-east1-d... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-9d3c450fc854/zones/us-east1-d/clusters/jenkins-cd].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-d/jenkins-cd?project=qwiklabs-gcp-00-9d3c450fc854
kubeconfig entry generated for jenkins-cd.
NAME        LOCATION    MASTER_VERSION   MASTER_IP      MACHINE_TYPE   NODE_VERSION     NUM_NODES  STATUS
jenkins-cd  us-east1-d  1.18.16-gke.502  35.185.79.186  n1-standard-2  1.18.16-gke.502  2          RUNNING
student_00_1c72a9e81e1f@cloudshell:~/continuous-deployment-on-kubernetes (qwiklabs-gcp-00-9d3c450fc854)$



v0.2: digest: sha256:59f9514843d9ce75952b5cd8a090da2ca9b904f637d13498cf2678683e5aae9e size: 3055
DONE
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                 STATUS
9c2cb2ab-4007-43f7-a209-ff30b0ae5fdd  2021-04-14T14:08:53+00:00  47S       gs://qwiklabs-gcp-02-8b7c885c17da_cloudbuild/source/1618409331.045144-be8608a756d14c8289c69f5fb6278d3c.tgz  gcr.io/qwiklabs-gcp-02-8b7c885c17da/devops-image:v0.2  SUCCESS


tudent_02_2c0074e6de54@cloudshell:~/gcp-course/training-data-analyst/courses/design-process/deploying-apps-to-gcp (qwiklabs-gcp-02-8b7c885c17da)$ kubectl get services
NAME                   TYPE           CLUSTER-IP   EXTERNAL-IP    PORT(S)        AGE
devops-deployment-lb   LoadBalancer   10.8.10.6    34.72.68.169   80:31410/TCP   40s
kubernetes             ClusterIP      10.8.0.1     <none>         443/TCP        11m
student_02_2c0074e6de54@cloudshell:~/gcp-course/training-data-analyst/courses/design-process/deploying-apps-to-gcp (qwiklabs-gcp-02-8b7c885c17da)$

v0.1: digest: sha256:4012de105d001335e963023529b74f006d39ebaf0f292f477309a26c3c885f8d size: 3055
DONE
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ID                                    CREATE_TIME                DURATION  SOURCE                                                                                            
          IMAGES                                                    STATUS
345d4a76-8d14-4cd0-bba7-434b84dde254  2021-04-14T14:12:26+00:00  48S       gs://qwiklabs-gcp-02-8b7c885c17da_cloudbuild/source/1618409544.623512-f2008ebae4634532a40ad73fd3fa
0157.tgz  

gcr.io/qwiklabs-gcp-02-8b7c885c17da/cloud-run-image:v0.1  SUCCESS


ab -n 1000 -c 10 https://qwiklabs-gcp-04-569634929eae.appspot.com/


ab -n 1000 -c 10 https://<your-project-id>.appspot.com/




Task 1: Create a project jumphost instance

Navigation menu > Compute engine > VM Instance


Task 2: Create a Kubernetes service cluster

gcloud config set compute/zone us-east1-b

gcloud container clusters create nucleus-webserver1

gcloud container clusters get-credentials nucleus-webserver1

kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:2.0

kubectl expose deployment hello-app --type=LoadBalancer --port 8080

kubectl get service 


Task 3: Setup an HTTP load balancer

cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF

cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF


1 .Create an instance template :

gcloud compute instance-templates create nginx-template \
--metadata-from-file startup-script=startup.sh

2 .Create a target pool :

gcloud compute target-pools create nginx-pool

3 .Create a managed instance group :

gcloud compute instance-groups managed create nginx-group \
--base-instance-name nginx \
--size 2 \
--template nginx-template \
--target-pool nginx-pool

gcloud compute instances list

4 .Create a firewall rule to allow traffic (80/tcp) :

gcloud compute firewall-rules create www-firewall --allow tcp:80

gcloud compute forwarding-rules create nginx-lb \
--region us-east1 \
--ports=80 \
--target-pool nginx-pool

gcloud compute forwarding-rules list

5 .Create a health check :

gcloud compute http-health-checks create http-basic-check

gcloud compute instance-groups managed \
set-named-ports nginx-group \
--named-ports http:80

6 .Create a backend service and attach the manged instance group :

gcloud compute backend-services create nginx-backend \
--protocol HTTP --http-health-checks http-basic-check --global

gcloud compute backend-services add-backend nginx-backend \
--instance-group nginx-group \
--instance-group-zone us-east1-b \
--global

7 .Create a URL map and target HTTP proxy to route requests to your URL map :

gcloud compute url-maps create web-map \
--default-service nginx-backend

gcloud compute target-http-proxies create http-lb-proxy \
--url-map web-map

8 .Create a forwarding rule :

gcloud compute forwarding-rules create http-content-rule \
--global \
--target-http-proxy http-lb-proxy \
--ports 80

gcloud compute forwarding-rules list


Introduction to SQL for BigQuery and Cloud SQL
Add to favorites
Help

25/100
Checkpoints

Create a cloud storage bucket

25 / 25

Upload CSV files to Cloud Storage

0 / 25

Create a Cloud SQL instance

0 / 25

Create a database

0 / 25
Introduction to SQL for BigQuery and Cloud SQL
1 hour 15 minutes Free
GSP281

Google Cloud Self-Paced Labs
Overview

SQL (Structured Query Language) is a standard language for data operations that allows you to ask questions and get insights from structured datasets. It's commonly used in database management and allows you to perform tasks like transaction record writing into relational databases and petabyte-scale data analysis.

This lab serves as an introduction to SQL and is intended to prepare you for the many labs and quests in Qwiklabs on data science topics. This lab is divided into two parts: in the first half, you will learn fundamental SQL querying keywords, which you will run in the BigQuery console on a public dataset that contains information on London bikeshares.

In the second half, you will learn how to export subsets of the London bikeshare dataset into CSV files, which you will then upload to Cloud SQL. From there you will learn how to use Cloud SQL to create and manage databases and tables. Towards the end, you will get hands-on practice with additional SQL keywords that manipulate and edit data.
Objectives

In this lab, you will learn how to:

    Distinguish databases from tables and projects.
    Use the SELECT, FROM, and WHERE keywords to construct simple queries.
    Identify the different components and hierarchies within the BigQuery console.
    Load databases and tables into BigQuery.
    Execute simple queries on tables.
    Learn about the COUNT, GROUP BY, AS, and ORDER BY keywords.
    Execute and chain the above commands to pull meaningful data from datasets.
    Export a subset of data into a CSV file and store that file into a new Cloud Storage bucket.
    Create a new Cloud SQL instance and load your exported CSV file as a new table.
    Run CREATE DATABASE, CREATE TABLE, DELETE, INSERT INTO, and UNION queries in Cloud SQL.

Prerequisites

Very Important: Before starting this lab, log out of your personal or corporate gmail account.

This is a introductory level lab. This assumes little to no prior experience with SQL. Familiarity with Cloud Storage and Cloud Shell is recommended, but not required. This lab will teach you the basics of reading and writing queries in SQL, which you will apply by using BigQuery and Cloud SQL.

Before taking this lab, consider your proficiency in SQL. Below are more challenging labs that will let you apply your knowledge to more advanced use cases:

    Weather Data in BigQuery
    Analyzing Natality Data Using Datalab and BigQuery

Once you're ready, scroll down and follow the steps below to get your lab environment set up.
Setup and Requirements
Before you click the Start Lab button

Read these instructions. Labs are timed and you cannot pause them. The timer, which starts when you click Start Lab, shows how long Google Cloud resources will be made available to you.

This Qwiklabs hands-on lab lets you do the lab activities yourself in a real cloud environment, not in a simulation or demo environment. It does so by giving you new, temporary credentials that you use to sign in and access Google Cloud for the duration of the lab.
What you need

To complete this lab, you need:

    Access to a standard internet browser (Chrome browser recommended).
    Time to complete the lab.

Note: If you already have your own personal Google Cloud account or project, do not use it for this lab.

Note: If you are using a Pixelbook, open an Incognito window to run this lab.
How to start your lab and sign in to the Google Cloud Console

    Click the Start Lab button. If you need to pay for the lab, a pop-up opens for you to select your payment method. On the left is a panel populated with the temporary credentials that you must use for this lab.

    Open Google Console

    Copy the username, and then click Open Google Console. The lab spins up resources, and then opens another tab that shows the Sign in page.

    Sign in

    Tip: Open the tabs in separate windows, side-by-side.
    If you see the Choose an account page, click Use Another Account. Choose an account

    In the Sign in page, paste the username that you copied from the Connection Details panel. Then copy and paste the password.

    Important: You must use the credentials from the Connection Details panel. Do not use your Qwiklabs credentials. If you have your own Google Cloud account, do not use it for this lab (avoids incurring charges).

    Click through the subsequent pages:
        Accept the terms and conditions.
        Do not add recovery options or two-factor authentication (because this is a temporary account).
        Do not sign up for free trials.

After a few moments, the Cloud Console opens in this tab.
Note: You can view the menu with a list of Google Cloud Products and Services by clicking the Navigation menu at the top-left. Cloud Console Menu
The Basics of SQL
Databases and Tables

As mentioned earlier, SQL allows you to get information from "structured datasets". Structured datasets have clear rules and formatting and often times are organized into tables, or data that's formatted in rows and columns.

An example of unstructured data would be an image file. Unstructured data is inoperable with SQL and cannot be stored in BigQuery datasets or tables (at least natively.) To work with image data (for instance), you would use a service like Cloud Vision, perhaps through its API directly.

The following is an example of a structured dataseta simple table:

User
	

Price
	

Shipped

Sean
	

$35
	

Yes

Rocky
	

$50
	

No

If you've had experience with Google Sheets, then the above should look quite similar. As we see, the table has columns for User, Price, and Shipped and two rows that are composed of filled in column values.

A Database is essentially a collection of one or more tables. SQL is a structured database management tool, but quite often (and in this lab) you will be running queries on one or a few tables joined togethernot on whole databases.
SELECT and FROM

SQL is phonetic by nature and before running a query, it's always helpful to first figure out what question you want to ask your data (unless you're just exploring for fun.)

SQL has predefined keywords which you use to translate your question into the pseudo-english SQL syntax so you can get the database engine to return the answer you want.

The most essential keywords are SELECT and FROM:

    Use SELECT to specify what fields you want to pull from your dataset.
    Use FROM to specify what table or tables we want to pull our data from.

An example may help understanding. Assume that we have the following table example_table, which has columns USER, PRICE, and SHIPPED:

14422cb7144f3ae.png

And let's say that we want to just pull the data that's found in the USER column. We can do this by running the following query that uses SELECT and FROM:

SELECT USER FROM example_table

If we executed the above command, we would select all the names from the USER column that are found in example_table.

You can also select multiple columns with the SQL SELECT keyword. Say that you want to pull the data that's found in the USER and SHIPPED columns. To do this, modify the previous query by adding another column value to our SELECT query (making sure it's separated by a comma!):

SELECT USER, SHIPPED FROM example_table

Running the above retrieves the USER and the SHIPPED data from memory:

a4027fb83edf734.png

And just like that you've covered two fundamental SQL keywords! Now to make things a bit more interesting.
WHERE

The WHERE keyword is another SQL command that filters tables for specific column values. Say that you want to pull the names from example_table whose packages were shipped. You can supplement the query with a WHERE, like the following:

SELECT USER FROM example_table WHERE SHIPPED='YES'

Running the above returns all USERs whose packages have been SHIPPED to from memory:

5566150a165277e8.png

Now that you have a baseline understanding of SQL's core keywords, apply what you've learned by running these types of queries in the BigQuery console.
Test your understanding

The following are some multiple choice questions to reinforce your understanding of the concepts covered so far. Answer them to the best of your abilities.

Exploring the BigQuery Console
The BigQuery paradigm

BigQuery is a fully-managed petabyte-scale data warehouse that runs on the Google Cloud. Data analysts and data scientists can quickly query and filter large datasets, aggregate results, and perform complex operations without having to worry about setting up and managing servers. It comes in the form of a command line tool (preinstalled in cloudshell) or a web consoleboth ready for managing and querying data housed in Google Cloud projects.

In this lab, you use the web console to run SQL queries.
Open BigQuery Console

In the Google Cloud Console, select Navigation menu > BigQuery:

BigQuery_menu.png

The Welcome to BigQuery in the Cloud Console message box opens. This message box provides a link to the quickstart guide and the release notes.

Click Done.

The BigQuery console opens.

bq-console.png

Take a moment to note some important features of the UI. The right-hand side of the console houses the query "Editor". This is where you write and run SQL commands like the examples we covered earlier. Below that is "Query history", which is a list of queries you ran previously.

The left pane of the console is the "Navigation panel". Apart from the self-explanatory query history, saved queries, and job history, there is the Explorer tab.

The highest level of resources in Explorer tab contain Google Cloud projects, which are just like the temporary Google Cloud projects you sign in to and use with each Qwiklab. As you can see in your console and in the last screenshot, we only have our Qwiklabs project housed in the Explorer tab. If you try clicking on the arrow next the project name, nothing will show up.

This is because your project doesn't contain any datasets or tables, you have nothing that can be queried. Earlier you learned datasets contain tables. When you add data to your project, note that in BigQuery, projects contain datasets, and datasets contain tables. Now that you better understand the project ? dataset ? table paradigm and the intricacies of the console, you can load up some queryable data.
Uploading queryable data

In this section you pull in some public data into your project so you can practice running SQL commands in BigQuery.

Click on the + ADD DATA link then select Explore public datasets:

BQ_adddata_2.png

In the search bar, enter "london", then select the London Bicycle Hires tile, then View Dataset.

A new tab will open, and you will now have a new project called bigquery-public-data added to the Explorer panel:

BQ_pubdata_2.png

It's important to note that you are still working out of your lab project in this new tab. All you did was pull a publicly accessible project that contains datasets and tables into BigQuery for analysis  you didn't switch over to that project. All of your jobs and services are still tied to your Qwiklabs account. You can see this for yourself by inspecting the project field near the top of the console:

BQ_proj_check_2.png

Expand bigquery-public-data > london_bicycles and select cycle_hire. You now have data that follows the BigQuery paradigm:

    Google Cloud Project ? bigquery-public-data
    Dataset ? london_bicycles
    Table ? cycle_hire

Now that you are in the cycle_hire table, in the center of the console click the Preview tab. Your page should resemble the following:

cycle_hire.png

Inspect the columns and values populated in the rows. You are now ready to run some SQL queries on the cycle_hire table.
Running SELECT, FROM, and WHERE in BigQuery

You now have a basic understanding of SQL querying keywords and the BigQuery data paradigm and some data to work with. Run some SQL commands using this service.

If you look at the bottom right corner of the console, you will notice that there are 24,369,201 rows of data, or individual bikeshare trips taken in London between 2015 and 2017 (not a small amount by any means!)

Now take note of the seventh column key: end_station_name, which specifies the end destination of bikeshare rides. Before we get too deep, let's first run a simple query to isolate the end_station_name column. Copy and paste the following command in to the query EDITOR:

SELECT end_station_name FROM `bigquery-public-data.london_bicycles.cycle_hire`;

Then click Run.

After ~20 seconds, you should be returned with 24369201 rows that contain the single column you queried for: end_station_name.

Why don't you find out how many bike trips were 20 minutes or longer?

Clear the query from the editor, then run the following query that utilizes the WHERE keyword:

SELECT * FROM `bigquery-public-data.london_bicycles.cycle_hire` WHERE duration>=1200;

This query may take a minute or so to run.

SELECT * returns all column values from the table. Duration is measured in seconds, which is why you used the value 1200 (60 * 20).

If you look in the bottom right corner you see that 7,334,890 rows were returned. As a fraction of the total (7334890/24369201), this means that ~30% of London bikeshare rides lasted 20 minutes or longer (they're in it for the long haul!)
Test your understanding

The following are some multiple choice questions to reinforce your understanding of the concepts we've covered so far. Answer them to the best of your abilities.

More SQL Keywords: GROUP BY, COUNT, AS, and ORDER BY
GROUP BY

The GROUP BY keyword will aggregate result-set rows that share common criteria (e.g. a column value) and will return all of the unique entries found for such criteria.

This is a useful keyword for figuring out categorical information on tables. To get a better picture of what this keyword does, clear the query from the editor, then copy and paste the following command:

SELECT start_station_name FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name;

Click Run.

You should receive a similar output (row values may not match the following):

30b04fc6f21c544c.png

Without the GROUP BY, the query would have returned the full 24,369,201 rows. GROUP BY will output the unique (non-duplicate) column values found in the table. You can see this for yourself by looking in the bottom right corner. You will see 880 rows, meaning there are 880 distinct London bikeshare starting points.
COUNT

The COUNT() function will return the number of rows that share the same criteria (e.g. column value). This can be very useful in tandem with a GROUP BY.

Add the COUNT function to our previous query to figure out how many rides begin in each starting point. Clear the query from the editor, then copy and paste the following command and then click Run:

SELECT start_station_name, COUNT(*) FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name;

You should receive a similar output (row values may not match the following):

b62aaf26b7a35e35.png

This shows how many bikeshare rides begin at each starting location.
AS

SQL also has an AS keyword, which creates an alias of a table or column. An alias is a new name that's given to the returned column or tablewhatever AS specifies.

Add an AS keyword to the last query we ran to see this in action. Clear the query from the editor, then copy and paste the following command:

SELECT start_station_name, COUNT(*) AS num_starts FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name;

Click Run.

You should receive a similar output (be aware that the row values might not be identical):

a45a8b122dbfea2b.png

As you see, the COUNT(*) column in the returned table is now set to the alias name num_starts. This is a handy keyword to use especially if you are dealing with large sets of data  forgetting that an ambiguous table or column name happens more often than you think!
ORDER BY

The ORDER BY keyword sorts the returned data from a query in ascending or descending order based on a specified criteria or column value. We will add this keyword to our previous query to do the following:

    Return a table that contains the number of bikeshare rides that begin in each starting station, organized alphabetically by the starting station.
    Return a table that contains the number of bikeshare rides that begin in each starting station, organized numerically from lowest to highest.
    Return a table that contains the number of bikeshare rides that begin in each starting station, organized numerically from highest to lowest.

Each of the commands below is a separate query. For each command, clear the query EDITOR, copy and paste the command in to the query EDITOR, and then click Run. Examine the results.

SELECT start_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name ORDER BY start_station_name;

SELECT start_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name ORDER BY num;

SELECT start_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name ORDER BY num DESC;

The last query should have returned the following:

368742bde0aa54d6.png

We see that "Belgrove Street, King's Cross" has the highest number of starts. However, as a fraction of the total (234458/24369201), we see that < 1% of rides start from this station.
Test your understanding

The following are some multiple choice questions to reinforce your understanding of the concepts we've covered so far. Answer them to the best of your abilities.

Working with Cloud SQL
Exporting queries as CSV files

Cloud SQL is a fully-managed database service that makes it easy to set up, maintain, manage, and administer your relational PostgreSQL and MySQL databases in the cloud. There are two formats of data accepted by Cloud SQL: dump files (.sql) or CSV files (.csv). You will learn how to export subsets of the cycle_hire table into CSV files and upload them to Cloud Storage as an intermediate location.

Back in the BigQuery Console, this should have been the last command that you ran:

SELECT start_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name ORDER BY num DESC;

In the Query Results section click SAVE RESULTS > CSV(local file) > SAVE. This initiates a download, which saves this query as a CSV file. Note the location and the name of this downloaded fileyou will need it soon.

Clear the query EDITOR, then copy and run the following in the query editor:

SELECT end_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY end_station_name ORDER BY num DESC;

This will return a table that contains the number of bikeshare rides that finish in each ending station and is organized numerically from highest to lowest number of rides. You should receive the following output:

814554dc82c60a74.png

In the Query Results section click SAVE RESULTS > CSV(local file) > SAVE. This initiates a download, which saves this query as a CSV file. Note the location and the name of this downloaded fileyou will need it in the following section.
Upload CSV files to Cloud Storage

Go to the Cloud Console where you'll create a storage bucket where you can upload the files you just created.

Select Navigation menu > Storage > Browser, and then click Create bucket.
Note: If prompted, Click LEAVE for Unsaved work.

Enter a unique name for your bucket, keep all other settings, and hit Create:

bucket_details.png
Test Completed Task

Click Check my progress below to check your lab progress. If you successfully created your bucket, you'll see an assessment score.
Create a cloud storage bucket.

You should now be in the Cloud Console looking at your newly created Cloud Storage Bucket.

Click Upload files and select the CSV that contains start_station_name data. Then click Open. Repeat this for the end_station_name data.

Rename your start_station_name file by clicking on the three dots next to on the far side of the file and click rename. Rename the file start_station_data.csv.

Rename your end_station_name file by clicking on the three dots next to on the far side of the file and click rename. Rename the file end_station_data.csv.

Your bucket should now resemble the following:

4ca41c9e381d94f.png
Test Completed Task

Click Check my progress to verify your performed task. If you have successfully upload CSV objects to your bucket, you will see an assessment score.
Upload CSV files to Cloud Storage.
Create a Cloud SQL instance

In the console, select Navigation menu > SQL.

Click Create Instance.

From here, you will be prompted to choose a database engine. Select MySQL.

Now enter in a name for your instance (like "qwiklabs-demo") and enter in a secure password in the Root password field (remember it!), then click CREATE INSTANCE:

CreateInstance.png

It might take a few minutes for the instance to be created. Once it is, you will see a green checkmark next to the instance name.

Click on the Cloud SQL instance. You should now be on a page that resembles the following:

overview.png
Test Completed Task

To check out your lab progress, click Check my progress below.If you have successfully set up your Cloud SQL instance, you will see an assessment score.
Create a CloudSQL Instance.
New Queries in Cloud SQL
CREATE keyword (databases and tables)

Now that you have a Cloud SQL instance up and running, create a database inside of it using the Cloud Shell Command Line.
Activate Cloud Shell

Cloud Shell is a virtual machine that is loaded with development tools. It offers a persistent 5GB home directory and runs on the Google Cloud. Cloud Shell provides command-line access to your Google Cloud resources.

In the Cloud Console, in the top right toolbar, click the Activate Cloud Shell button.

Cloud Shell icon

Click Continue.

cloudshell_continue.png

It takes a few moments to provision and connect to the environment. When you are connected, you are already authenticated, and the project is set to your PROJECT_ID. For example:

Cloud Shell Terminal

gcloud is the command-line tool for Google Cloud. It comes pre-installed on Cloud Shell and supports tab-completion.

You can list the active account name with this command:

gcloud auth list

(Output)

Credentialed accounts:
 - <myaccount>@<mydomain>.com (active)

(Example output)

Credentialed accounts:
 - google1623327_student@qwiklabs.net

You can list the project ID with this command:

gcloud config list project

(Output)

[core]
project = <project_ID>

(Example output)

[core]
project = qwiklabs-gcp-44776a13dea667a6

For full documentation of gcloud see the gcloud command-line tool overview.

Run the following command in Cloud Shell to connect to your SQL instance, replacing qwiklabs-demo if you used a different name for your instance:

gcloud sql connect  qwiklabs-demo --user=root

It may take a minute to connect to your instance.

When prompted, enter the root password you set for the instance.

You should now be on a similar output:

Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 494
Server version: 5.7.14-google-log (Google)

Copyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql>

A Cloud SQL instance comes with pre-configured databases, but you will create your own to store the London bikeshare data.

Run the following command at the MySQL server prompt to create a database called bike:

CREATE DATABASE bike;

You should receive the following output:

Query OK, 1 row affected (0.05 sec)

mysql>

Test Completed Task

Check your progress by clicking Check my progress to verify your performed task. If you have successfully created database in Cloud SQL instance, you will see an assessment score.
Create a database.

Make a table inside of the bike database by running the following command:

USE bike;
CREATE TABLE london1 (start_station_name VARCHAR(255), num INT);

This statement uses the CREATE keyword, but this time it uses the TABLE clause to specify that it wants to build a table instead of a database. The USE keyword specifies a database that you want to connect to. You now have a table named "london1" that contains two columns, "start_station_name" and "num". VARCHAR(255) specifies variable length string column that can hold up to 255 characters and INT is a column of type integer.

Create another table named "london2" by running the following command:

USE bike;
CREATE TABLE london2 (end_station_name VARCHAR(255), num INT);

Now confirm that your empty tables were created. Run the following commands at the MySQL server prompt:

SELECT * FROM london1;
SELECT * FROM london2;

You should receive the following output for both commands:

Empty set (0.04 sec)

It says "empty set" because you haven't loaded in any data yet.
Upload CSV files to tables

Return to the Cloud SQL console. You will now upload the start_station_name and end_station_name CSV files into your newly created london1 and london2 tables.

    In your Cloud SQL instance page, click IMPORT.
    In the Cloud Storage file field, click Browse, and then click the arrow opposite your bucket name, and then click start_station_data.csv. Click Select.
    Select CSV as File format.
    Select the bike database and type in "london1" as your table.
    Click Import:

ImportData

Do the same for the other CSV file.

    In your Cloud SQL instance page, click IMPORT.
    In the Cloud Storage file field, click Browse, and then click the arrow opposite your bucket name, and then click end_station_data.csv Click Select.
    Select CSV as File format.
    Select the bike database and type in "london2" as your table.
    Click Import:

You should now have both CSV files uploaded to tables in the bike database.

Return to your Cloud Shell session and run the following command at the MySQL server prompt to inspect the contents of london1:

SELECT * FROM london1;

You should receive 881 lines of output, one more each unique station name. Your output be formatted like this:

48c3c74603692827.png

Run the following command to make sure that london2 has been populated:

SELECT * FROM london2;

You should receive 883 lines of output, one more each unique station name. Your output be formatted like this:

85a788ec7971f8a0.png
DELETE keyword

Here are a couple more SQL keywords that help us with data management. The first is the DELETE keyword.

Run the following commands in your MySQL session to delete the first row of the london1 and london2:

DELETE FROM london1 WHERE num=0;
DELETE FROM london2 WHERE num=0;

You should receive the following output after running both commands:

Query OK, 1 row affected (0.04 sec)

The rows deleted were the column headers from the CSV files. The DELETE keyword will not remove the first row of the file per se, but all rows of the table where the column name (in this case "num") contains a specified value (in this case "0"). If you run the SELECT * FROM london1; and SELECT * FROM london2; queries and scroll to the top of the table, you will see that those rows no longer exist.
INSERT INTO keyword

You can also insert values into tables with the INSERT INTO keyword. Run the following command to insert a new row into london1, which sets start_station_name to "test destination" and num to "1":

INSERT INTO london1 (start_station_name, num) VALUES ("test destination", 1);

The INSERT INTO keyword requires a table (london1) and will create a new row with columns specified by the terms in the first parenthesis (in this case "start_station_name" and "num"). Whatever comes after the "VALUES" clause will be inserted as values in the new row.

You should receive the following output:

Query OK, 1 row affected (0.05 sec)

If you run the query SELECT * FROM london1; you will see an additional row added at the bottom of the "london1" table:

b067eb36e63b9e68.png
UNION keyword

The last SQL keyword that you'll learn about is UNION. This keyword combines the output of two or more SELECT queries into a result-set. You use UNION to combine subsets of the "london1" and "london2" tables.

The following chained query pulls specific data from both tables and combine them with the UNION operator.

Run the following command at the MySQL server prompt:

SELECT start_station_name AS top_stations, num FROM london1 WHERE num>100000
UNION
SELECT end_station_name, num FROM london2 WHERE num>100000
ORDER BY top_stations DESC;

The first SELECT query selects the two columns from the "london1" table and creates an alias for "start_station_name", which gets set to "top_stations". It uses the WHERE keyword to only pull rideshare station names where over 100,000 bikes start their journey.

The second SELECT query selects the two columns from the "london2" table and uses the WHERE keyword to only pull rideshare station names where over 100,000 bikes end their journey.

The UNION keyword in between combines the output of these queries by assimilating the "london2" data with "london1". Since "london1" is being unioned with "london2", the column values that take precedent are "top_stations" and "num".

ORDER BY will order the final, unioned table by the "top_stations" column value alphabetically and in descending order.

You should receive the following output:

num.png

As you see, 13/14 stations share the top spots for rideshare starting and ending points. With some basic SQL keywords you were able to query a sizable dataset, which returned data points and answers to specific questions.
Congratulations!

In this lab you learned the fundamentals of SQL and how you can apply keywords and run queries in BigQuery and CloudSQL. You were taught the core concepts behind projects, databases, and tables. You practiced with keywords that manipulated and edited data. You learned how to load datasets into BigQuery and you practiced running queries on tables. You learned how to create instances in Cloud SQL and practiced transferring subsets of data into tables contained in databases. You chained and ran queries in Cloud SQL to arrive at some interesting conclusions about London bikesharing starting and ending stations.

quest-badge-two.png Data_Science_125.png cloudsql-quest-badge.png BigQueryBasicsforDataAnalysts-125x135.png MarchMadness02_125.png CloudEngineeringExaPrep_125.pmg Data Catalog Quest Badge.pmg bq_retail_125.png
Finish Your Quest

This self-paced lab is part of the Qwiklabs Quests Data Science on Google Cloud, Scientific Data Processing, Cloud SQL, BigQuery Basics for Data Analysts, NCAA March Madness: Bracketology with Google Cloud, Cloud Engineering, Data Catalog Fundamentals and Applying BQML's Classification, Regression, and Demand Forcastng for Retail Applications. A Quest is a series of related labs that form a learning path. Completing a Quest earns you one of the badges above, to recognize your achievement. You can make your badge (or badges) public and link to them in your online resume or social media account. Enroll in a quest and get immediate completion credit if you've taken this lab. See other available Qwiklabs Quests.
Next Steps / Learn More

Continue your learning with and get more practice with Cloud SQL and BigQuery:

    Weather Data in BigQuery
    Exploring NCAA Data with BigQuery
    Loading Data into Google Cloud SQL
    Cloud SQL with Terraform

Google Cloud Training & Certification

...helps you make the most of Google Cloud technologies. Our classes include technical skills and best practices to help you get up to speed quickly and continue your learning journey. We offer fundamental to advanced level training, with on-demand, live, and virtual options to suit your busy schedule. Certifications help you validate and prove your skill and expertise in Google Cloud technologies.
Manual Last Updated March 30, 2021
Lab Last Tested March 17, 2021

Copyright 2021 Google LLC All rights reserved. Google and the Google logo are trademarks of Google LLC. All other company and product names may be trademarks of the respective companies with which they are associated.
Continue questing
Lab
Introduction to SQL for BigQuery and Cloud SQL
Introductory
GSP281
Overview
Setup and Requirements
The Basics of SQL
Exploring the BigQuery Console
More SQL Keywords: GROUP BY, COUNT, AS, and ORDER BY
Working with Cloud SQL
New Queries in Cloud SQL
Congratulations!





variable "instance_name" {}
variable "instance_zone" {}
variable "instance_type" {
  default = "n1-standard-1"
  }
variable "instance_network" {}

resource "google_compute_instance" "vm_instance" {
  name         = "${var.instance_name}"
  zone         = "${var.instance_zone}"
  machine_type = "${var.instance_type}"
  boot_disk {
    initialize_params {
      image = "debian-cloud/debian-9"
      }
  }
  network_interface {
    network = "${var.instance_network}"
    access_config {
      # Allocate a one-to-one NAT IP to the instance
    }
  }
}

kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:2.0

gcloud container clusters get-credentials my-cluster
kubectl expose deployment hello-app --type=LoadBalancer --port 8080

kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0

Create a cluster (in the us-east1-b zone) to host the service.
Use the Docker container hello-app (gcr.io/google-samples/hello-app:2.0) as a place holder; the team will replace the container with their own work later.
Expose the app on port 8080.

gcr.io/google-samples/hello-app:2.0)

us-east1-b

Create an instance template.
Create a target pool.
Create a managed instance group.
Create a firewall rule to allow traffic (80/tcp).
Create a health check.
Create a backend service, and attach the managed instance group.
Create a URL map, and target the HTTP proxy to route requests to your URL map.
Create a forwarding rule.

gcloud compute instances create nginx1 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
 apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html"
	
gcloud compute instances create nginx2 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
 apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html"

gcloud compute firewall-rules create www-firewall-network-lb \
    --target-tags network-lb-tag --allow tcp:80
	
	

gcloud compute networks create managementnet --project=qwiklabs-gcp-03-637d4d885e32 --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-03-637d4d885e32 --range=10.130.0.0/20 --network=managementnet --region=us-central1

gcloud compute --project=qwiklabs-gcp-03-637d4d885e32 firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0

gcloud beta compute --project=qwiklabs-gcp-03-637d4d885e32 instances create managementnet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=844965241571-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210217 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any


student_02_9985c7b9d67a@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-02-eb3cb8fca754)$ kubectl get services frontend
NAME       TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)         AGE
frontend   LoadBalancer   10.115.249.14   34.67.56.157   443:30698/TCP   65s


docker pull gcr.io/qwiklabs-gcp-01-200aad9a20ed/node-app:0.2
docker run -p 4000:80 -d gcr.io/qwiklabs-gcp-01-200aad9a20ed/node-app:0.2
curl http://localhost:4000

student_01_e1239e502c7d@cloudshell:~ (qwiklabs-gcp-01-b7642adaec72)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
hello-server   LoadBalancer   10.3.254.128   35.184.224.3   8080:31200/TCP   44s
kubernetes     ClusterIP      10.3.240.1     <none>         443/TCP          3m50s
student_01_e1239e502c7d@cloudshell:~ (qwiklabs-gcp-01-b7642adaec72)$



gcloud compute instance-groups managed set-named-ports nginx-group --named-ports http:80



 --------------------Set up and Configure a Cloud Environment in Google Cloud: Challenge Lab:--------------



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

----------------Task 1: Create development VPC manually--------------------

For this task because it is mentioned to develop manually .....
We will perform it manually



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

--------------Task 2: Create production VPC using Deployment Manager--------


gsutil cp -r gs://cloud-training/gsp321/dm .

cd dm

sed -i s/SET_REGION/us-east1/g prod-network.yaml

gcloud deployment-manager deployments create prod-network \
    --config=prod-network.yaml

cd ..


##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

-------------Task 3: Create bastion host----------------------------------------

You can copy the below three commands at a time and run them on the Cloud shell.------

gcloud compute instances create bastion --network-interface=network=griffin-dev-vpc,subnet=griffin-dev-mgmt  --network-interface=network=griffin-prod-vpc,subnet=griffin-prod-mgmt --tags=ssh --zone=us-east1-b

gcloud compute firewall-rules create fw-ssh-dev --source-ranges=0.0.0.0/0 --target-tags ssh --allow=tcp:22 --network=griffin-dev-vpc

gcloud compute firewall-rules create fw-ssh-prod --source-ranges=0.0.0.0/0 --target-tags ssh --allow=tcp:22 --network=griffin-prod-vpc




##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
-------------Task 4: Create and configure Cloud SQL Instance-----------------------

gcloud sql instances create griffin-dev-db --root-password password --region=us-east1

gcloud sql connect griffin-dev-db


sql commands:---
CREATE DATABASE wordpress;
GRANT ALL PRIVILEGES ON wordpress.* TO "wp_user"@"%" IDENTIFIED BY "stormwind_rules";
FLUSH PRIVILEGES;



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
--------------Task 5: Create Kubernetes cluster-------------------------------------

gcloud container clusters create griffin-dev \
  --network griffin-dev-vpc \
  --subnetwork griffin-dev-wp \
  --machine-type n1-standard-4 \
  --num-nodes 2  \
  --zone us-east1-b

ubeconfig entry generated for griffin-dev.
NAME         LOCATION    MASTER_VERSION    MASTER_IP      MACHINE_TYPE   NODE_VERSION      NUM_NODES  STATUS
griffin-dev  us-east1-b  1.18.12-gke.1210  35.231.154.14  n1-standard-4  1.18.12-gke.1210  2          RUNNING
student_01_9e99e6b73110@cloudshell:~ (qwiklabs-gcp-01-28fbed30f737)$

gcloud container clusters get-credentials griffin-dev --zone us-east1-b

cd ~/


##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
---------------------------------Task 6 ,7, 8------------------------------------

gsutil cp -r gs://cloud-training/gsp321/wp-k8s .

cd wp-k8s

sed -i s/username_goes_here/wp_user/g wp-env.yaml

sed -i s/password_goes_here/stormwind_rules/g wp-env.yaml

----------------------------------------------------------------------------------

kubectl create -f wp-env.yaml

gcloud iam service-accounts keys create key.json --iam-account=cloud-sql-proxy@$GOOGLE_CLOUD_PROJECT.iam.gserviceaccount.com

kubectl create secret generic cloudsql-instance-credentials --from-file key.json

----------------------------------------------------------------------------------


I=$(gcloud sql instances describe griffin-dev-db --format="value(connectionName)")

sed -i s/YOUR_SQL_INSTANCE/$I/g wp-deployment.yaml

kubectl create -f wp-deployment.yaml

kubectl create -f wp-service.yaml


thanks :)
##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$ gcloud container clusters create webfrontend --zone $MY_ZONE --num-nodes 2

WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster webfrontend in us-central1-a... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-fe66d4e862ba/zones/us-central1-a/clusters/webfrontend].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/webfrontend?project=qwiklabs-gcp-00-fe66d4e862ba
kubeconfig entry generated for webfrontend.
NAME         LOCATION       MASTER_VERSION   MASTER_IP       MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
webfrontend  us-central1-a  1.18.16-gke.302  34.123.157.157  e2-medium     1.18.16-gke.302  2          RUNNING
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$

104.154.203.125


nginx        LoadBalancer   10.51.245.111   <pending>     80:31011/TCP   42s
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$ kubectl get services
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP       PORT(S)        AGE
kubernetes   ClusterIP      10.51.240.1     <none>            443/TCP        8m28s
nginx        LoadBalancer   10.51.245.111   104.154.203.125   80:31011/TCP   45s

VPC Networking

gcloud compute networks create managementnet --project=qwiklabs-gcp-03-d0417a0df52c --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-03-d0417a0df52c --range=10.130.0.0/20 --network=managementnet --region=us-central1


gcloud compute networks create privatenet --subnet-mode=custom

gcloud compute networks subnets create privatesubnet-us --network=privatenet --region=us-central1 --range=172.16.0.0/24

gcloud compute networks subnets create privatesubnet-eu --network=privatenet --region=europe-central2 --range=172.20.0.0/20

gcloud compute networks list


gcloud compute networks subnets list --sort-by=NETWORK

gcloud compute --project=qwiklabs-gcp-03-d0417a0df52c firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0


gcloud compute firewall-rules create privatenet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=privatenet --action=ALLOW --rules=icmp,tcp:22,tcp:3389 --source-ranges=0.0.0.0/0


gcloud beta compute --project=qwiklabs-gcp-03-d0417a0df52c instances create managementnet-us-vm --zone=us-central1-c --machine-type=n1-standard-1 --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=378953624177-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210316 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any



gcloud compute instances create privatenet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=privatesubnet-us --image-family=debian-10 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-standard --boot-disk-device-name=privatenet-us-vm



gcloud compute instances list --sort-by=ZONE



Implement Private Google Access and Cloud NAT

To connect to vm-internal, run the following command:

gcloud compute ssh vm-internal --zone us-central1-c --tunnel-through-iap


mybucket13806

gsutil cp gs://cloud-training/gcpnet/private/access.svg gs://mybucket13806

gsutil cp gs://mybucket13806/*.svg .



export SQL_CONNECTION=qwiklabs-gcp-03-a61351f94ea3:us-central1:wordpress-db

10.63.240.2
34.68.23.74

qwiklabs-gcp-04-storecore21778f3f0b95

qwiklabs-gcp-04-storecorede0347cd46b4

mybucket21778f3f0b95

Tr+QuUvSSilbpelcDDT+TfkrIQlnEgwZDdcjfh+j1vI=

+lrNHeRNQ4VMiL1iRDVWfQKQU/ddUs0y17jboebzZbs=

export BUCKET_NAME_1=storecore21778f3f0b95


peering network
gcloud compute target-vpn-gateways create vpn-1 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --network=vpn-network-1

gcloud compute forwarding-rules create vpn-1-rule-esp --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=ESP --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp500 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=UDP --ports=500 --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp4500 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=UDP --ports=4500 --target-vpn-gateway=vpn-1

gcloud compute vpn-tunnels create vpn-1-tunnel-1 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --peer-address=35.233.6.236 --shared-secret=gcprocks --ike-version=2 --local-traffic-selector=0.0.0.0/0 --remote-traffic-selector=0.0.0.0/0 --target-vpn-gateway=vpn-1

gcloud compute routes create vpn-1-tunnel-1-route-1 --project=qwiklabs-gcp-00-9353e3a9e4af --network=vpn-network-1 --priority=1000 --destination-range=10.1.3.0/24 --next-hop-vpn-tunnel=vpn-1-tunnel-1 --next-hop-vpn-tunnel-region=us-central1



gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-image:v0.1

student_00_f82b8b5f83e7@cloudshell:~/gcp-course/devops-repo (qwiklabs-gcp-00-90db9ea27409)$ git push origin master
Enumerating objects: 5, done.
Counting objects: 100% (5/5), done.
Delta compression using up to 2 threads
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 317 bytes | 317.00 KiB/s, done.
Total 3 (delta 2), reused 0 (delta 0)
remote: Resolving deltas: 100% (2/2)
To https://source.developers.google.com/p/qwiklabs-gcp-00-90db9ea27409/r/devops-repo
   f774936..063da15  master -> master
student_00_f82b8b5f83e7@cloudshell:~/gcp-course/devops-repo (qwiklabs-gcp-00-90db9ea27409)$

063da15315ecaeee1e9baeaf5b8f595f7fa9780e
build -t gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e .

gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e

gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e 




gcloud auth list


gcloud config list project

gcloud compute instances create gcelab2 --machine-type n1-standard-2 --zone us-central1-c

gcloud config get-value compute/zone
gcloud config get-value compute/region
gcloud compute project-info describe --project qwiklabs-gcp-00-85a0a8114378

gcloud compute instances create gcelab2 --machine-type n1-standard-2 --zone $ZONE


gcloud config set compute/zone us-central1-a

gcloud container clusters create my-cluster

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters create my-cluster
WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster my-cluster in us-central1-a... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-02-f17e6e96a602/zones/us-central1-a/clusters/my-cluster].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/my-cluster?project=qwiklabs-gcp-02-f17e6e96a602
kubeconfig entry generated for my-cluster.
NAME        LOCATION       MASTER_VERSION   MASTER_IP     MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
my-cluster  us-central1-a  1.18.16-gke.302  34.121.78.52  e2-medium     1.18.16-gke.302  3          RUNNING
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters get-credentials my-cluster
Fetching cluster endpoint and auth data.
kubeconfig entry generated for my-cluster.
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0
deployment.apps/hello-server created
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl expose deployment hello-server --type=LoadBalancer --port 8080
service/hello-server exposed
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
hello-server   LoadBalancer   10.3.251.101   <pending>     8080:32398/TCP   14s
kubernetes     ClusterIP      10.3.240.1     <none>        443/TCP          2m52s
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
hello-server   LoadBalancer   10.3.251.101   34.70.133.95   8080:32398/TCP   41s
kubernetes     ClusterIP      10.3.240.1     <none>         443/TCP          3m19s
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$


gcloud container clusters delete my-cluster

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters delete my-cluster
The following clusters will be deleted.
 - [my-cluster] in [us-central1-a]

Do you want to continue (Y/n)?  y

Deleting cluster my-cluster...done.
Deleted [https://container.googleapis.com/v1/projects/qwiklabs-gcp-02-f17e6e96a602/zones/us-central1-a/clusters/my-cluster].
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

In Cloud Shell, set the default zone:

gcloud config set compute/zone us-central1-a

Set the default region:

gcloud config set compute/region us-central1



    Create three new virtual machines in your default zone and give them all the same tag. The code provided sets the zone to us-central1-a. Setting the tags field lets you reference these instances all at once, such as with a firewall rule. These commands also install Apache on each instance and give each instance a unique home page.

gcloud compute instances create www1 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www1</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances create www2 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www2</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances create www3 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www3</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances list
tudent_00_2e86c9330f72@cloudshell:~ (qwiklabs-gcp-00-52ffa2e76b63)$ gcloud compute instances list
NAME  ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP     STATUS
www1  us-central1-a  n1-standard-1               10.128.0.2   34.123.14.179   RUNNING
www2  us-central1-a  n1-standard-1               10.128.0.3   35.225.110.197  RUNNING
www3  us-central1-a  n1-standard-1               10.128.0.4   35.193.225.168  RUNNING
student_00_2e86c9330f72@cloudshell:~ (qwiklabs-gcp-00-52ffa2e76b63)$




    First, create the load balancer template:

gcloud compute instance-templates create lb-backend-template \
   --region=us-central1 \
   --network=default \
   --subnet=default \
   --tags=allow-health-check \
   --image-family=debian-9 \
   --image-project=debian-cloud \
   --metadata=startup-script='#! /bin/bash
     apt-get update
     apt-get install apache2 -y
     a2ensite default-ssl
     a2enmod ssl
     vm_hostname="$(curl -H "Metadata-Flavor:Google" \
     http://169.254.169.254/computeMetadata/v1/instance/name)"
     echo "Page served from: $vm_hostname" | \
     tee /var/www/html/index.html
     systemctl restart apache2'
	 
	 
	 34.117.170.104
	 
	 
	 ARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster nucleus-webserver1 in us-east1-b... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-a9230877c3b8/zones/us-east1-b/clusters/nucleus-webserver1].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-b/nucleus-webserver1?project=qwiklabs-gcp-00-a9230877c3b8
kubeconfig entry generated for nucleus-webserver1.
NAME                LOCATION    MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
nucleus-webserver1  us-east1-b  1.18.16-gke.502  34.73.125.163  e2-medium     1.18.16-gke.502  3          RUNNING

student_00_8a28695a7131@cloudshell:~ (qwiklabs-gcp-00-a9230877c3b8)$ kubectl get service
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)          AGE
hello-app    LoadBalancer   10.119.247.38   35.231.85.25   8080:31562/TCP   44s
kubernetes   ClusterIP      10.119.240.1    <none>         443/TCP          2m31s
student_00_8a28695a7131@cloudshell:~ (qwiklabs-gcp-00-a9230877c3b8)$





gcloud compute networks create managementnet --project=qwiklabs-gcp-01-3e49a9834b0c --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-01-3e49a9834b0c --range=10.130.0.0/20 --network=managementnet --region=us-central1


kubeconfig entry generated for bootcamp.
NAME      LOCATION       MASTER_VERSION   MASTER_IP       MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
bootcamp  us-central1-a  1.18.16-gke.502  35.238.109.114  e2-medium     1.18.16-gke.502  5          RUNNING
student_01_133a2027419a@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-01-2ac127202402)$ kubectl get services frontend
NAME       TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)         AGE
frontend   LoadBalancer   10.115.245.182   34.66.211.255   443:31384/TCP   47s


NAME  LOCATION       MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
io    us-central1-b  1.18.16-gke.502  34.70.253.157  e2-medium     1.18.16-gke.502  3          RUNNING
student_04_5e78fc7ffc81@cloudshell:~ (qwiklabs-gcp-04-a83a0e5ac5d0)$

student_04_5e78fc7ffc81@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-04-a83a0e5ac5d0)$ kubectl get services
NAME         TYPE           CLUSTER-IP    EXTERNAL-IP    PORT(S)        AGE
kubernetes   ClusterIP      10.3.240.1    <none>         443/TCP        3m8s
nginx        LoadBalancer   10.3.242.44   34.68.26.164   80:30484/TCP   38s


student_00_1c72a9e81e1f@cloudshell:~/continuous-deployment-on-kubernetes (qwiklabs-gcp-00-9d3c450fc854)$ gcloud container clusters create jenkins-cd \
> --num-nodes 2 \
> --machine-type n1-standard-2 \
> --scopes "https://www.googleapis.com/auth/source.read_write,cloud-platform"
WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster jenkins-cd in us-east1-d... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-9d3c450fc854/zones/us-east1-d/clusters/jenkins-cd].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-d/jenkins-cd?project=qwiklabs-gcp-00-9d3c450fc854
kubeconfig entry generated for jenkins-cd.
NAME        LOCATION    MASTER_VERSION   MASTER_IP      MACHINE_TYPE   NODE_VERSION     NUM_NODES  STATUS
jenkins-cd  us-east1-d  1.18.16-gke.502  35.185.79.186  n1-standard-2  1.18.16-gke.502  2          RUNNING
student_00_1c72a9e81e1f@cloudshell:~/continuous-deployment-on-kubernetes (qwiklabs-gcp-00-9d3c450fc854)$



v0.2: digest: sha256:59f9514843d9ce75952b5cd8a090da2ca9b904f637d13498cf2678683e5aae9e size: 3055
DONE
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                 STATUS
9c2cb2ab-4007-43f7-a209-ff30b0ae5fdd  2021-04-14T14:08:53+00:00  47S       gs://qwiklabs-gcp-02-8b7c885c17da_cloudbuild/source/1618409331.045144-be8608a756d14c8289c69f5fb6278d3c.tgz  gcr.io/qwiklabs-gcp-02-8b7c885c17da/devops-image:v0.2  SUCCESS


tudent_02_2c0074e6de54@cloudshell:~/gcp-course/training-data-analyst/courses/design-process/deploying-apps-to-gcp (qwiklabs-gcp-02-8b7c885c17da)$ kubectl get services
NAME                   TYPE           CLUSTER-IP   EXTERNAL-IP    PORT(S)        AGE
devops-deployment-lb   LoadBalancer   10.8.10.6    34.72.68.169   80:31410/TCP   40s
kubernetes             ClusterIP      10.8.0.1     <none>         443/TCP        11m
student_02_2c0074e6de54@cloudshell:~/gcp-course/training-data-analyst/courses/design-process/deploying-apps-to-gcp (qwiklabs-gcp-02-8b7c885c17da)$

v0.1: digest: sha256:4012de105d001335e963023529b74f006d39ebaf0f292f477309a26c3c885f8d size: 3055
DONE
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ID                                    CREATE_TIME                DURATION  SOURCE                                                                                            
          IMAGES                                                    STATUS
345d4a76-8d14-4cd0-bba7-434b84dde254  2021-04-14T14:12:26+00:00  48S       gs://qwiklabs-gcp-02-8b7c885c17da_cloudbuild/source/1618409544.623512-f2008ebae4634532a40ad73fd3fa
0157.tgz  

gcr.io/qwiklabs-gcp-02-8b7c885c17da/cloud-run-image:v0.1  SUCCESS


ab -n 1000 -c 10 https://qwiklabs-gcp-04-569634929eae.appspot.com/


ab -n 1000 -c 10 https://<your-project-id>.appspot.com/





Task 1: Create a project jumphost instance

Navigation menu > Compute engine > VM Instance


Task 2: Create a Kubernetes service cluster

gcloud config set compute/zone us-east1-b

gcloud container clusters create nucleus-webserver1

gcloud container clusters get-credentials nucleus-webserver1

kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:2.0

kubectl expose deployment hello-app --type=LoadBalancer --port 8080

kubectl get service 


Task 3: Setup an HTTP load balancer

cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF

cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF


1 .Create an instance template :

gcloud compute instance-templates create nginx-template \
--metadata-from-file startup-script=startup.sh

2 .Create a target pool :

gcloud compute target-pools create nginx-pool

3 .Create a managed instance group :

gcloud compute instance-groups managed create nginx-group \
--base-instance-name nginx \
--size 2 \
--template nginx-template \
--target-pool nginx-pool

gcloud compute instances list

4 .Create a firewall rule to allow traffic (80/tcp) :

gcloud compute firewall-rules create www-firewall --allow tcp:80

gcloud compute forwarding-rules create nginx-lb \
--region us-east1 \
--ports=80 \
--target-pool nginx-pool

gcloud compute forwarding-rules list

5 .Create a health check :

gcloud compute http-health-checks create http-basic-check

gcloud compute instance-groups managed \
set-named-ports nginx-group \
--named-ports http:80

6 .Create a backend service and attach the manged instance group :

gcloud compute backend-services create nginx-backend \
--protocol HTTP --http-health-checks http-basic-check --global

gcloud compute backend-services add-backend nginx-backend \
--instance-group nginx-group \
--instance-group-zone us-east1-b \
--global

7 .Create a URL map and target HTTP proxy to route requests to your URL map :

gcloud compute url-maps create web-map \
--default-service nginx-backend

gcloud compute target-http-proxies create http-lb-proxy \
--url-map web-map

8 .Create a forwarding rule :

gcloud compute forwarding-rules create http-content-rule \
--global \
--target-http-proxy http-lb-proxy \
--ports 80

gcloud compute forwarding-rules list



gcloud compute zones list
gcloud compute zones list | grep us-central1
gcloud config set compute/zone us-central1-b

gcloud compute instances create "my-vm-2" \
--machine-type "n1-standard-1" \
--image-project "debian-cloud" \
--image "debian-9-stretch-v20190213" \
--subnet "default"

student_01_e85d9095ca4e@cloudshell:~ (qwiklabs-gcp-01-777266d3e9f3)$
student_01_e85d9095ca4e@cloudshell:~ (qwiklabs-gcp-01-777266d3e9f3)$ gcloud compute instances create "my-vm-2" \
> --machine-type "n1-standard-1" \
> --image-project "debian-cloud" \
> --image "debian-9-stretch-v20190213" \
> --subnet "default"
Created [https://www.googleapis.com/compute/v1/projects/qwiklabs-gcp-01-777266d3e9f3/zones/us-central1-b/instances/my-vm-2].
WARNING: Some requests generated warnings:
 - The resource 'projects/debian-cloud/global/images/debian-9-stretch-v20190213' is deprecated. A suggested replacement is 'projects/debian-cloud/global/images/debian-9-s
tretch-v20190312'.
NAME     ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP    STATUS
my-vm-2  us-central1-b  n1-standard-1               10.128.0.3   35.222.20.187  RUNNING
student_01_e85d9095ca4e@cloudshell:~ (qwiklabs-gcp-01-777266d3e9f3)$


gcloud compute instances create "my-vm-2" \
> --machine-type "n1-standard-1" \
> --image-project "debian-cloud" \
> --image "debian-9-stretch-v20190213" \
> --subnet "default"


https://niyander.blogspot.com/2020/09/Big%20Data%20and%20Machine%20Learning%20quiz%20answer.html

gcr.io/qwiklabs-gcp-03-fce10dd0479b/devops-repo:ef1495a72524d4fffd9565ab18a3ad9cbcd67f5e 

gcr.io/qwiklabs-gcp-03-fce10dd0479b/devops-image:v0.1
gcr.io/qwiklabs-gcp-03-fce10dd0479b/devops-repo:535d3491a6ba8ba9548afb3a9d6e4715083eb5e7
https://console.cloud.google.com/cloud-build/builds;region=global/0a4309ee-443d-4b1d-b719-b0000162738d;step=0?authuser=2&project=qwiklabs-gcp-03-fce10dd0479b




gcr.io/qwiklabs-gcp-03-2e2100e07441/devops-image:v0.2


35.193.236.52

qwiklabs-gcp-01-50186c5937d1:us-central1:blog-db
34.121.15.242

https://storage.googleapis.com/qwiklabs-gcp-01-50186c5937d1/my-excellent-blog.png

sed -i -e "s/qwiklabs-gcp-04-3515a53d80b0/$DEVSHELL_PROJECT_ID/" mydeploy.yaml

sed -i -e "s/PROJECT_ID/$DEVSHELL_PROJECT_ID/" mydeploy.yaml

sed -i -e "s/ZONE/$MY_ZONE/" mydeploy.yaml

dd if=/dev/urandom | gzip -9 >> /dev/null &

This Linux pipeline forces the CPU to work on compressing a continuous stream of random data.

gsutil mb gs://<my-storage-bucket1380>


Admin user
user
Admin password (Temporary)
E6MkKSVMjfyF

gcloud compute --project=qwiklabs-gcp-01-5700098d951f firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,icmp --source-ranges=0.0.0.0/0


gcloud compute --project=qwiklabs-gcp-01-5700098d951f firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0

gcloud beta compute --project=qwiklabs-gcp-01-5700098d951f instances create managementnet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=631874837590-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210217 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any


gcloud compute instances list --sort-by=ZONE
NAME                 ZONE            MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP     STATUS
mynet-eu-vm          europe-west1-c  n1-standard-1               10.132.0.2   130.211.102.89  RUNNING
managementnet-us-vm  us-central1-c   f1-micro                    10.130.0.2   34.121.160.164  RUNNING
mynet-us-vm          us-central1-c   n1-standard-1               10.128.0.2   35.222.145.135  RUNNING
privatenet-us-vm     us-central1-c   f1-micro                    172.16.0.2   34.123.9.194    RUNNING
student_01_feb12fb61313@cloudshell:~ (qwiklabs-gcp-01-5700098d951f)$


my-storage-bucket138012

gsutil cp gs://cloud-training/gcpnet/private/access.svg gs://my-storage-bucket138012

gsutil cp gs://my-storage-bucket138012/*.svg .

gsutil ls gs://my-storage-bucket138012

gsutil cp gs://my-storage-bucket1380122/sample.txt .


myproj-155a26

myproj-c197c
export BUCKET_NAME_1=155a26_bucket

decryption
VaSql+KA6+0b+IV+H13IxBoiit2RbOvVaeAUNs6zdpg=

45gBD+wmAoFgjAWI5RXUY9Pb1JN7QP3FCFt61ZoRS1w=


student_04_84e0100ca6ed@cloudshell:~ (qwiklabs-gcp-04-155a262b192b)$ gsutil ls -a gs://$BUCKET_NAME_1/setup.html
gs://myproj-155a26/setup.html#1614230131009289
gs://myproj-155a26/setup.html#1614231129184244
gs://myproj-155a26/setup.html#1614231153790239

export VERSION_NAME=gs://myproj-155a26/setup.html#1614230131009289

vpn-2-static-ip
34.76.178.85

vpn-1-static-ip
34.72.18.250
gcprocks

HTTP	35.244.196.221:80	Premium
HTTP	[2600:1901:0:1cb5::]:80	Premium



nPzgN+q/8Y2StdzUkigPn1PGA5+pGSIP

dcHnYIjjzvYo0ClUZTfRMRkJtP7vEsst


gcloud compute target-vpn-gateways create vpn-1 --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --network=vpn-network-1

gcloud compute forwarding-rules create vpn-1-rule-esp --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --address=34.72.18.250 --ip-protocol=ESP --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp500 --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --address=34.72.18.250 --ip-protocol=UDP --ports=500 --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp4500 --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --address=34.72.18.250 --ip-protocol=UDP --ports=4500 --target-vpn-gateway=vpn-1

gcloud compute vpn-tunnels create tunnel1to2 --project=qwiklabs-gcp-04-75c147194c21 --region=us-central1 --peer-address=35.229.93.165 --shared-secret=NZDG0LhMlTGTI9twTwPw6zmTeBtmm68e --ike-version=1 --local-traffic-selector=0.0.0.0/0 --remote-traffic-selector=0.0.0.0/0 --target-vpn-gateway=vpn-1

gcloud compute routes create tunnel1to2-route-1 --project=qwiklabs-gcp-04-75c147194c21 --network=vpn-network-1 --priority=1000 --destination-range=10.1.3.0/24 --next-hop-vpn-tunnel=tunnel1to2 --next-hop-vpn-tunnel-region=us-central1



resources:
# Create the auto-mode network
- name: mynetwork
  type: compute.v1.network
  properties:
    autoCreateSubnetworks: true

# Create the firewall rule
- name: mynetwork-allow-http-ssh-rdp-icmp
  type: compute.v1.firewall
  properties:
    network: $(ref.mynetwork.selfLink)
    sourceRanges: ["0.0.0.0/0"]
    allowed:
    - IPProtocol: TCP
      ports: [22, 80, 3389]
    - IPProtocol: ICMP
	
	
variable "instance_name" {}
variable "instance_zone" {}
variable "instance_type" {
  default = "n1-standard-1"
  }
variable "instance_network" {}

resource "google_compute_instance" "vm_instance" {
  name         = "${var.instance_name}"
  zone         = "${var.instance_zone}"
  machine_type = "${var.instance_type}"
  boot_disk {
    initialize_params {
      image = "debian-cloud/debian-9"
      }
  }
  network_interface {
    network = "${var.instance_network}"
    access_config {
      # Allocate a one-to-one NAT IP to the instance
    }
  }
}

kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:2.0

gcloud container clusters get-credentials my-cluster
kubectl expose deployment hello-app --type=LoadBalancer --port 8080

kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0

Create a cluster (in the us-east1-b zone) to host the service.
Use the Docker container hello-app (gcr.io/google-samples/hello-app:2.0) as a place holder; the team will replace the container with their own work later.
Expose the app on port 8080.

gcr.io/google-samples/hello-app:2.0)

us-east1-b

Create an instance template.
Create a target pool.
Create a managed instance group.
Create a firewall rule to allow traffic (80/tcp).
Create a health check.
Create a backend service, and attach the managed instance group.
Create a URL map, and target the HTTP proxy to route requests to your URL map.
Create a forwarding rule.

gcloud compute instances create nginx1 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
 apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html"
	
gcloud compute instances create nginx2 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
 apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html"

gcloud compute firewall-rules create www-firewall-network-lb \
    --target-tags network-lb-tag --allow tcp:80
	
	
gcloud compute networks create managementnet --project=qwiklabs-gcp-03-637d4d885e32 --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-03-637d4d885e32 --range=10.130.0.0/20 --network=managementnet --region=us-central1

gcloud compute --project=qwiklabs-gcp-03-637d4d885e32 firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0

gcloud beta compute --project=qwiklabs-gcp-03-637d4d885e32 instances create managementnet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=844965241571-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210217 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any


student_02_9985c7b9d67a@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-02-eb3cb8fca754)$ kubectl get services frontend
NAME       TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)         AGE
frontend   LoadBalancer   10.115.249.14   34.67.56.157   443:30698/TCP   65s


docker pull gcr.io/qwiklabs-gcp-01-200aad9a20ed/node-app:0.2
docker run -p 4000:80 -d gcr.io/qwiklabs-gcp-01-200aad9a20ed/node-app:0.2
curl http://localhost:4000

student_01_e1239e502c7d@cloudshell:~ (qwiklabs-gcp-01-b7642adaec72)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
hello-server   LoadBalancer   10.3.254.128   35.184.224.3   8080:31200/TCP   44s
kubernetes     ClusterIP      10.3.240.1     <none>         443/TCP          3m50s
student_01_e1239e502c7d@cloudshell:~ (qwiklabs-gcp-01-b7642adaec72)$



gcloud compute instance-groups managed set-named-ports nginx-group --named-ports http:80

 --------------------Set up and Configure a Cloud Environment in Google Cloud: Challenge Lab:--------------



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

----------------Task 1: Create development VPC manually--------------------

For this task because it is mentioned to develop manually .....
We will perform it manually



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

--------------Task 2: Create production VPC using Deployment Manager--------


gsutil cp -r gs://cloud-training/gsp321/dm .

cd dm

sed -i s/SET_REGION/us-east1/g prod-network.yaml

gcloud deployment-manager deployments create prod-network \
    --config=prod-network.yaml

cd ..


##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

-------------Task 3: Create bastion host----------------------------------------

You can copy the below three commands at a time and run them on the Cloud shell.------

gcloud compute instances create bastion --network-interface=network=griffin-dev-vpc,subnet=griffin-dev-mgmt  --network-interface=network=griffin-prod-vpc,subnet=griffin-prod-mgmt --tags=ssh --zone=us-east1-b

gcloud compute firewall-rules create fw-ssh-dev --source-ranges=0.0.0.0/0 --target-tags ssh --allow=tcp:22 --network=griffin-dev-vpc

gcloud compute firewall-rules create fw-ssh-prod --source-ranges=0.0.0.0/0 --target-tags ssh --allow=tcp:22 --network=griffin-prod-vpc




##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
-------------Task 4: Create and configure Cloud SQL Instance-----------------------

gcloud sql instances create griffin-dev-db --root-password password --region=us-east1

gcloud sql connect griffin-dev-db


sql commands:---
CREATE DATABASE wordpress;
GRANT ALL PRIVILEGES ON wordpress.* TO "wp_user"@"%" IDENTIFIED BY "stormwind_rules";
FLUSH PRIVILEGES;



##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
--------------Task 5: Create Kubernetes cluster-------------------------------------

gcloud container clusters create griffin-dev \
  --network griffin-dev-vpc \
  --subnetwork griffin-dev-wp \
  --machine-type n1-standard-4 \
  --num-nodes 2  \
  --zone us-east1-b

ubeconfig entry generated for griffin-dev.
NAME         LOCATION    MASTER_VERSION    MASTER_IP      MACHINE_TYPE   NODE_VERSION      NUM_NODES  STATUS
griffin-dev  us-east1-b  1.18.12-gke.1210  35.231.154.14  n1-standard-4  1.18.12-gke.1210  2          RUNNING
student_01_9e99e6b73110@cloudshell:~ (qwiklabs-gcp-01-28fbed30f737)$

gcloud container clusters get-credentials griffin-dev --zone us-east1-b

cd ~/


##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************
---------------------------------Task 6 ,7, 8------------------------------------

gsutil cp -r gs://cloud-training/gsp321/wp-k8s .

cd wp-k8s

sed -i s/username_goes_here/wp_user/g wp-env.yaml

sed -i s/password_goes_here/stormwind_rules/g wp-env.yaml

----------------------------------------------------------------------------------

kubectl create -f wp-env.yaml

gcloud iam service-accounts keys create key.json --iam-account=cloud-sql-proxy@$GOOGLE_CLOUD_PROJECT.iam.gserviceaccount.com

kubectl create secret generic cloudsql-instance-credentials --from-file key.json

----------------------------------------------------------------------------------


I=$(gcloud sql instances describe griffin-dev-db --format="value(connectionName)")

sed -i s/YOUR_SQL_INSTANCE/$I/g wp-deployment.yaml

kubectl create -f wp-deployment.yaml

kubectl create -f wp-service.yaml


thanks :)
##############################################################################################################################
If you are getting help from our channel, we request you to subscribe to Prakash Foundation, this is the only way to help us.
#############################################################################################################################
******************************************************************************************************************************

MY_BUCKET_NAME_1=my_storage
MY_BUCKET_NAME_2=my_storage_2
MY_REGION=us-central1

Created [https://www.googleapis.com/compute/v1/projects/qwiklabs-gcp-00-cfe3de25623f/zones/us-central1-c/instances/second-vm].
NAME       ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP     STATUS
second-vm  us-central1-c  e2-standard-2               10.128.0.3   146.148.52.169  RUNNING
student_00_2f9893063cc6@cloudshell:~ (qwiklabs-gcp-00-cfe3de25623f)$ gcloud compute instances list
NAME       ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP      STATUS
first-vm   us-central1-c  e2-micro                    10.128.0.2   104.197.222.196  RUNNING
second-vm  us-central1-c  e2-standard-2               10.128.0.3   146.148.52.169   RUNNING
student_00_2f9893063cc6@cloudshell:~ (qwiklabs-gcp-00-cfe3de25623f)$ gcloud iam service-accounts create test-service-account2 --display-name "test-service-account2"
Created service account [test-service-account2].



gcloud compute instances create "my-vm-2" \
--machine-type "n1-standard-1" \
--image-project "debian-cloud" \
--image-family "debian-10" \
--subnet "default"



student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$ gcloud container clusters create webfrontend --zone $MY_ZONE --num-nodes 2

WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster webfrontend in us-central1-a... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-fe66d4e862ba/zones/us-central1-a/clusters/webfrontend].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/webfrontend?project=qwiklabs-gcp-00-fe66d4e862ba
kubeconfig entry generated for webfrontend.
NAME         LOCATION       MASTER_VERSION   MASTER_IP       MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
webfrontend  us-central1-a  1.18.16-gke.302  34.123.157.157  e2-medium     1.18.16-gke.302  2          RUNNING
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$

104.154.203.125


nginx        LoadBalancer   10.51.245.111   <pending>     80:31011/TCP   42s
student_00_bd63618217c1@cloudshell:~ (qwiklabs-gcp-00-fe66d4e862ba)$ kubectl get services
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP       PORT(S)        AGE
kubernetes   ClusterIP      10.51.240.1     <none>            443/TCP        8m28s
nginx        LoadBalancer   10.51.245.111   104.154.203.125   80:31011/TCP   45s

VPC Networking

gcloud compute networks create managementnet --project=qwiklabs-gcp-03-d0417a0df52c --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-03-d0417a0df52c --range=10.130.0.0/20 --network=managementnet --region=us-central1


gcloud compute networks create privatenet --subnet-mode=custom

gcloud compute networks subnets create privatesubnet-us --network=privatenet --region=us-central1 --range=172.16.0.0/24

gcloud compute networks subnets create privatesubnet-eu --network=privatenet --region=europe-central2 --range=172.20.0.0/20

gcloud compute networks list


gcloud compute networks subnets list --sort-by=NETWORK

gcloud compute --project=qwiklabs-gcp-03-d0417a0df52c firewall-rules create managementnet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=managementnet --action=ALLOW --rules=tcp:22,tcp:3389,icmp --source-ranges=0.0.0.0/0


gcloud compute firewall-rules create privatenet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=privatenet --action=ALLOW --rules=icmp,tcp:22,tcp:3389 --source-ranges=0.0.0.0/0


gcloud beta compute --project=qwiklabs-gcp-03-d0417a0df52c instances create managementnet-us-vm --zone=us-central1-c --machine-type=n1-standard-1 --subnet=managementsubnet-us --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=378953624177-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --image=debian-10-buster-v20210316 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-balanced --boot-disk-device-name=managementnet-us-vm --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any



gcloud compute instances create privatenet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=privatesubnet-us --image-family=debian-10 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-standard --boot-disk-device-name=privatenet-us-vm



gcloud compute instances list --sort-by=ZONE



Implement Private Google Access and Cloud NAT

To connect to vm-internal, run the following command:

gcloud compute ssh vm-internal --zone us-central1-c --tunnel-through-iap


mybucket13806

gsutil cp gs://cloud-training/gcpnet/private/access.svg gs://mybucket13806

gsutil cp gs://mybucket13806/*.svg .



export SQL_CONNECTION=qwiklabs-gcp-03-a61351f94ea3:us-central1:wordpress-db

10.63.240.2
34.68.23.74

qwiklabs-gcp-04-storecore21778f3f0b95

qwiklabs-gcp-04-storecorede0347cd46b4

mybucket21778f3f0b95

Tr+QuUvSSilbpelcDDT+TfkrIQlnEgwZDdcjfh+j1vI=

+lrNHeRNQ4VMiL1iRDVWfQKQU/ddUs0y17jboebzZbs=

export BUCKET_NAME_1=storecore21778f3f0b95


peering network
gcloud compute target-vpn-gateways create vpn-1 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --network=vpn-network-1

gcloud compute forwarding-rules create vpn-1-rule-esp --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=ESP --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp500 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=UDP --ports=500 --target-vpn-gateway=vpn-1

gcloud compute forwarding-rules create vpn-1-rule-udp4500 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --address=34.71.4.242 --ip-protocol=UDP --ports=4500 --target-vpn-gateway=vpn-1

gcloud compute vpn-tunnels create vpn-1-tunnel-1 --project=qwiklabs-gcp-00-9353e3a9e4af --region=us-central1 --peer-address=35.233.6.236 --shared-secret=gcprocks --ike-version=2 --local-traffic-selector=0.0.0.0/0 --remote-traffic-selector=0.0.0.0/0 --target-vpn-gateway=vpn-1

gcloud compute routes create vpn-1-tunnel-1-route-1 --project=qwiklabs-gcp-00-9353e3a9e4af --network=vpn-network-1 --priority=1000 --destination-range=10.1.3.0/24 --next-hop-vpn-tunnel=vpn-1-tunnel-1 --next-hop-vpn-tunnel-region=us-central1



gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-image:v0.1

student_00_f82b8b5f83e7@cloudshell:~/gcp-course/devops-repo (qwiklabs-gcp-00-90db9ea27409)$ git push origin master
Enumerating objects: 5, done.
Counting objects: 100% (5/5), done.
Delta compression using up to 2 threads
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 317 bytes | 317.00 KiB/s, done.
Total 3 (delta 2), reused 0 (delta 0)
remote: Resolving deltas: 100% (2/2)
To https://source.developers.google.com/p/qwiklabs-gcp-00-90db9ea27409/r/devops-repo
   f774936..063da15  master -> master
student_00_f82b8b5f83e7@cloudshell:~/gcp-course/devops-repo (qwiklabs-gcp-00-90db9ea27409)$

063da15315ecaeee1e9baeaf5b8f595f7fa9780e
build -t gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e .

gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e

gcr.io/qwiklabs-gcp-00-90db9ea27409/devops-repo:063da15315ecaeee1e9baeaf5b8f595f7fa9780e 




gcloud auth list


gcloud config list project

gcloud compute instances create gcelab2 --machine-type n1-standard-2 --zone us-central1-c

gcloud config get-value compute/zone
gcloud config get-value compute/region
gcloud compute project-info describe --project qwiklabs-gcp-00-85a0a8114378

gcloud compute instances create gcelab2 --machine-type n1-standard-2 --zone $ZONE


gcloud config set compute/zone us-central1-a

gcloud container clusters create my-cluster

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters create my-cluster
WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster my-cluster in us-central1-a... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-02-f17e6e96a602/zones/us-central1-a/clusters/my-cluster].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/my-cluster?project=qwiklabs-gcp-02-f17e6e96a602
kubeconfig entry generated for my-cluster.
NAME        LOCATION       MASTER_VERSION   MASTER_IP     MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
my-cluster  us-central1-a  1.18.16-gke.302  34.121.78.52  e2-medium     1.18.16-gke.302  3          RUNNING
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters get-credentials my-cluster
Fetching cluster endpoint and auth data.
kubeconfig entry generated for my-cluster.
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0
deployment.apps/hello-server created
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl expose deployment hello-server --type=LoadBalancer --port 8080
service/hello-server exposed
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
hello-server   LoadBalancer   10.3.251.101   <pending>     8080:32398/TCP   14s
kubernetes     ClusterIP      10.3.240.1     <none>        443/TCP          2m52s
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ kubectl get service
NAME           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
hello-server   LoadBalancer   10.3.251.101   34.70.133.95   8080:32398/TCP   41s
kubernetes     ClusterIP      10.3.240.1     <none>         443/TCP          3m19s
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$


gcloud container clusters delete my-cluster

student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$ gcloud container clusters delete my-cluster
The following clusters will be deleted.
 - [my-cluster] in [us-central1-a]

Do you want to continue (Y/n)?  y

Deleting cluster my-cluster...done.
Deleted [https://container.googleapis.com/v1/projects/qwiklabs-gcp-02-f17e6e96a602/zones/us-central1-a/clusters/my-cluster].
student_02_b1050a8122e7@cloudshell:~ (qwiklabs-gcp-02-f17e6e96a602)$

In Cloud Shell, set the default zone:

gcloud config set compute/zone us-central1-a

Set the default region:

gcloud config set compute/region us-central1



    Create three new virtual machines in your default zone and give them all the same tag. The code provided sets the zone to us-central1-a. Setting the tags field lets you reference these instances all at once, such as with a firewall rule. These commands also install Apache on each instance and give each instance a unique home page.

gcloud compute instances create www1 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www1</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances create www2 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www2</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances create www3 \
  --image-family debian-9 \
  --image-project debian-cloud \
  --zone us-central1-a \
  --tags network-lb-tag \
  --metadata startup-script="#! /bin/bash
    sudo apt-get update
    sudo apt-get install apache2 -y
    sudo service apache2 restart
    echo '<!doctype html><html><body><h1>www3</h1></body></html>' | tee /var/www/html/index.html"

gcloud compute instances list
tudent_00_2e86c9330f72@cloudshell:~ (qwiklabs-gcp-00-52ffa2e76b63)$ gcloud compute instances list
NAME  ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP     STATUS
www1  us-central1-a  n1-standard-1               10.128.0.2   34.123.14.179   RUNNING
www2  us-central1-a  n1-standard-1               10.128.0.3   35.225.110.197  RUNNING
www3  us-central1-a  n1-standard-1               10.128.0.4   35.193.225.168  RUNNING
student_00_2e86c9330f72@cloudshell:~ (qwiklabs-gcp-00-52ffa2e76b63)$




    First, create the load balancer template:

gcloud compute instance-templates create lb-backend-template \
   --region=us-central1 \
   --network=default \
   --subnet=default \
   --tags=allow-health-check \
   --image-family=debian-9 \
   --image-project=debian-cloud \
   --metadata=startup-script='#! /bin/bash
     apt-get update
     apt-get install apache2 -y
     a2ensite default-ssl
     a2enmod ssl
     vm_hostname="$(curl -H "Metadata-Flavor:Google" \
     http://169.254.169.254/computeMetadata/v1/instance/name)"
     echo "Page served from: $vm_hostname" | \
     tee /var/www/html/index.html
     systemctl restart apache2'
	 
	 
	 34.117.170.104
	 
	 
	 ARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster nucleus-webserver1 in us-east1-b... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-a9230877c3b8/zones/us-east1-b/clusters/nucleus-webserver1].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-b/nucleus-webserver1?project=qwiklabs-gcp-00-a9230877c3b8
kubeconfig entry generated for nucleus-webserver1.
NAME                LOCATION    MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
nucleus-webserver1  us-east1-b  1.18.16-gke.502  34.73.125.163  e2-medium     1.18.16-gke.502  3          RUNNING

student_00_8a28695a7131@cloudshell:~ (qwiklabs-gcp-00-a9230877c3b8)$ kubectl get service
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)          AGE
hello-app    LoadBalancer   10.119.247.38   35.231.85.25   8080:31562/TCP   44s
kubernetes   ClusterIP      10.119.240.1    <none>         443/TCP          2m31s
student_00_8a28695a7131@cloudshell:~ (qwiklabs-gcp-00-a9230877c3b8)$





gcloud compute networks create managementnet --project=qwiklabs-gcp-01-3e49a9834b0c --subnet-mode=custom --mtu=1460 --bgp-routing-mode=regional

gcloud compute networks subnets create managementsubnet-us --project=qwiklabs-gcp-01-3e49a9834b0c --range=10.130.0.0/20 --network=managementnet --region=us-central1


kubeconfig entry generated for bootcamp.
NAME      LOCATION       MASTER_VERSION   MASTER_IP       MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
bootcamp  us-central1-a  1.18.16-gke.502  35.238.109.114  e2-medium     1.18.16-gke.502  5          RUNNING
student_01_133a2027419a@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-01-2ac127202402)$ kubectl get services frontend
NAME       TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)         AGE
frontend   LoadBalancer   10.115.245.182   34.66.211.255   443:31384/TCP   47s


NAME  LOCATION       MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
io    us-central1-b  1.18.16-gke.502  34.70.253.157  e2-medium     1.18.16-gke.502  3          RUNNING
student_04_5e78fc7ffc81@cloudshell:~ (qwiklabs-gcp-04-a83a0e5ac5d0)$

student_04_5e78fc7ffc81@cloudshell:~/orchestrate-with-kubernetes/kubernetes (qwiklabs-gcp-04-a83a0e5ac5d0)$ kubectl get services
NAME         TYPE           CLUSTER-IP    EXTERNAL-IP    PORT(S)        AGE
kubernetes   ClusterIP      10.3.240.1    <none>         443/TCP        3m8s
nginx        LoadBalancer   10.3.242.44   34.68.26.164   80:30484/TCP   38s


student_00_1c72a9e81e1f@cloudshell:~/continuous-deployment-on-kubernetes (qwiklabs-gcp-00-9d3c450fc854)$ gcloud container clusters create jenkins-cd \
> --num-nodes 2 \
> --machine-type n1-standard-2 \
> --scopes "https://www.googleapis.com/auth/source.read_write,cloud-platform"
WARNING: Starting in January 2021, clusters will use the Regular release channel by default when `--cluster-version`, `--release-channel`, `--no-enable-autoupgrade`, and `--no-enable-autorepair` flags are not specified.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting with version 1.18, clusters will have shielded GKE nodes by default.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).
WARNING: Starting with version 1.19, newly created clusters and node-pools will have COS_CONTAINERD as the default node image when no image type is specified.
Creating cluster jenkins-cd in us-east1-d... Cluster is being health-checked (master is healthy)...done.
Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-00-9d3c450fc854/zones/us-east1-d/clusters/jenkins-cd].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-d/jenkins-cd?project=qwiklabs-gcp-00-9d3c450fc854
kubeconfig entry generated for jenkins-cd.
NAME        LOCATION    MASTER_VERSION   MASTER_IP      MACHINE_TYPE   NODE_VERSION     NUM_NODES  STATUS
jenkins-cd  us-east1-d  1.18.16-gke.502  35.185.79.186  n1-standard-2  1.18.16-gke.502  2          RUNNING
student_00_1c72a9e81e1f@cloudshell:~/continuous-deployment-on-kubernetes (qwiklabs-gcp-00-9d3c450fc854)$



v0.2: digest: sha256:59f9514843d9ce75952b5cd8a090da2ca9b904f637d13498cf2678683e5aae9e size: 3055
DONE
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                 STATUS
9c2cb2ab-4007-43f7-a209-ff30b0ae5fdd  2021-04-14T14:08:53+00:00  47S       gs://qwiklabs-gcp-02-8b7c885c17da_cloudbuild/source/1618409331.045144-be8608a756d14c8289c69f5fb6278d3c.tgz  gcr.io/qwiklabs-gcp-02-8b7c885c17da/devops-image:v0.2  SUCCESS


tudent_02_2c0074e6de54@cloudshell:~/gcp-course/training-data-analyst/courses/design-process/deploying-apps-to-gcp (qwiklabs-gcp-02-8b7c885c17da)$ kubectl get services
NAME                   TYPE           CLUSTER-IP   EXTERNAL-IP    PORT(S)        AGE
devops-deployment-lb   LoadBalancer   10.8.10.6    34.72.68.169   80:31410/TCP   40s
kubernetes             ClusterIP      10.8.0.1     <none>         443/TCP        11m
student_02_2c0074e6de54@cloudshell:~/gcp-course/training-data-analyst/courses/design-process/deploying-apps-to-gcp (qwiklabs-gcp-02-8b7c885c17da)$

v0.1: digest: sha256:4012de105d001335e963023529b74f006d39ebaf0f292f477309a26c3c885f8d size: 3055
DONE
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ID                                    CREATE_TIME                DURATION  SOURCE                                                                                            
          IMAGES                                                    STATUS
345d4a76-8d14-4cd0-bba7-434b84dde254  2021-04-14T14:12:26+00:00  48S       gs://qwiklabs-gcp-02-8b7c885c17da_cloudbuild/source/1618409544.623512-f2008ebae4634532a40ad73fd3fa
0157.tgz  

gcr.io/qwiklabs-gcp-02-8b7c885c17da/cloud-run-image:v0.1  SUCCESS


ab -n 1000 -c 10 https://qwiklabs-gcp-04-569634929eae.appspot.com/


ab -n 1000 -c 10 https://<your-project-id>.appspot.com/




Task 1: Create a project jumphost instance

Navigation menu > Compute engine > VM Instance


Task 2: Create a Kubernetes service cluster

gcloud config set compute/zone us-east1-b

gcloud container clusters create nucleus-webserver1

gcloud container clusters get-credentials nucleus-webserver1

kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:2.0

kubectl expose deployment hello-app --type=LoadBalancer --port 8080

kubectl get service 


Task 3: Setup an HTTP load balancer

cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF

cat << EOF > startup.sh
#! /bin/bash
apt-get update
apt-get install -y nginx
service nginx start
sed -i -- 's/nginx/Google Cloud Platform - '"\$HOSTNAME"'/' /var/www/html/index.nginx-debian.html
EOF


1 .Create an instance template :

gcloud compute instance-templates create nginx-template \
--metadata-from-file startup-script=startup.sh

2 .Create a target pool :

gcloud compute target-pools create nginx-pool

3 .Create a managed instance group :

gcloud compute instance-groups managed create nginx-group \
--base-instance-name nginx \
--size 2 \
--template nginx-template \
--target-pool nginx-pool

gcloud compute instances list

4 .Create a firewall rule to allow traffic (80/tcp) :

gcloud compute firewall-rules create www-firewall --allow tcp:80

gcloud compute forwarding-rules create nginx-lb \
--region us-east1 \
--ports=80 \
--target-pool nginx-pool

gcloud compute forwarding-rules list

5 .Create a health check :

gcloud compute http-health-checks create http-basic-check

gcloud compute instance-groups managed \
set-named-ports nginx-group \
--named-ports http:80

6 .Create a backend service and attach the manged instance group :

gcloud compute backend-services create nginx-backend \
--protocol HTTP --http-health-checks http-basic-check --global

gcloud compute backend-services add-backend nginx-backend \
--instance-group nginx-group \
--instance-group-zone us-east1-b \
--global

7 .Create a URL map and target HTTP proxy to route requests to your URL map :

gcloud compute url-maps create web-map \
--default-service nginx-backend

gcloud compute target-http-proxies create http-lb-proxy \
--url-map web-map

8 .Create a forwarding rule :

gcloud compute forwarding-rules create http-content-rule \
--global \
--target-http-proxy http-lb-proxy \
--ports 80

gcloud compute forwarding-rules list


Introduction to SQL for BigQuery and Cloud SQL
Add to favorites
Help

25/100
Checkpoints

Create a cloud storage bucket

25 / 25

Upload CSV files to Cloud Storage

0 / 25

Create a Cloud SQL instance

0 / 25

Create a database

0 / 25
Introduction to SQL for BigQuery and Cloud SQL
1 hour 15 minutes Free
GSP281

Google Cloud Self-Paced Labs
Overview

SQL (Structured Query Language) is a standard language for data operations that allows you to ask questions and get insights from structured datasets. It's commonly used in database management and allows you to perform tasks like transaction record writing into relational databases and petabyte-scale data analysis.

This lab serves as an introduction to SQL and is intended to prepare you for the many labs and quests in Qwiklabs on data science topics. This lab is divided into two parts: in the first half, you will learn fundamental SQL querying keywords, which you will run in the BigQuery console on a public dataset that contains information on London bikeshares.

In the second half, you will learn how to export subsets of the London bikeshare dataset into CSV files, which you will then upload to Cloud SQL. From there you will learn how to use Cloud SQL to create and manage databases and tables. Towards the end, you will get hands-on practice with additional SQL keywords that manipulate and edit data.
Objectives

In this lab, you will learn how to:

    Distinguish databases from tables and projects.
    Use the SELECT, FROM, and WHERE keywords to construct simple queries.
    Identify the different components and hierarchies within the BigQuery console.
    Load databases and tables into BigQuery.
    Execute simple queries on tables.
    Learn about the COUNT, GROUP BY, AS, and ORDER BY keywords.
    Execute and chain the above commands to pull meaningful data from datasets.
    Export a subset of data into a CSV file and store that file into a new Cloud Storage bucket.
    Create a new Cloud SQL instance and load your exported CSV file as a new table.
    Run CREATE DATABASE, CREATE TABLE, DELETE, INSERT INTO, and UNION queries in Cloud SQL.

Prerequisites

Very Important: Before starting this lab, log out of your personal or corporate gmail account.

This is a introductory level lab. This assumes little to no prior experience with SQL. Familiarity with Cloud Storage and Cloud Shell is recommended, but not required. This lab will teach you the basics of reading and writing queries in SQL, which you will apply by using BigQuery and Cloud SQL.

Before taking this lab, consider your proficiency in SQL. Below are more challenging labs that will let you apply your knowledge to more advanced use cases:

    Weather Data in BigQuery
    Analyzing Natality Data Using Datalab and BigQuery

Once you're ready, scroll down and follow the steps below to get your lab environment set up.
Setup and Requirements
Before you click the Start Lab button

Read these instructions. Labs are timed and you cannot pause them. The timer, which starts when you click Start Lab, shows how long Google Cloud resources will be made available to you.

This Qwiklabs hands-on lab lets you do the lab activities yourself in a real cloud environment, not in a simulation or demo environment. It does so by giving you new, temporary credentials that you use to sign in and access Google Cloud for the duration of the lab.
What you need

To complete this lab, you need:

    Access to a standard internet browser (Chrome browser recommended).
    Time to complete the lab.

Note: If you already have your own personal Google Cloud account or project, do not use it for this lab.

Note: If you are using a Pixelbook, open an Incognito window to run this lab.
How to start your lab and sign in to the Google Cloud Console

    Click the Start Lab button. If you need to pay for the lab, a pop-up opens for you to select your payment method. On the left is a panel populated with the temporary credentials that you must use for this lab.

    Open Google Console

    Copy the username, and then click Open Google Console. The lab spins up resources, and then opens another tab that shows the Sign in page.

    Sign in

    Tip: Open the tabs in separate windows, side-by-side.
    If you see the Choose an account page, click Use Another Account. Choose an account

    In the Sign in page, paste the username that you copied from the Connection Details panel. Then copy and paste the password.

    Important: You must use the credentials from the Connection Details panel. Do not use your Qwiklabs credentials. If you have your own Google Cloud account, do not use it for this lab (avoids incurring charges).

    Click through the subsequent pages:
        Accept the terms and conditions.
        Do not add recovery options or two-factor authentication (because this is a temporary account).
        Do not sign up for free trials.

After a few moments, the Cloud Console opens in this tab.
Note: You can view the menu with a list of Google Cloud Products and Services by clicking the Navigation menu at the top-left. Cloud Console Menu
The Basics of SQL
Databases and Tables

As mentioned earlier, SQL allows you to get information from "structured datasets". Structured datasets have clear rules and formatting and often times are organized into tables, or data that's formatted in rows and columns.

An example of unstructured data would be an image file. Unstructured data is inoperable with SQL and cannot be stored in BigQuery datasets or tables (at least natively.) To work with image data (for instance), you would use a service like Cloud Vision, perhaps through its API directly.

The following is an example of a structured dataseta simple table:

User
	

Price
	

Shipped

Sean
	

$35
	

Yes

Rocky
	

$50
	

No

If you've had experience with Google Sheets, then the above should look quite similar. As we see, the table has columns for User, Price, and Shipped and two rows that are composed of filled in column values.

A Database is essentially a collection of one or more tables. SQL is a structured database management tool, but quite often (and in this lab) you will be running queries on one or a few tables joined togethernot on whole databases.
SELECT and FROM

SQL is phonetic by nature and before running a query, it's always helpful to first figure out what question you want to ask your data (unless you're just exploring for fun.)

SQL has predefined keywords which you use to translate your question into the pseudo-english SQL syntax so you can get the database engine to return the answer you want.

The most essential keywords are SELECT and FROM:

    Use SELECT to specify what fields you want to pull from your dataset.
    Use FROM to specify what table or tables we want to pull our data from.

An example may help understanding. Assume that we have the following table example_table, which has columns USER, PRICE, and SHIPPED:

14422cb7144f3ae.png

And let's say that we want to just pull the data that's found in the USER column. We can do this by running the following query that uses SELECT and FROM:

SELECT USER FROM example_table

If we executed the above command, we would select all the names from the USER column that are found in example_table.

You can also select multiple columns with the SQL SELECT keyword. Say that you want to pull the data that's found in the USER and SHIPPED columns. To do this, modify the previous query by adding another column value to our SELECT query (making sure it's separated by a comma!):

SELECT USER, SHIPPED FROM example_table

Running the above retrieves the USER and the SHIPPED data from memory:

a4027fb83edf734.png

And just like that you've covered two fundamental SQL keywords! Now to make things a bit more interesting.
WHERE

The WHERE keyword is another SQL command that filters tables for specific column values. Say that you want to pull the names from example_table whose packages were shipped. You can supplement the query with a WHERE, like the following:

SELECT USER FROM example_table WHERE SHIPPED='YES'

Running the above returns all USERs whose packages have been SHIPPED to from memory:

5566150a165277e8.png

Now that you have a baseline understanding of SQL's core keywords, apply what you've learned by running these types of queries in the BigQuery console.
Test your understanding

The following are some multiple choice questions to reinforce your understanding of the concepts covered so far. Answer them to the best of your abilities.

Exploring the BigQuery Console
The BigQuery paradigm

BigQuery is a fully-managed petabyte-scale data warehouse that runs on the Google Cloud. Data analysts and data scientists can quickly query and filter large datasets, aggregate results, and perform complex operations without having to worry about setting up and managing servers. It comes in the form of a command line tool (preinstalled in cloudshell) or a web consoleboth ready for managing and querying data housed in Google Cloud projects.

In this lab, you use the web console to run SQL queries.
Open BigQuery Console

In the Google Cloud Console, select Navigation menu > BigQuery:

BigQuery_menu.png

The Welcome to BigQuery in the Cloud Console message box opens. This message box provides a link to the quickstart guide and the release notes.

Click Done.

The BigQuery console opens.

bq-console.png

Take a moment to note some important features of the UI. The right-hand side of the console houses the query "Editor". This is where you write and run SQL commands like the examples we covered earlier. Below that is "Query history", which is a list of queries you ran previously.

The left pane of the console is the "Navigation panel". Apart from the self-explanatory query history, saved queries, and job history, there is the Explorer tab.

The highest level of resources in Explorer tab contain Google Cloud projects, which are just like the temporary Google Cloud projects you sign in to and use with each Qwiklab. As you can see in your console and in the last screenshot, we only have our Qwiklabs project housed in the Explorer tab. If you try clicking on the arrow next the project name, nothing will show up.

This is because your project doesn't contain any datasets or tables, you have nothing that can be queried. Earlier you learned datasets contain tables. When you add data to your project, note that in BigQuery, projects contain datasets, and datasets contain tables. Now that you better understand the project ? dataset ? table paradigm and the intricacies of the console, you can load up some queryable data.
Uploading queryable data

In this section you pull in some public data into your project so you can practice running SQL commands in BigQuery.

Click on the + ADD DATA link then select Explore public datasets:

BQ_adddata_2.png

In the search bar, enter "london", then select the London Bicycle Hires tile, then View Dataset.

A new tab will open, and you will now have a new project called bigquery-public-data added to the Explorer panel:

BQ_pubdata_2.png

It's important to note that you are still working out of your lab project in this new tab. All you did was pull a publicly accessible project that contains datasets and tables into BigQuery for analysis  you didn't switch over to that project. All of your jobs and services are still tied to your Qwiklabs account. You can see this for yourself by inspecting the project field near the top of the console:

BQ_proj_check_2.png

Expand bigquery-public-data > london_bicycles and select cycle_hire. You now have data that follows the BigQuery paradigm:

    Google Cloud Project ? bigquery-public-data
    Dataset ? london_bicycles
    Table ? cycle_hire

Now that you are in the cycle_hire table, in the center of the console click the Preview tab. Your page should resemble the following:

cycle_hire.png

Inspect the columns and values populated in the rows. You are now ready to run some SQL queries on the cycle_hire table.
Running SELECT, FROM, and WHERE in BigQuery

You now have a basic understanding of SQL querying keywords and the BigQuery data paradigm and some data to work with. Run some SQL commands using this service.

If you look at the bottom right corner of the console, you will notice that there are 24,369,201 rows of data, or individual bikeshare trips taken in London between 2015 and 2017 (not a small amount by any means!)

Now take note of the seventh column key: end_station_name, which specifies the end destination of bikeshare rides. Before we get too deep, let's first run a simple query to isolate the end_station_name column. Copy and paste the following command in to the query EDITOR:

SELECT end_station_name FROM `bigquery-public-data.london_bicycles.cycle_hire`;

Then click Run.

After ~20 seconds, you should be returned with 24369201 rows that contain the single column you queried for: end_station_name.

Why don't you find out how many bike trips were 20 minutes or longer?

Clear the query from the editor, then run the following query that utilizes the WHERE keyword:

SELECT * FROM `bigquery-public-data.london_bicycles.cycle_hire` WHERE duration>=1200;

This query may take a minute or so to run.

SELECT * returns all column values from the table. Duration is measured in seconds, which is why you used the value 1200 (60 * 20).

If you look in the bottom right corner you see that 7,334,890 rows were returned. As a fraction of the total (7334890/24369201), this means that ~30% of London bikeshare rides lasted 20 minutes or longer (they're in it for the long haul!)
Test your understanding

The following are some multiple choice questions to reinforce your understanding of the concepts we've covered so far. Answer them to the best of your abilities.

More SQL Keywords: GROUP BY, COUNT, AS, and ORDER BY
GROUP BY

The GROUP BY keyword will aggregate result-set rows that share common criteria (e.g. a column value) and will return all of the unique entries found for such criteria.

This is a useful keyword for figuring out categorical information on tables. To get a better picture of what this keyword does, clear the query from the editor, then copy and paste the following command:

SELECT start_station_name FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name;

Click Run.

You should receive a similar output (row values may not match the following):

30b04fc6f21c544c.png

Without the GROUP BY, the query would have returned the full 24,369,201 rows. GROUP BY will output the unique (non-duplicate) column values found in the table. You can see this for yourself by looking in the bottom right corner. You will see 880 rows, meaning there are 880 distinct London bikeshare starting points.
COUNT

The COUNT() function will return the number of rows that share the same criteria (e.g. column value). This can be very useful in tandem with a GROUP BY.

Add the COUNT function to our previous query to figure out how many rides begin in each starting point. Clear the query from the editor, then copy and paste the following command and then click Run:

SELECT start_station_name, COUNT(*) FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name;

You should receive a similar output (row values may not match the following):

b62aaf26b7a35e35.png

This shows how many bikeshare rides begin at each starting location.
AS

SQL also has an AS keyword, which creates an alias of a table or column. An alias is a new name that's given to the returned column or tablewhatever AS specifies.

Add an AS keyword to the last query we ran to see this in action. Clear the query from the editor, then copy and paste the following command:

SELECT start_station_name, COUNT(*) AS num_starts FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name;

Click Run.

You should receive a similar output (be aware that the row values might not be identical):

a45a8b122dbfea2b.png

As you see, the COUNT(*) column in the returned table is now set to the alias name num_starts. This is a handy keyword to use especially if you are dealing with large sets of data  forgetting that an ambiguous table or column name happens more often than you think!
ORDER BY

The ORDER BY keyword sorts the returned data from a query in ascending or descending order based on a specified criteria or column value. We will add this keyword to our previous query to do the following:

    Return a table that contains the number of bikeshare rides that begin in each starting station, organized alphabetically by the starting station.
    Return a table that contains the number of bikeshare rides that begin in each starting station, organized numerically from lowest to highest.
    Return a table that contains the number of bikeshare rides that begin in each starting station, organized numerically from highest to lowest.

Each of the commands below is a separate query. For each command, clear the query EDITOR, copy and paste the command in to the query EDITOR, and then click Run. Examine the results.

SELECT start_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name ORDER BY start_station_name;

SELECT start_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name ORDER BY num;

SELECT start_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name ORDER BY num DESC;

The last query should have returned the following:

368742bde0aa54d6.png

We see that "Belgrove Street, King's Cross" has the highest number of starts. However, as a fraction of the total (234458/24369201), we see that < 1% of rides start from this station.
Test your understanding

The following are some multiple choice questions to reinforce your understanding of the concepts we've covered so far. Answer them to the best of your abilities.

Working with Cloud SQL
Exporting queries as CSV files

Cloud SQL is a fully-managed database service that makes it easy to set up, maintain, manage, and administer your relational PostgreSQL and MySQL databases in the cloud. There are two formats of data accepted by Cloud SQL: dump files (.sql) or CSV files (.csv). You will learn how to export subsets of the cycle_hire table into CSV files and upload them to Cloud Storage as an intermediate location.

Back in the BigQuery Console, this should have been the last command that you ran:

SELECT start_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY start_station_name ORDER BY num DESC;

In the Query Results section click SAVE RESULTS > CSV(local file) > SAVE. This initiates a download, which saves this query as a CSV file. Note the location and the name of this downloaded fileyou will need it soon.

Clear the query EDITOR, then copy and run the following in the query editor:

SELECT end_station_name, COUNT(*) AS num FROM `bigquery-public-data.london_bicycles.cycle_hire` GROUP BY end_station_name ORDER BY num DESC;

This will return a table that contains the number of bikeshare rides that finish in each ending station and is organized numerically from highest to lowest number of rides. You should receive the following output:

814554dc82c60a74.png

In the Query Results section click SAVE RESULTS > CSV(local file) > SAVE. This initiates a download, which saves this query as a CSV file. Note the location and the name of this downloaded fileyou will need it in the following section.
Upload CSV files to Cloud Storage

Go to the Cloud Console where you'll create a storage bucket where you can upload the files you just created.

Select Navigation menu > Storage > Browser, and then click Create bucket.
Note: If prompted, Click LEAVE for Unsaved work.

Enter a unique name for your bucket, keep all other settings, and hit Create:

bucket_details.png
Test Completed Task

Click Check my progress below to check your lab progress. If you successfully created your bucket, you'll see an assessment score.
Create a cloud storage bucket.

You should now be in the Cloud Console looking at your newly created Cloud Storage Bucket.

Click Upload files and select the CSV that contains start_station_name data. Then click Open. Repeat this for the end_station_name data.

Rename your start_station_name file by clicking on the three dots next to on the far side of the file and click rename. Rename the file start_station_data.csv.

Rename your end_station_name file by clicking on the three dots next to on the far side of the file and click rename. Rename the file end_station_data.csv.

Your bucket should now resemble the following:

4ca41c9e381d94f.png
Test Completed Task

Click Check my progress to verify your performed task. If you have successfully upload CSV objects to your bucket, you will see an assessment score.
Upload CSV files to Cloud Storage.
Create a Cloud SQL instance

In the console, select Navigation menu > SQL.

Click Create Instance.

From here, you will be prompted to choose a database engine. Select MySQL.

Now enter in a name for your instance (like "qwiklabs-demo") and enter in a secure password in the Root password field (remember it!), then click CREATE INSTANCE:

CreateInstance.png

It might take a few minutes for the instance to be created. Once it is, you will see a green checkmark next to the instance name.

Click on the Cloud SQL instance. You should now be on a page that resembles the following:

overview.png
Test Completed Task

To check out your lab progress, click Check my progress below.If you have successfully set up your Cloud SQL instance, you will see an assessment score.
Create a CloudSQL Instance.
New Queries in Cloud SQL
CREATE keyword (databases and tables)

Now that you have a Cloud SQL instance up and running, create a database inside of it using the Cloud Shell Command Line.
Activate Cloud Shell

Cloud Shell is a virtual machine that is loaded with development tools. It offers a persistent 5GB home directory and runs on the Google Cloud. Cloud Shell provides command-line access to your Google Cloud resources.

In the Cloud Console, in the top right toolbar, click the Activate Cloud Shell button.

Cloud Shell icon

Click Continue.

cloudshell_continue.png

It takes a few moments to provision and connect to the environment. When you are connected, you are already authenticated, and the project is set to your PROJECT_ID. For example:

Cloud Shell Terminal

gcloud is the command-line tool for Google Cloud. It comes pre-installed on Cloud Shell and supports tab-completion.

You can list the active account name with this command:

gcloud auth list

(Output)

Credentialed accounts:
 - <myaccount>@<mydomain>.com (active)

(Example output)

Credentialed accounts:
 - google1623327_student@qwiklabs.net

You can list the project ID with this command:

gcloud config list project

(Output)

[core]
project = <project_ID>

(Example output)

[core]
project = qwiklabs-gcp-44776a13dea667a6

For full documentation of gcloud see the gcloud command-line tool overview.

Run the following command in Cloud Shell to connect to your SQL instance, replacing qwiklabs-demo if you used a different name for your instance:

gcloud sql connect  qwiklabs-demo --user=root

It may take a minute to connect to your instance.

When prompted, enter the root password you set for the instance.

You should now be on a similar output:

Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 494
Server version: 5.7.14-google-log (Google)

Copyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql>

A Cloud SQL instance comes with pre-configured databases, but you will create your own to store the London bikeshare data.

Run the following command at the MySQL server prompt to create a database called bike:

CREATE DATABASE bike;

You should receive the following output:

Query OK, 1 row affected (0.05 sec)

mysql>

Test Completed Task

Check your progress by clicking Check my progress to verify your performed task. If you have successfully created database in Cloud SQL instance, you will see an assessment score.
Create a database.

Make a table inside of the bike database by running the following command:

USE bike;
CREATE TABLE london1 (start_station_name VARCHAR(255), num INT);

This statement uses the CREATE keyword, but this time it uses the TABLE clause to specify that it wants to build a table instead of a database. The USE keyword specifies a database that you want to connect to. You now have a table named "london1" that contains two columns, "start_station_name" and "num". VARCHAR(255) specifies variable length string column that can hold up to 255 characters and INT is a column of type integer.

Create another table named "london2" by running the following command:

USE bike;
CREATE TABLE london2 (end_station_name VARCHAR(255), num INT);

Now confirm that your empty tables were created. Run the following commands at the MySQL server prompt:

SELECT * FROM london1;
SELECT * FROM london2;

You should receive the following output for both commands:

Empty set (0.04 sec)

It says "empty set" because you haven't loaded in any data yet.
Upload CSV files to tables

Return to the Cloud SQL console. You will now upload the start_station_name and end_station_name CSV files into your newly created london1 and london2 tables.

    In your Cloud SQL instance page, click IMPORT.
    In the Cloud Storage file field, click Browse, and then click the arrow opposite your bucket name, and then click start_station_data.csv. Click Select.
    Select CSV as File format.
    Select the bike database and type in "london1" as your table.
    Click Import:

ImportData

Do the same for the other CSV file.

    In your Cloud SQL instance page, click IMPORT.
    In the Cloud Storage file field, click Browse, and then click the arrow opposite your bucket name, and then click end_station_data.csv Click Select.
    Select CSV as File format.
    Select the bike database and type in "london2" as your table.
    Click Import:

You should now have both CSV files uploaded to tables in the bike database.

Return to your Cloud Shell session and run the following command at the MySQL server prompt to inspect the contents of london1:

SELECT * FROM london1;

You should receive 881 lines of output, one more each unique station name. Your output be formatted like this:

48c3c74603692827.png

Run the following command to make sure that london2 has been populated:

SELECT * FROM london2;

You should receive 883 lines of output, one more each unique station name. Your output be formatted like this:

85a788ec7971f8a0.png
DELETE keyword

Here are a couple more SQL keywords that help us with data management. The first is the DELETE keyword.

Run the following commands in your MySQL session to delete the first row of the london1 and london2:

DELETE FROM london1 WHERE num=0;
DELETE FROM london2 WHERE num=0;

You should receive the following output after running both commands:

Query OK, 1 row affected (0.04 sec)

The rows deleted were the column headers from the CSV files. The DELETE keyword will not remove the first row of the file per se, but all rows of the table where the column name (in this case "num") contains a specified value (in this case "0"). If you run the SELECT * FROM london1; and SELECT * FROM london2; queries and scroll to the top of the table, you will see that those rows no longer exist.
INSERT INTO keyword

You can also insert values into tables with the INSERT INTO keyword. Run the following command to insert a new row into london1, which sets start_station_name to "test destination" and num to "1":

INSERT INTO london1 (start_station_name, num) VALUES ("test destination", 1);

The INSERT INTO keyword requires a table (london1) and will create a new row with columns specified by the terms in the first parenthesis (in this case "start_station_name" and "num"). Whatever comes after the "VALUES" clause will be inserted as values in the new row.

You should receive the following output:

Query OK, 1 row affected (0.05 sec)

If you run the query SELECT * FROM london1; you will see an additional row added at the bottom of the "london1" table:

b067eb36e63b9e68.png
UNION keyword

The last SQL keyword that you'll learn about is UNION. This keyword combines the output of two or more SELECT queries into a result-set. You use UNION to combine subsets of the "london1" and "london2" tables.

The following chained query pulls specific data from both tables and combine them with the UNION operator.

Run the following command at the MySQL server prompt:

SELECT start_station_name AS top_stations, num FROM london1 WHERE num>100000
UNION
SELECT end_station_name, num FROM london2 WHERE num>100000
ORDER BY top_stations DESC;

The first SELECT query selects the two columns from the "london1" table and creates an alias for "start_station_name", which gets set to "top_stations". It uses the WHERE keyword to only pull rideshare station names where over 100,000 bikes start their journey.

The second SELECT query selects the two columns from the "london2" table and uses the WHERE keyword to only pull rideshare station names where over 100,000 bikes end their journey.

The UNION keyword in between combines the output of these queries by assimilating the "london2" data with "london1". Since "london1" is being unioned with "london2", the column values that take precedent are "top_stations" and "num".

ORDER BY will order the final, unioned table by the "top_stations" column value alphabetically and in descending order.

You should receive the following output:

num.png

As you see, 13/14 stations share the top spots for rideshare starting and ending points. With some basic SQL keywords you were able to query a sizable dataset, which returned data points and answers to specific questions.
Congratulations!

In this lab you learned the fundamentals of SQL and how you can apply keywords and run queries in BigQuery and CloudSQL. You were taught the core concepts behind projects, databases, and tables. You practiced with keywords that manipulated and edited data. You learned how to load datasets into BigQuery and you practiced running queries on tables. You learned how to create instances in Cloud SQL and practiced transferring subsets of data into tables contained in databases. You chained and ran queries in Cloud SQL to arrive at some interesting conclusions about London bikesharing starting and ending stations.

quest-badge-two.png Data_Science_125.png cloudsql-quest-badge.png BigQueryBasicsforDataAnalysts-125x135.png MarchMadness02_125.png CloudEngineeringExaPrep_125.pmg Data Catalog Quest Badge.pmg bq_retail_125.png
Finish Your Quest

This self-paced lab is part of the Qwiklabs Quests Data Science on Google Cloud, Scientific Data Processing, Cloud SQL, BigQuery Basics for Data Analysts, NCAA March Madness: Bracketology with Google Cloud, Cloud Engineering, Data Catalog Fundamentals and Applying BQML's Classification, Regression, and Demand Forcastng for Retail Applications. A Quest is a series of related labs that form a learning path. Completing a Quest earns you one of the badges above, to recognize your achievement. You can make your badge (or badges) public and link to them in your online resume or social media account. Enroll in a quest and get immediate completion credit if you've taken this lab. See other available Qwiklabs Quests.
Next Steps / Learn More

Continue your learning with and get more practice with Cloud SQL and BigQuery:

    Weather Data in BigQuery
    Exploring NCAA Data with BigQuery
    Loading Data into Google Cloud SQL
    Cloud SQL with Terraform

Google Cloud Training & Certification

...helps you make the most of Google Cloud technologies. Our classes include technical skills and best practices to help you get up to speed quickly and continue your learning journey. We offer fundamental to advanced level training, with on-demand, live, and virtual options to suit your busy schedule. Certifications help you validate and prove your skill and expertise in Google Cloud technologies.
Manual Last Updated March 30, 2021
Lab Last Tested March 17, 2021

Copyright 2021 Google LLC All rights reserved. Google and the Google logo are trademarks of Google LLC. All other company and product names may be trademarks of the respective companies with which they are associated.
Continue questing
Lab
Introduction to SQL for BigQuery and Cloud SQL
Introductory
GSP281
Overview
Setup and Requirements
The Basics of SQL
Exploring the BigQuery Console
More SQL Keywords: GROUP BY, COUNT, AS, and ORDER BY
Working with Cloud SQL
New Queries in Cloud SQL
Congratulations!





